<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> Movle</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="https://img-blog.csdnimg.cn/20200609161448519.jpg" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/Shen-Yu/hexo-theme-ayer"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="https://img-blog.csdnimg.cn/2020060916514052.png" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">Movle</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['种一棵树，最好的时机是十年前，其次是现在', '人必有痴，而后有成', '今天，我没有浑浑噩噩的度过'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Spark SQL实战：UDF与UDAF的使用"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9AUDF%E4%B8%8EUDAF%E7%9A%84%E4%BD%BF%E7%94%A8/"
    >Spark SQL实战之UDF与UDAF的使用</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9AUDF%E4%B8%8EUDAF%E7%9A%84%E4%BD%BF%E7%94%A8/" class="article-date">
  <time datetime="2020-03-13T11:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-概念："><a href="#1-概念：" class="headerlink" title="1.概念："></a>1.概念：</h4><p>UDF就是用户自定义的函数<br>UDAF就是用户自定义的聚合函数</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-SparkSQLUDFUDAF-scala"><a href="#2-SparkSQLUDFUDAF-scala" class="headerlink" title="(2)SparkSQLUDFUDAF.scala"></a>(2)SparkSQLUDFUDAF.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.sqlshizhan</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123; Row, SQLContext &#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructField</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StringType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.UserDefinedAggregateFunction</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.MutableAggregationBuffer</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.DataType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.IntegerType</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> SparkSQLUDFUDAF</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@MethodDesc</span>: SparkSQL UDF与UDAF的使用</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Movle</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 5/18/20 10:44 下午</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Email</span> movle_xjk@foxmail.com</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line">object SparkSQLUDFUDAF &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;SparkSQLUDFUDAF&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val sc = <span class="keyword">new</span> SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val sqlContext = <span class="keyword">new</span> SQLContext(sc)</span><br><span class="line"></span><br><span class="line">    val bigData = Array(<span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;spark&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建Dataframe</span></span><br><span class="line">    val bigDataRDD = sc.parallelize(bigData)</span><br><span class="line"></span><br><span class="line">    val bigDataRDDRow = bigDataRDD.map(item =&gt; Row(item))</span><br><span class="line"></span><br><span class="line">    val structType = StructType(Array(</span><br><span class="line">      <span class="keyword">new</span> StructField(<span class="string">&quot;word&quot;</span>, StringType)))</span><br><span class="line"></span><br><span class="line">    val bigDataDF = sqlContext.createDataFrame(bigDataRDDRow, structType)</span><br><span class="line"></span><br><span class="line">    bigDataDF.createOrReplaceTempView(<span class="string">&quot;bigDataTable&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//UDF 最多22个输入参数</span></span><br><span class="line">    sqlContext.udf.register(<span class="string">&quot;computeLength&quot;</span>,(input:String,input2:String) =&gt; input.length())</span><br><span class="line"></span><br><span class="line">    sqlContext.sql(<span class="string">&quot;select word,computeLength(word,word) from bigDataTable&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    sqlContext.udf.register(<span class="string">&quot;wordcount&quot;</span>, <span class="keyword">new</span> MyUDAF)</span><br><span class="line"></span><br><span class="line">    sqlContext.sql(<span class="string">&quot;select word,wordcount(word) as count from bigDataTable group by word&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyUDAF</span> <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 该方法指定具体输入数据的类型</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def inputSchema: StructType = StructType(Array(StructField(<span class="string">&quot;input&quot;</span>, StringType, <span class="keyword">true</span>)))</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 在进行聚合操作的时候所要处理的数据的结果的类型</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def bufferSchema: StructType = StructType(Array(StructField(<span class="string">&quot;count&quot;</span>, IntegerType, <span class="keyword">true</span>)))</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 指定UDAF函数计算后返回的结果类型</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def dataType: DataType = IntegerType</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 确保一致性，一般都用true</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def deterministic: Boolean = <span class="keyword">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 在Aggregate之前每组数据的初始化结果</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">initialize</span><span class="params">(buffer: MutableAggregationBuffer)</span>: Unit </span>= &#123; buffer(<span class="number">0</span>) = <span class="number">0</span> &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 在进行聚合的时候，每当有新的值进来，对分组后的聚合如何进行计算</span></span><br><span class="line"><span class="comment">   * 本地的聚合操作，相当于Hadoop MapReduce模型中的Combiner</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> input</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">update</span><span class="params">(buffer: MutableAggregationBuffer, input: Row)</span>: Unit </span>= &#123;</span><br><span class="line">    buffer(<span class="number">0</span>) = buffer.getAs[Int](<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 最后在分布式节点进行Local Reduce完成后需要进行全局级别的Merge操作</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer1</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer2</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">merge</span><span class="params">(buffer1: MutableAggregationBuffer, buffer2: Row)</span>: Unit </span>= &#123;</span><br><span class="line">    buffer1(<span class="number">0</span>) = buffer1.getAs[Int](<span class="number">0</span>) + buffer2.getAs[Int](<span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 返回UDAF最后的计算结果</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">evaluate</span><span class="params">(buffer: Row)</span>: Any </span>= buffer.getAs[Int](<span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark SQL实战：SparkSQL exmple"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9ASparkSQL%20exmple/"
    >Spark SQL实战：SparkSQL exmple</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9ASparkSQL%20exmple/" class="article-date">
  <time datetime="2020-03-13T10:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>使用Spark SQL，读取文件并查询数据表</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="2-SparkSQLExample-scala"><a href="#2-SparkSQLExample-scala" class="headerlink" title="(2)SparkSQLExample.scala"></a>(2)SparkSQLExample.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.sqlshizhan</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;Level, Logger&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> SparkSQLExample</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@MethodDesc</span>: TODO SparkSQLExample功能介绍</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Movle</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 5/18/20 9:34 下午</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Email</span> movle_xjk@foxmail.com</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Student1</span><span class="params">(sno:String,sname:String,ssex:String,sbirthday:String,sclass:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Course</span><span class="params">(cno:String,cname:String,tno:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Score</span><span class="params">(sno:String,cno:String,degree:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Teacher</span><span class="params">(tno:String,tname:String,tsex:String,tbirthday:String,tprof:String,tdepart:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">import</span> java.text.SimpleDateFormat</span></span><br><span class="line"><span class="function">object SparkSQLExample </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>,<span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line"></span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    <span class="comment">//Logger.getLogger(&quot;org.eclipse.jetty.server&quot;).setLevel(Level.OFF)</span></span><br><span class="line"></span><br><span class="line">    <span class="function">def <span class="title">getDate</span><span class="params">(time: String)</span> </span>= &#123;</span><br><span class="line">      val now: Long = System.currentTimeMillis()</span><br><span class="line">      val df: SimpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(time)</span><br><span class="line">      df.format(now)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val spark = SparkSession.builder().master(<span class="string">&quot;local&quot;</span>).appName(<span class="string">&quot;SparkSQLExample&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.sqlContext.implicits._</span><br><span class="line"></span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Student.csv&quot;</span>)</span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map(x=&gt;Student1(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>),x(<span class="number">3</span>),x(<span class="number">4</span>)))</span><br><span class="line">      .toDF</span><br><span class="line">      .createOrReplaceTempView(<span class="string">&quot;Student1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Course.csv&quot;</span>)</span><br><span class="line">        .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        .map(x =&gt; Course(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>)))</span><br><span class="line">        .toDF</span><br><span class="line">        .createOrReplaceTempView(<span class="string">&quot;Course&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Score.csv&quot;</span>)</span><br><span class="line">        .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        .map(x =&gt; Score(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>)))</span><br><span class="line">        .toDF</span><br><span class="line">        .createOrReplaceTempView(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Teacher.csv&quot;</span>)</span><br><span class="line">        .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        .map(x =&gt; Teacher(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>),x(<span class="number">3</span>),x(<span class="number">4</span>),x(<span class="number">5</span>)))</span><br><span class="line">        .toDF</span><br><span class="line">        .createOrReplaceTempView(<span class="string">&quot;Teacher&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询整个teacher表</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from Teacher&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查询Student表中所有记录的sname ssex class列</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sname,ssex,sclass from student&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询教师表中不重复的depart列</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select distinct tdepart from teacher&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line">    spark.sql(<span class="string">&quot;select tdepart from teacher group by tdepart&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score表中成绩在60 80 之间的所有记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree &gt;= 60 and degree &lt;= 80&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree between 60 and 80&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score表中成绩为 85 86 或 88 的记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree = &#x27;85&#x27; or degree=&#x27;86&#x27; OR degree=&#x27;88&#x27;&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree =85 or degree=86 OR degree=88&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//以class降序、升序排列查询</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from student order by sclass desc&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from student order by sclass&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//以cno升序 degree降序查询score表中的数据</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score t order by t.sno asc, t.degree desc&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询Score表中的最高分的学生学号和课程</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score order by Int(degree) desc limit 1&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score order by Int(degree) desc&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询每门课的平均成绩</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select cno,avg(degree) from score group by cno&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score表中至少有5名学生选修的课，并且名字以 3 开头的课程 的平均分数</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select cno,avg(degree) from score where cno like &#x27;3%&#x27; group by cno having count(cno) &gt;= 5&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询所有学生中的sname cname degree</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select s.sname, t.degree,c.cname from score t &quot;</span> +</span><br><span class="line">      <span class="string">&quot;join student s on t.sno=s.sno &quot;</span> +</span><br><span class="line">      <span class="string">&quot;join course c on c.cno=t.cno&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score中选择多门课程的同学中，分数为非最高分成绩的记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where &quot;</span> +</span><br><span class="line">      <span class="string">&quot;sno in (select sno from score t group by t.sno having count(1) &gt; 1) &quot;</span> +</span><br><span class="line">      <span class="string">&quot; and degree != (select max(degree) from score)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询和学号为108的同学同年出生的所有学生的sno sname sbirthday 列</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sno,sname,sbirthday from student where substring(sbirthday,0,4) = (&quot;</span> +</span><br><span class="line">      <span class="string">&quot; select substring(t.sbirthday,0,4) from student t where sno=&#x27;108&#x27;)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询选修某课程的同学人数多于5人的教师姓名</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select tname from teacher e &quot;</span> +</span><br><span class="line">      <span class="string">&quot; join course c on e.tno = c.tno &quot;</span> +</span><br><span class="line">      <span class="string">&quot; join (select cno from score group by cno having count(cno) &gt; 5) t on c.cno = t.cno&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询成绩比该课程平均成绩低的同学的成绩表</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select s.* from score s where s.degree &lt; (select avg(degree) from score c where s.cno = c.cno)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询所有没有讲课的教师的tname 和 depart</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select tname , tdepart from teacher t where t.tno not in (select tno from course c where c.cno in (select cno from score))&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询至少有2名男生的班号</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sclass from student t where ssex=&#x27;male&#x27; group by sclass having count(ssex) &gt;= 2&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询student表中不姓 王 的同学记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from student t where sname not like(&#x27;Wang%&#x27;)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询student表中每个学生的姓名和年龄</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sname, (cast(&quot;</span> + getDate(<span class="string">&quot;yyyy&quot;</span>) + <span class="string">&quot; as int) - cast(substring(sbirthday,0,4) as int)) as age from student t&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="3-结果："><a href="#3-结果：" class="headerlink" title="3.结果："></a>3.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWZkNjQ4ZTg2ZTQ0NjQ0MjMucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark SQL实战：使用Spark SQL 连接hive ，将统计结果存储到 mysql中"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8Spark%20SQL%20%E8%BF%9E%E6%8E%A5hive%20%EF%BC%8C%E5%B0%86%E7%BB%9F%E8%AE%A1%E7%BB%93%E6%9E%9C%E5%AD%98%E5%82%A8%E5%88%B0%20mysql%E4%B8%AD/"
    >Spark SQL实战：使用Spark SQL 连接hive ，将统计结果存储到 mysql中</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8Spark%20SQL%20%E8%BF%9E%E6%8E%A5hive%20%EF%BC%8C%E5%B0%86%E7%BB%9F%E8%AE%A1%E7%BB%93%E6%9E%9C%E5%AD%98%E5%82%A8%E5%88%B0%20mysql%E4%B8%AD/" class="article-date">
  <time datetime="2020-03-13T08:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>使用Spark SQL 连接hive ，读取数据，将统计结果存储到 mysql中</p>
<h4 id="2-将写好的代码打包上传的集群，然后提交spark运行，前提是hive，HDFS已经启动"><a href="#2-将写好的代码打包上传的集群，然后提交spark运行，前提是hive，HDFS已经启动" class="headerlink" title="2.将写好的代码打包上传的集群，然后提交spark运行，前提是hive，HDFS已经启动"></a>2.将写好的代码打包上传的集群，然后提交spark运行，前提是hive，HDFS已经启动</h4><h4 id="3-代码："><a href="#3-代码：" class="headerlink" title="3.代码："></a>3.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-demo4-scala"><a href="#2-demo4-scala" class="headerlink" title="(2)demo4.scala"></a>(2)demo4.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1209</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession</span><br><span class="line"><span class="keyword">import</span> java.util.Properties</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用Spark SQL 连接hive ，将统计结果存储到 mysql中</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * ./spark-submit --master spark://hadoop1:7077 --jars /usr/local/tmp_files/mysql-connector-java-8.0.11.jar --driver-class-path /usr/local/tmp_files/mysql-connector-java-8.0.11.jar --class day0628.Demo4 /usr/local/tmp_files/Demo1209.jar</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">object Demo4 &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    val spark = SparkSession.builder().appName(<span class="string">&quot;Hive2Mysql&quot;</span>).enableHiveSupport().getOrCreate()</span><br><span class="line">   <span class="comment">//.config(&quot;spark.sql.inMemoryColumnarStorage.batchSize&quot;, 10)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//执行sql</span></span><br><span class="line">    val result = spark.sql(<span class="string">&quot;select deptno,mgr from default.emp&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将结果保存到mysql中</span></span><br><span class="line">    val props = <span class="keyword">new</span> Properties()</span><br><span class="line">    props.setProperty(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">    props.setProperty(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;000000&quot;</span>)</span><br><span class="line"></span><br><span class="line">    result.write.mode(<span class="string">&quot;append&quot;</span>).jdbc(</span><br><span class="line">      <span class="string">&quot;jdbc:mysql://hadoop2:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8&quot;</span>,</span><br><span class="line">      <span class="string">&quot;emp_stat&quot;</span>, props)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//停止Spark</span></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="4-执行："><a href="#4-执行：" class="headerlink" title="4.执行："></a>4.执行：</h4><h5 id="1-启动spark"><a href="#1-启动spark" class="headerlink" title="(1)启动spark"></a>(1)启动spark</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/spark-2.1.1</span><br><span class="line"></span><br><span class="line">./bin/spark-submit --master spark://hadoop2:7077 --jars /opt/TestFolder/mysql-connector-java-5.1.27.jar --driver-class-path /opt/TestFolder/mysql-connector-java-5.1.27.jar --class spark.sqlshizhan.Demo4 /opt/TestFolder/Scala-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<h4 id="5-结果："><a href="#5-结果：" class="headerlink" title="5.结果："></a>5.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWVlZTNkZDg4OWY4OTBkYzAucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark SQL实战：将结果写入 Mysql"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E5%B0%86%E7%BB%93%E6%9E%9C%E5%86%99%E5%85%A5%20Mysql/"
    >Spark SQL实战：将结果写入 Mysql</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E5%B0%86%E7%BB%93%E6%9E%9C%E5%86%99%E5%85%A5%20Mysql/" class="article-date">
  <time datetime="2020-03-13T07:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>读取本地student.txt，并创建DataFrame，并将结果写入mysql数据库中</p>
<h4 id="2-数据源："><a href="#2-数据源：" class="headerlink" title="2.数据源："></a>2.数据源：</h4><p>student.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	tom  15</span><br><span class="line">2	lucy	20</span><br><span class="line">3	mike	18</span><br></pre></td></tr></table></figure>

<h4 id="3-写代码："><a href="#3-写代码：" class="headerlink" title="3.写代码："></a>3.写代码：</h4><h5 id="1-添加依赖："><a href="#1-添加依赖：" class="headerlink" title="(1)添加依赖："></a>(1)添加依赖：</h5><p>pom.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-Demo3-scala"><a href="#2-Demo3-scala" class="headerlink" title="(2)Demo3.scala"></a>(2)Demo3.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1209</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructField</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.IntegerType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StringType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row</span><br><span class="line"><span class="keyword">import</span> java.util.Properties</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将结果写入 Mysql</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">object Demo3 &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    <span class="comment">//创建Spark Session对象</span></span><br><span class="line">    val spark = SparkSession.builder().master(<span class="string">&quot;local&quot;</span>).appName(<span class="string">&quot;Save to Mysql&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//从指定地址读取文件 创建RDD</span></span><br><span class="line">    val personRDD = spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/student.txt&quot;</span>).map(_.split(<span class="string">&quot;\t&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定schema</span></span><br><span class="line">    val schema = StructType(</span><br><span class="line">      List(</span><br><span class="line">        StructField(<span class="string">&quot;id&quot;</span>, IntegerType),</span><br><span class="line">        StructField(<span class="string">&quot;sname&quot;</span>, StringType),</span><br><span class="line">        StructField(<span class="string">&quot;age&quot;</span>, IntegerType)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将RDD转换为 rowRDD</span></span><br><span class="line">    val rowRDD = personRDD.map(p =&gt; Row(p(<span class="number">0</span>).toInt, p(<span class="number">1</span>).trim(), p(<span class="number">2</span>).toInt))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建DataFrame 将schema与row对应</span></span><br><span class="line">    val personDataFrame = spark.createDataFrame(rowRDD, schema)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//注册视图</span></span><br><span class="line">    personDataFrame.createOrReplaceTempView(<span class="string">&quot;t_person&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//执行SQL</span></span><br><span class="line">    val result = spark.sql(<span class="string">&quot;select * from t_person order by age desc&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//显示结果</span></span><br><span class="line">    <span class="comment">//df.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//把结果保存在Mysql中</span></span><br><span class="line">    val props = <span class="keyword">new</span> Properties()</span><br><span class="line">    props.setProperty(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">    props.setProperty(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;000000&quot;</span>)</span><br><span class="line"></span><br><span class="line">    result.write.mode(<span class="string">&quot;append&quot;</span>).jdbc(<span class="string">&quot;jdbc:mysql://192.168.1.121:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8&quot;</span>, <span class="string">&quot;student&quot;</span>, props)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="4-结果："><a href="#4-结果：" class="headerlink" title="4.结果："></a>4.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWU5OGVmMWY3OTdhMDZkMjAucG5n?x-oss-process=image/format,png" alt="执行前查询student表"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWNlYjcwMmI1OGFmNjNkYTAucG5n?x-oss-process=image/format,png" alt="执行后查询student表"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark SQL实战：使用 case class 创建DataFrame"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8%20case%20class%20%E5%88%9B%E5%BB%BADataFrame/"
    >Spark SQL实战:使用 case class 创建DataFrame</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8%20case%20class%20%E5%88%9B%E5%BB%BADataFrame/" class="article-date">
  <time datetime="2020-03-13T06:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>使用 case class 创建DataFrame</p>
<h4 id="2-数据源："><a href="#2-数据源：" class="headerlink" title="2.数据源："></a>2.数据源：</h4><h5 id="1-student-txt"><a href="#1-student-txt" class="headerlink" title="(1)student.txt"></a>(1)student.txt</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	tom  15</span><br><span class="line">2	lucy	20</span><br><span class="line">3	mike	18</span><br></pre></td></tr></table></figure>

<h4 id="3-编写代码"><a href="#3-编写代码" class="headerlink" title="3.编写代码"></a>3.编写代码</h4><h5 id="1-添加依赖："><a href="#1-添加依赖：" class="headerlink" title="(1)添加依赖："></a>(1)添加依赖：</h5><p>pom.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-Demo2-scala"><a href="#2-Demo2-scala" class="headerlink" title="(2)Demo2.scala"></a>(2)Demo2.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1209</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用 case class 创建DataFrame</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">object Demo2 &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    val spark = SparkSession.builder().master(<span class="string">&quot;local&quot;</span>).appName(<span class="string">&quot;CaseClassDemo&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    val lineRDD = spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/student.txt&quot;</span>).map(_.split(<span class="string">&quot;\t&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//RDD 和 表结构关联</span></span><br><span class="line">    val studentRDD = lineRDD.map(x =&gt; Student(x(<span class="number">0</span>).toInt,x(<span class="number">1</span>),x(<span class="number">2</span>).toInt))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//生成DataFrame</span></span><br><span class="line">    <span class="keyword">import</span> spark.sqlContext.implicits._</span><br><span class="line">    val studentDF = studentRDD.toDF</span><br><span class="line"></span><br><span class="line">    studentDF.createOrReplaceTempView(<span class="string">&quot;student&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from student&quot;</span>).show</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//定义 case class 相当于schema</span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Student</span><span class="params">(stuId:Int,stuName:String,stuAge:Int)</span></span></span><br></pre></td></tr></table></figure>

<h4 id="4-结果："><a href="#4-结果：" class="headerlink" title="4.结果："></a>4.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTcwMTk4ZmY0NmQ1YmJjMzYucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark SQL实战：使用SparkSession创建DataFrame执行sql"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8SparkSession%E5%88%9B%E5%BB%BADataFrame%E6%89%A7%E8%A1%8Csql/"
    >Spark SQL实战:使用SparkSession创建DataFrame执行sql</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8SparkSession%E5%88%9B%E5%BB%BADataFrame%E6%89%A7%E8%A1%8Csql/" class="article-date">
  <time datetime="2020-03-13T03:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>在IDEA中编写代码，创建DataFrame 执行sql命令：</p>
<h4 id="2-数据源："><a href="#2-数据源：" class="headerlink" title="2.数据源："></a>2.数据源：</h4><h5 id="1-student-txt"><a href="#1-student-txt" class="headerlink" title="(1)student.txt"></a>(1)student.txt</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	tom  15</span><br><span class="line">2	lucy	20</span><br><span class="line">3	mike	18</span><br></pre></td></tr></table></figure>
<h4 id="3-编写代码："><a href="#3-编写代码：" class="headerlink" title="3.编写代码："></a>3.编写代码：</h4><h5 id="1-添加依赖："><a href="#1-添加依赖：" class="headerlink" title="(1)添加依赖："></a>(1)添加依赖：</h5><p>pom.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-Demo1-scala"><a href="#2-Demo1-scala" class="headerlink" title="(2)Demo1.scala"></a>(2)Demo1.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1209</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructField</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.IntegerType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StringType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建DataFrame 执行sql</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">object Demo1 &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    <span class="comment">//创建Spark Session对象</span></span><br><span class="line">    val spark = SparkSession.builder().master(<span class="string">&quot;local&quot;</span>).appName(<span class="string">&quot;UnderstandSparkSession&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//从指定地址读取文件 创建RDD</span></span><br><span class="line">    val personRDD = spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/student.txt&quot;</span>).map(_.split(<span class="string">&quot;\t&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定schema</span></span><br><span class="line">    val schema = StructType(</span><br><span class="line">      List(</span><br><span class="line">        StructField(<span class="string">&quot;id&quot;</span>, IntegerType),</span><br><span class="line">        StructField(<span class="string">&quot;name&quot;</span>, StringType),</span><br><span class="line">        StructField(<span class="string">&quot;age&quot;</span>, IntegerType)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将RDD转换为 rowRDD</span></span><br><span class="line">    val rowRDD = personRDD.map(p =&gt; Row(p(<span class="number">0</span>).toInt, p(<span class="number">1</span>).trim(), p(<span class="number">2</span>).toInt))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建DataFrame 将schema与row对应</span></span><br><span class="line">    val personDataFrame = spark.createDataFrame(rowRDD, schema)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//注册视图</span></span><br><span class="line">    personDataFrame.createOrReplaceTempView(<span class="string">&quot;t_person&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//执行SQL</span></span><br><span class="line">    val df = spark.sql(<span class="string">&quot;select * from t_person order by age desc&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//显示结果</span></span><br><span class="line">    df.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//停止Spark</span></span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="4-运行结果："><a href="#4-运行结果：" class="headerlink" title="4.运行结果："></a>4.运行结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWY2MzZmYWEwM2E4NzZjODkucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Core实战：使用JDBC RDD操作数据库"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8JDBC%20RDD%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93/"
    >Spark Core实战：使用JDBC RDD操作数据库</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E4%BD%BF%E7%94%A8JDBC%20RDD%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93/" class="article-date">
  <time datetime="2020-03-12T10:00:00.000Z" itemprop="datePublished">2020-03-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>使用JDBC RDD 操作数据库</p>
<h4 id="2-在数据库中建表并插入数据："><a href="#2-在数据库中建表并插入数据：" class="headerlink" title="2.在数据库中建表并插入数据："></a>2.在数据库中建表并插入数据：</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> emp(</span><br><span class="line">                id <span class="type">int</span>(<span class="number">11</span>), </span><br><span class="line">                ename <span class="type">varchar</span>(<span class="number">20</span>), </span><br><span class="line">                deptno <span class="type">int</span>(<span class="number">11</span>), </span><br><span class="line">                sal <span class="type">int</span>(<span class="number">11</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span>  emp <span class="keyword">values</span>(<span class="number">1</span>,&quot;Tom&quot;,<span class="number">10</span>,<span class="number">2500</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span>  emp <span class="keyword">values</span>(<span class="number">2</span>,&quot;Movle&quot;,<span class="number">11</span>,<span class="number">1000</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span>  emp <span class="keyword">values</span>(<span class="number">2</span>,&quot;Mike&quot;,<span class="number">10</span>,<span class="number">1500</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span>  emp <span class="keyword">values</span>(<span class="number">2</span>,&quot;jack&quot;,<span class="number">11</span>,<span class="number">500</span>);</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWVlZDIyMmFjYmY4ZmQ3YTQucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-添加JDBC驱动"><a href="#3-添加JDBC驱动" class="headerlink" title="3.添加JDBC驱动"></a>3.添加JDBC驱动</h4><h4 id="4-写代码："><a href="#4-写代码：" class="headerlink" title="4.写代码："></a>4.写代码：</h4><h5 id="1-MyJDBCRddDemo-scala"><a href="#1-MyJDBCRddDemo-scala" class="headerlink" title="(1)MyJDBCRddDemo.scala"></a>(1)MyJDBCRddDemo.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.JdbcRDD</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用JDBC RDD 操作数据库</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">object MyJDBCRddDemo &#123;</span><br><span class="line"></span><br><span class="line">  val connection = () =&gt; &#123;</span><br><span class="line">    Class.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>).newInstance()</span><br><span class="line">    DriverManager.getConnection(<span class="string">&quot;jdbc:mysql://localhost:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建Spark对象</span></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">&quot;My JDBC Rdd Demo&quot;</span>).setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    val sc = <span class="keyword">new</span> SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val mysqlRDD = <span class="keyword">new</span> JdbcRDD(sc,connection,<span class="string">&quot;select * from emp where sal &gt; ? and sal &lt;= ?&quot;</span>,<span class="number">900</span>,<span class="number">2000</span>, <span class="number">2</span>, r=&gt;&#123;</span><br><span class="line">      <span class="comment">//获取员工的姓名和薪水</span></span><br><span class="line">      val ename = r.getString(<span class="number">2</span>)</span><br><span class="line">      val sal = r.getInt(<span class="number">4</span>)</span><br><span class="line">      (ename,sal)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    val result = mysqlRDD.collect()</span><br><span class="line">    println(result.toBuffer)</span><br><span class="line">    sc.stop</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5-结果："><a href="#5-结果：" class="headerlink" title="5.结果："></a>5.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTRkNzVhOWM3ZGVjOTkyOTYucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkCore/" rel="tag">SparkCore</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Core实战：将Tomcat日志分析的结果写入mysql数据库"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E5%B0%86Tomcat%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%9A%84%E7%BB%93%E6%9E%9C%E5%86%99%E5%85%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93/"
    >Spark Core实战-将Tomcat日志分析的结果写入mysql数据库</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E5%B0%86Tomcat%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%9A%84%E7%BB%93%E6%9E%9C%E5%86%99%E5%85%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93/" class="article-date">
  <time datetime="2020-03-12T09:00:00.000Z" itemprop="datePublished">2020-03-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-Tomcat日志和前面一样"><a href="#1-Tomcat日志和前面一样" class="headerlink" title="1.Tomcat日志和前面一样"></a>1.Tomcat日志和前面一样</h4><h4 id="2-需求："><a href="#2-需求：" class="headerlink" title="2.需求："></a>2.需求：</h4><p>将Tomcat日志分析的结果：jps的名称和个数统计，并插入mysql数据库</p>
<h4 id="3-在mysql-本地，我的是MacOS-中建库建表："><a href="#3-在mysql-本地，我的是MacOS-中建库建表：" class="headerlink" title="3.在mysql(本地，我的是MacOS)中建库建表："></a>3.在mysql(本地，我的是MacOS)中建库建表：</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database company;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> mydata(</span><br><span class="line">          jsname <span class="type">varchar</span>(<span class="number">50</span>),</span><br><span class="line">          countNumber <span class="type">int</span>(<span class="number">11</span>));</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWY3NGYwNTMyMGU1MzM3NjIucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-编写代码："><a href="#4-编写代码：" class="headerlink" title="4.编写代码："></a>4.编写代码：</h4><h5 id="1-添加pom依赖："><a href="#1-添加pom依赖：" class="headerlink" title="(1)添加pom依赖："></a>(1)添加pom依赖：</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-在项目中加入JDBC驱动包"><a href="#2-在项目中加入JDBC驱动包" class="headerlink" title="(2)在项目中加入JDBC驱动包"></a>(2)在项目中加入JDBC驱动包</h5><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWUxNjQwNWNkMjMwODFkNDgucG5n?x-oss-process=image/format,png" alt="JDBC驱动包"></p>
<h5 id="3-MyTomcatLogCountToMysql-scala"><a href="#3-MyTomcatLogCountToMysql-scala" class="headerlink" title="(3)MyTomcatLogCountToMysql.scala"></a>(3)MyTomcatLogCountToMysql.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">object MyTomcatLogCountToMysql &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建Spark对象</span></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;My Tomcat Log Count To Mysql&quot;</span>)</span><br><span class="line">    val sc = <span class="keyword">new</span> SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读入日志，解析，找到访问jsp网页</span></span><br><span class="line"><span class="comment">     * 192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    val rdd1 = sc.textFile(<span class="string">&quot;/users/macbook/TestInfo/localhost_access_log.txt&quot;</span>)</span><br><span class="line">      .map(</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 找到网页名字</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 并计数</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * line 代表读进来的每一行数据</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">          <span class="comment">//解析字符串，找到jsp名字</span></span><br><span class="line">          <span class="comment">//得到两个双引号之间的东西</span></span><br><span class="line">          val index1 = line.indexOf(<span class="string">&quot;\&quot;&quot;</span>)</span><br><span class="line">          val index2 = line.lastIndexOf(<span class="string">&quot;\&quot;&quot;</span>)</span><br><span class="line">          val line1 = line.substring(index1 + <span class="number">1</span>, index2) <span class="comment">// GET /MyDemoWeb/web.jsp HTTP/1.1</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//得到两个空格之间的东西</span></span><br><span class="line">          val index3 = line1.indexOf(<span class="string">&quot; &quot;</span>)</span><br><span class="line">          val index4 = line1.lastIndexOf(<span class="string">&quot; &quot;</span>)</span><br><span class="line">          val line2 = line1.substring(index3 + <span class="number">1</span>, index4) <span class="comment">// /MyDemoWeb/web.jsp</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//得到jsp的名字</span></span><br><span class="line">          val jspName = line2.substring(line2.lastIndexOf(<span class="string">&quot;/&quot;</span>) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">          (jspName, <span class="number">1</span>)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    rdd1.foreachPartition(saveToMysql)</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//定义一个函数 针对分区进行操作</span></span><br><span class="line">  <span class="function">def <span class="title">saveToMysql</span><span class="params">(it: Iterator[(String, Int)</span>]) </span>= &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> conn: Connection = <span class="keyword">null</span></span><br><span class="line">    <span class="keyword">var</span> pst: PreparedStatement = <span class="keyword">null</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建连接</span></span><br><span class="line">    conn = DriverManager.getConnection(<span class="string">&quot;jdbc:mysql://localhost:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//把数据保存到mysql中</span></span><br><span class="line">    pst = conn.prepareStatement(<span class="string">&quot;insert into mydata values (?,?) &quot;</span>)</span><br><span class="line"></span><br><span class="line">    it.foreach(data =&gt; &#123;</span><br><span class="line">      pst.setString(<span class="number">1</span>, data._1)</span><br><span class="line">      pst.setInt(<span class="number">2</span>,data._2)</span><br><span class="line">      pst.executeUpdate()</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-结果："><a href="#5-结果：" class="headerlink" title="5.结果："></a>5.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWFkZmMwMmNhZGNkNGE5NzcucG5n?x-oss-process=image/format,png" alt="1"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTlhOTIyOTM1OTBhYzM1YmEucG5n?x-oss-process=image/format,png" alt="2"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkCore/" rel="tag">SparkCore</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Core实战：创建自定义分区"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA/"
    >Spark Core实战-创建自定义分区</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA/" class="article-date">
  <time datetime="2020-03-12T08:00:00.000Z" itemprop="datePublished">2020-03-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-Tomcat日志格式："><a href="#1-Tomcat日志格式：" class="headerlink" title="1.Tomcat日志格式："></a>1.Tomcat日志格式：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/ HTTP/1.1&quot; 200 259</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/head.jsp HTTP/1.1&quot; 200 713</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/body.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:37 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] &quot;GET /MyDemoWeb/java.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:40 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:40 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:41 +0800] &quot;GET /MyDemoWeb/mysql.jsp HTTP/1.1&quot; 200 241</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:41 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:53 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] &quot;GET /MyDemoWeb/mysql.jsp HTTP/1.1&quot; 200 241</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:56 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:56 +0800] &quot;GET /MyDemoWeb/java.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:57 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:57 +0800] &quot;GET /MyDemoWeb/java.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:58 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:58 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:59 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:59 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:00 +0800] &quot;GET /MyDemoWeb/mysql.jsp HTTP/1.1&quot; 200 241</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:00 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:02 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:02 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br></pre></td></tr></table></figure>
<h4 id="2-需求：按照jsp的名字，将访问日志进行分区"><a href="#2-需求：按照jsp的名字，将访问日志进行分区" class="headerlink" title="2.需求：按照jsp的名字，将访问日志进行分区"></a>2.需求：按照jsp的名字，将访问日志进行分区</h4><h4 id="3-分析："><a href="#3-分析：" class="headerlink" title="3.分析："></a>3.分析：</h4><p>一个文件就是一个分区，并且一个文件中只包含一个jsp的名字<br> jsp名字看成key 访问日志看成value</p>
<h4 id="4-代码："><a href="#4-代码：" class="headerlink" title="4.代码："></a>4.代码：</h4><h5 id="1-添加依赖："><a href="#1-添加依赖：" class="headerlink" title="(1)添加依赖："></a>(1)添加依赖：</h5><p>pom.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-MyTomcatLogPartitioner-scala"><a href="#2-MyTomcatLogPartitioner-scala" class="headerlink" title="(2)MyTomcatLogPartitioner.scala"></a>(2)MyTomcatLogPartitioner.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1208</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.Partitioner</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.HashMap</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 创建自定义分区</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 需求：按照jsp的名字，将访问日志进行分区。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 一个文件就是一个分区，并且一个文件中只包含一个jsp的名字</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * jsp名字看成key 访问日志看成value</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">object MyTomcatLogPartitioner &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    <span class="comment">//创建Spark对象</span></span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;My Tomcat Log Partitioner&quot;</span>)</span><br><span class="line">    val sc = <span class="keyword">new</span> SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读入日志 解析</span></span><br><span class="line"><span class="comment">     * 192.168.88.1 - - [30/Jul/2017:12:54:40 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val rdd1 = sc.textFile(<span class="string">&quot;/users/macbook/TestInfo/localhost_access_log.txt&quot;</span>)</span><br><span class="line">      .map(</span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">          <span class="comment">//解析字符串，找到jsp名字</span></span><br><span class="line">          <span class="comment">//得到两个双引号之间的东西</span></span><br><span class="line">          val index1 = line.indexOf(<span class="string">&quot;\&quot;&quot;</span>)</span><br><span class="line">          val index2 = line.lastIndexOf(<span class="string">&quot;\&quot;&quot;</span>)</span><br><span class="line">          val line1 = line.substring(index1 + <span class="number">1</span>, index2) <span class="comment">// GET /MyDemoWeb/web.jsp HTTP/1.1</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//得到两个空格之间的东西</span></span><br><span class="line">          val index3 = line1.indexOf(<span class="string">&quot; &quot;</span>)</span><br><span class="line">          val index4 = line1.lastIndexOf(<span class="string">&quot; &quot;</span>)</span><br><span class="line">          val line2 = line1.substring(index3 + <span class="number">1</span>, index4) <span class="comment">// /MyDemoWeb/web.jsp</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//得到jsp的名字</span></span><br><span class="line">          val jspName = line2.substring(line2.lastIndexOf(<span class="string">&quot;/&quot;</span>) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">          (jspName, line)</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//自定义分区规则 新建一个类</span></span><br><span class="line"></span><br><span class="line">    val rdd2 = rdd1.map(_._1).distinct().collect()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建分区规则</span></span><br><span class="line">    val myPartitioner = <span class="keyword">new</span> MyWebPartitioner(rdd2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//对rdd1进行分区</span></span><br><span class="line">    val rdd3 = rdd1.partitionBy(myPartitioner)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//输出</span></span><br><span class="line">    rdd3.saveAsTextFile(<span class="string">&quot;/users/macbook/TestInfo/1208/test_partition&quot;</span>)</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyWebPartitioner</span>(<span class="title">jspList</span> : <span class="title">Array</span>[<span class="title">String</span>]) <span class="keyword">extends</span> <span class="title">Partitioner</span></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//定义一个集合来保存分区的条件 即保存jsp分到哪个区</span></span><br><span class="line">  val partitionMap = <span class="keyword">new</span> HashMap[String,Int]()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> partId = <span class="number">0</span> <span class="comment">//分区号</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(jsp &lt;- jspList)&#123;</span><br><span class="line">    partitionMap.put(jsp,partId)</span><br><span class="line">    partId += <span class="number">1</span> <span class="comment">//分区号加一</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//返回有多少个分区</span></span><br><span class="line">  def numPartitions :Int = partitionMap.size</span><br><span class="line"></span><br><span class="line">  <span class="comment">//根据jsp 返回对应的分区</span></span><br><span class="line">  <span class="function">def <span class="title">getPartition</span><span class="params">(key:Any)</span>:Int </span>= partitionMap.getOrElse(key.toString(), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="5-结果："><a href="#5-结果：" class="headerlink" title="5.结果："></a>5.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTllMmFkODc1ODA3ZTBjZGEucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkCore/" rel="tag">SparkCore</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Core实战：解析Tomcat日志"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E8%A7%A3%E6%9E%90Tomcat%E6%97%A5%E5%BF%97/"
    >Spark Core实战：解析Tomcat日志</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/12/Spark%20Core%E5%AE%9E%E6%88%98%EF%BC%9A%E8%A7%A3%E6%9E%90Tomcat%E6%97%A5%E5%BF%97/" class="article-date">
  <time datetime="2020-03-12T06:00:00.000Z" itemprop="datePublished">2020-03-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-Tomcat日志格式："><a href="#1-Tomcat日志格式：" class="headerlink" title="1.Tomcat日志格式："></a>1.Tomcat日志格式：</h4><p>localhost_access_log.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/ HTTP/1.1&quot; 200 259</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/head.jsp HTTP/1.1&quot; 200 713</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/body.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:37 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] &quot;GET /MyDemoWeb/java.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:40 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:40 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:41 +0800] &quot;GET /MyDemoWeb/mysql.jsp HTTP/1.1&quot; 200 241</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:41 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:52 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:53 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] &quot;GET /MyDemoWeb/mysql.jsp HTTP/1.1&quot; 200 241</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:54 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:56 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:56 +0800] &quot;GET /MyDemoWeb/java.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:57 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:57 +0800] &quot;GET /MyDemoWeb/java.jsp HTTP/1.1&quot; 200 240</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:58 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:58 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:59 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:54:59 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:00 +0800] &quot;GET /MyDemoWeb/mysql.jsp HTTP/1.1&quot; 200 241</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:00 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:02 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span><br><span class="line">192.168.88.1 - - [30/Jul/2017:12:55:02 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span><br></pre></td></tr></table></figure>

<h4 id="2-需求："><a href="#2-需求：" class="headerlink" title="2.需求："></a>2.需求：</h4><p>找到访问量最高的两个网页</p>
<h4 id="3-分析："><a href="#3-分析：" class="headerlink" title="3.分析："></a>3.分析：</h4><ul>
<li>第一步：对网页的访问量求和   和WordCount类似</li>
<li>第二步：排序，降序</li>
</ul>
<h4 id="4-编写代码："><a href="#4-编写代码：" class="headerlink" title="4.编写代码："></a>4.编写代码：</h4><h5 id="1-添加依赖："><a href="#1-添加依赖：" class="headerlink" title="(1)添加依赖："></a>(1)添加依赖：</h5><p>pom.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-MyTomcatLogCount-scala"><a href="#2-MyTomcatLogCount-scala" class="headerlink" title="(2)MyTomcatLogCount.scala"></a>(2)MyTomcatLogCount.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1208</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 解析Tomcat日志</span></span><br><span class="line"><span class="comment"> * 192.168.88.1 - - [30/Jul/2017:12:54:41 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242</span></span><br><span class="line"><span class="comment">		192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">		需求：</span></span><br><span class="line"><span class="comment">		找到访问量最高的两个网页</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">		第一步：对网页的访问量求和   和WordCount类似</span></span><br><span class="line"><span class="comment">		第二步：排序，降序</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">object MyTomcatLogCount &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;My Tomcat Log Count&quot;</span>)</span><br><span class="line">    val sc = <span class="keyword">new</span> SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读入日志，解析，找到访问jsp网页</span></span><br><span class="line"><span class="comment">     * 192.168.88.1 - - [30/Jul/2017:12:54:42 +0800] &quot;GET /MyDemoWeb/web.jsp HTTP/1.1&quot; 200 239</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    val rdd1 = sc.textFile(<span class="string">&quot;/users/macbook/TestInfo/localhost_access_log.txt&quot;</span>)</span><br><span class="line">      .map(</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 找到网页名字</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 并计数</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * line 代表读进来的每一行数据</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        line =&gt; &#123;</span><br><span class="line">          <span class="comment">//解析字符串，找到jsp名字</span></span><br><span class="line">          <span class="comment">//得到两个双引号之间的东西</span></span><br><span class="line">          val index1 = line.indexOf(<span class="string">&quot;\&quot;&quot;</span>)</span><br><span class="line">          val index2 = line.lastIndexOf(<span class="string">&quot;\&quot;&quot;</span>)</span><br><span class="line">          val line1 = line.substring(index1+<span class="number">1</span>, index2) <span class="comment">// GET /MyDemoWeb/web.jsp HTTP/1.1</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//得到两个空格之间的东西</span></span><br><span class="line">          val index3 = line1.indexOf(<span class="string">&quot; &quot;</span>)</span><br><span class="line">          val index4 = line1.lastIndexOf(<span class="string">&quot; &quot;</span>)</span><br><span class="line">          val line2 = line1.substring(index3+<span class="number">1</span>, index4) <span class="comment">// /MyDemoWeb/web.jsp</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//得到jsp的名字</span></span><br><span class="line">          val jspName = line2.substring(line2.lastIndexOf(<span class="string">&quot;/&quot;</span>)+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">          (jspName,<span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 按照jsp的名字 进行聚合操作</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    val rdd2 = rdd1.reduceByKey(_+_)<span class="comment">//得到每个jsp的访问量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用value排序</span></span><br><span class="line">    val rdd3 = rdd2.sortBy(_._2,<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//取出访问量最高的两个网页</span></span><br><span class="line">    rdd3.take(<span class="number">2</span>).foreach(println)</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//销售  ：  勇气输出岗</span></span><br><span class="line">    <span class="comment">//技术 ： 头脑</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="5-运行结果："><a href="#5-运行结果：" class="headerlink" title="5.运行结果："></a>5.运行结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTA5MTljNGZjZjNhODNhY2UucG5n?x-oss-process=image/format,png" alt="运行结果"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SparkCore/" rel="tag">SparkCore</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/7/">上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/9/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2021
        <i class="ri-heart-fill heart_icon"></i> Movle
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="https://img-blog.csdnimg.cn/20200609161448519.jpg" alt="Movle"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>
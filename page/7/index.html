<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> Movle</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="https://img-blog.csdnimg.cn/20200609161448519.jpg" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/Shen-Yu/hexo-theme-ayer"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="https://img-blog.csdnimg.cn/2020060916514052.png" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">Movle</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['种一棵树，最好的时机是十年前，其次是现在', '人必有痴，而后有成', '今天，我没有浑浑噩噩的度过'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Spark Streaming实战：处理来自flume pull方式发来的数据"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86%E6%9D%A5%E8%87%AAflume%20pull%E6%96%B9%E5%BC%8F%E5%8F%91%E6%9D%A5%E7%9A%84%E6%95%B0%E6%8D%AE/"
    >SparkStreaming实战：处理来自flume pull方式发来的数据</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86%E6%9D%A5%E8%87%AAflume%20pull%E6%96%B9%E5%BC%8F%E5%8F%91%E6%9D%A5%E7%9A%84%E6%95%B0%E6%8D%AE/" class="article-date">
  <time datetime="2020-03-15T11:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>处理来自flume pull方式发来的数据</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming-flume --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-flume_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-option2"><a href="#2-option2" class="headerlink" title="(2)option2"></a>(2)option2</h5><p>option2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#定义agent名，source，channel，sink的名称</span><br><span class="line">a1.sources=r1</span><br><span class="line">a1.channels =c1</span><br><span class="line">a1.sinks=k1</span><br><span class="line"></span><br><span class="line">#具体定义source</span><br><span class="line">a1.sources.r1.type= spooldir</span><br><span class="line">a1.sources.r1.spoolDir= /opt/TestFolder/logs</span><br><span class="line">a1.sources.r1.fileSuffix = .COMPLETED</span><br><span class="line"></span><br><span class="line">#具体定义channel1</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity=10000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line">#具体定义sink</span><br><span class="line">a1.sinks.k1.type = org.apache.spark.streaming.flume.sink.SparkSink</span><br><span class="line">a1.sinks.k1.channels =c1</span><br><span class="line">a1.sinks.k1.hostname=192.168.31.132</span><br><span class="line">a1.sinks.k1.port=1234</span><br><span class="line"></span><br><span class="line">#组装source, channel,sink</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel =c1</span><br></pre></td></tr></table></figure>

<h5 id="3-FlumeLogPul-scala"><a href="#3-FlumeLogPul-scala" class="headerlink" title="(3)FlumeLogPul.scala"></a>(3)FlumeLogPul.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.flume.FlumeUtils</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.StorageLevel</span><br><span class="line"></span><br><span class="line">object FlumeLogPull &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">&quot;FlumeLogPull&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf,Seconds(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    val flumeEvent = FlumeUtils.createPollingStream(ssc, <span class="string">&quot;192.168.31.211&quot;</span>, <span class="number">1234</span>,StorageLevel.MEMORY_ONLY_SER)</span><br><span class="line"></span><br><span class="line">    val lineDStream = flumeEvent.map( e =&gt; &#123;</span><br><span class="line">      <span class="keyword">new</span> String(e.event.getBody.array)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    lineDStream.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="3-将spark-streaming-flume-sink-2-11-2-1-0-jar拷贝到flume的jar目录下"><a href="#3-将spark-streaming-flume-sink-2-11-2-1-0-jar拷贝到flume的jar目录下" class="headerlink" title="3.将spark-streaming-flume-sink_2.11-2.1.0.jar拷贝到flume的jar目录下"></a>3.将spark-streaming-flume-sink_2.11-2.1.0.jar拷贝到flume的jar目录下</h4><h4 id="4-运行："><a href="#4-运行：" class="headerlink" title="4.运行："></a>4.运行：</h4><h5 id="1-运行SparkStreaming程序："><a href="#1-运行SparkStreaming程序：" class="headerlink" title="(1)运行SparkStreaming程序："></a>(1)运行SparkStreaming程序：</h5><h5 id="2-开启flume"><a href="#2-开启flume" class="headerlink" title="(2)开启flume"></a>(2)开启flume</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/option2 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<h4 id="5-结果："><a href="#5-结果：" class="headerlink" title="5.结果："></a>5.结果：</h4> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Streaming实战：处理来自flume push方式发来的数据"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86%E6%9D%A5%E8%87%AAflume%20push%E6%96%B9%E5%BC%8F%E5%8F%91%E6%9D%A5%E7%9A%84%E6%95%B0%E6%8D%AE/"
    >SparkStreaming实战：处理来自flume push方式发来的数据</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86%E6%9D%A5%E8%87%AAflume%20push%E6%96%B9%E5%BC%8F%E5%8F%91%E6%9D%A5%E7%9A%84%E6%95%B0%E6%8D%AE/" class="article-date">
  <time datetime="2020-03-15T10:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>SparkStreaming处理来自flume push方式发来的数据,即flume将数据推给spark Streaming</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming-flume --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-flume_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-flume文件option"><a href="#2-flume文件option" class="headerlink" title="(2)flume文件option"></a>(2)flume文件option</h5><p>option</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#bin/flume-ng agent -n a1 -f myconf/option -c conf -Dflume.root.logger=INFO,console</span><br><span class="line">#定义agent名，source，channel，sink的名称</span><br><span class="line">a1.sources=r1</span><br><span class="line">a1.channels =c1</span><br><span class="line">a1.sinks=k1</span><br><span class="line"></span><br><span class="line">#具体定义source</span><br><span class="line">a1.sources.r1.type= spooldir</span><br><span class="line">a1.sources.r1.spoolDir= /opt/TestFolder/logs</span><br><span class="line"></span><br><span class="line">#具体定义channel1</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity=10000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line">#具体定义sink</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.channels =c1</span><br><span class="line">a1.sinks.k1.hostname=192.168.31.211</span><br><span class="line">a1.sinks.k1.port=1236</span><br><span class="line"></span><br><span class="line">#组装source, channel,sink</span><br><span class="line"></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel =c1</span><br></pre></td></tr></table></figure>
<h5 id="3-MyFlumeStream-scala"><a href="#3-MyFlumeStream-scala" class="headerlink" title="(3) MyFlumeStream.scala"></a>(3) MyFlumeStream.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.flume.FlumeUtils</span><br><span class="line"></span><br><span class="line">object MyFlumeStream &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">&quot;MyFlumeStream&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf,Seconds(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建 flume event 从 flume中接收push来的数据 ---&gt; 也是DStream</span></span><br><span class="line">    <span class="comment">//flume将数据push到了 ip 和 端口中</span></span><br><span class="line">    val flumeEventDstream = FlumeUtils.createStream(ssc, <span class="string">&quot;192.168.1.121&quot;</span>, <span class="number">1236</span>)</span><br><span class="line"></span><br><span class="line">    val lineDStream = flumeEventDstream.map( e =&gt; &#123;</span><br><span class="line">      <span class="keyword">new</span> String(e.event.getBody.array)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    lineDStream.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-运行："><a href="#3-运行：" class="headerlink" title="3.运行："></a>3.运行：</h4><h5 id="1-运行SparkStreaming程序："><a href="#1-运行SparkStreaming程序：" class="headerlink" title="(1)运行SparkStreaming程序："></a>(1)运行SparkStreaming程序：</h5><h5 id="2-开启flume"><a href="#2-开启flume" class="headerlink" title="(2)开启flume"></a>(2)开启flume</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f jobconf/option -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<h4 id="4-向-opt-TestFolder-logs中添加数据，查看结果："><a href="#4-向-opt-TestFolder-logs中添加数据，查看结果：" class="headerlink" title="4.向/opt/TestFolder/logs中添加数据，查看结果："></a>4.向/opt/TestFolder/logs中添加数据，查看结果：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp a.txt /opt/TestFolder/logs</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWU0ZjFmZjcxNDA4YmE0OWQucG5n?x-oss-process=image/format,png" alt="添加数据"></p>
<h4 id="5-查看结果"><a href="#5-查看结果" class="headerlink" title="5.查看结果"></a>5.查看结果</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTg3NjUxMjg1MDE2YmQ0MWYucG5n?x-oss-process=image/format,png" alt="结果"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Streaming实战：处理RDD队列流"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86RDD%E9%98%9F%E5%88%97%E6%B5%81/"
    >SparkStreaming实战：处理RDD队列流</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86RDD%E9%98%9F%E5%88%97%E6%B5%81/" class="article-date">
  <time datetime="2020-03-15T09:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>利用SparkStreaming处理RDD队列流</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-RDDQueueStream-scala"><a href="#2-RDDQueueStream-scala" class="headerlink" title="(2)RDDQueueStream.scala"></a>(2)RDDQueueStream.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.Queue</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.RDD</span><br><span class="line"></span><br><span class="line">object RDDQueueStream &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">&quot;RDDQueueStream&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf,Seconds(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//需要一个RDD队列</span></span><br><span class="line">    val rddQueue = <span class="keyword">new</span> Queue[RDD[Int]]()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>( i &lt;- <span class="number">1</span> to <span class="number">3</span>)&#123;</span><br><span class="line">      rddQueue += ssc.sparkContext.makeRDD(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">      Thread.sleep(<span class="number">5000</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//从队列中接收数据 创建DStream</span></span><br><span class="line">    val inputDStream = ssc.queueStream(rddQueue)</span><br><span class="line"></span><br><span class="line">    val result = inputDStream.map(x=&gt;(x,x*<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    result.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-运行："><a href="#3-运行：" class="headerlink" title="3.运行："></a>3.运行：</h4><h4 id="4-结果："><a href="#4-结果：" class="headerlink" title="4.结果："></a>4.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThlZWFkNzdlOWZlNzBhNDMucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Streaming实战：处理文件流"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%B5%81/"
    >SparkStreaming实战：处理文件流</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E6%B5%81/" class="article-date">
  <time datetime="2020-03-15T08:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>利用SparkStreaming处理文件流：</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-FileStreaming-scala"><a href="#2-FileStreaming-scala" class="headerlink" title="(2)FileStreaming.scala"></a>(2)FileStreaming.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1211</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.StorageLevel</span><br><span class="line"></span><br><span class="line">object FileStreaming &#123;</span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//local[2]代表开启两个线程</span></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">&quot;MyNetwordWordCount&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//接收两个参数，第一个conf，第二个是采样时间间隔</span></span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf, Seconds(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//监控目录 如果文件系统发生变化 就读取进来</span></span><br><span class="line">    val lines = ssc.textFileStream(<span class="string">&quot;/Users/macbook/TestInfo/test_file_stream&quot;</span>)</span><br><span class="line"></span><br><span class="line">    lines.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h4 id="3-运行"><a href="#3-运行" class="headerlink" title="3.运行"></a>3.运行</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWRiNDkxMjllNTQ2Zjc3ZWUucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-结果："><a href="#4-结果：" class="headerlink" title="4.结果："></a>4.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTlkMmRjOWMyMTdhNjUwZmMucG5n?x-oss-process=image/format,png" alt="image.png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Streaming实战：集成Spark SQL，使用SQL语句进行WordCount"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E9%9B%86%E6%88%90Spark%20SQL%EF%BC%8C%E4%BD%BF%E7%94%A8SQL%E8%AF%AD%E5%8F%A5%E8%BF%9B%E8%A1%8CWordCount/"
    >SparkStearming实战：集成Spark SQL，使用SQL语句进行WordCount</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E9%9B%86%E6%88%90Spark%20SQL%EF%BC%8C%E4%BD%BF%E7%94%A8SQL%E8%AF%AD%E5%8F%A5%E8%BF%9B%E8%A1%8CWordCount/" class="article-date">
  <time datetime="2020-03-15T06:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>集成Spark SQL，使用SQL语句进行WordCount</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-MyNetwordWordCountWithSQL-scala"><a href="#2-MyNetwordWordCountWithSQL-scala" class="headerlink" title="(2)MyNetwordWordCountWithSQL.scala"></a>(2)MyNetwordWordCountWithSQL.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.StorageLevel</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line">object MyNetwordWordCountWithSQL &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local[2]&quot;</span>).setAppName(<span class="string">&quot;MyNetwordWordCountWithSQL&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf,Seconds(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    val lines = ssc.socketTextStream(<span class="string">&quot;192.168.1.121&quot;</span>,<span class="number">1235</span>,StorageLevel.MEMORY_ONLY)</span><br><span class="line"></span><br><span class="line">    val words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//集成Spark SQL 使用SQL语句进行WordCount</span></span><br><span class="line">    words.foreachRDD( rdd =&gt; &#123;</span><br><span class="line"></span><br><span class="line">      val spark = SparkSession.builder().config(rdd.sparkContext.getConf).getOrCreate()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">import</span> spark.implicits._</span><br><span class="line">      val df1 = rdd.toDF(<span class="string">&quot;word&quot;</span>)</span><br><span class="line"></span><br><span class="line">      df1.createOrReplaceTempView(<span class="string">&quot;words&quot;</span>)</span><br><span class="line"></span><br><span class="line">      spark.sql(<span class="string">&quot;select word , count(1) from words group by word&quot;</span>).show()</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-运行："><a href="#3-运行：" class="headerlink" title="3.运行："></a>3.运行：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTdjMjdmMmRiNWVlZDUwOGMucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-结果："><a href="#4-结果：" class="headerlink" title="4.结果："></a>4.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ0YmIwNTFkOGY5MmY1ZjIucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Streaming实战：窗口操作，每10秒，把过去30秒的数据取出来(读取端口号1235中的数据)"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E7%AA%97%E5%8F%A3%E6%93%8D%E4%BD%9C%EF%BC%8C%E6%AF%8F10%E7%A7%92%EF%BC%8C%E6%8A%8A%E8%BF%87%E5%8E%BB30%E7%A7%92%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%96%E5%87%BA%E6%9D%A5(%E8%AF%BB%E5%8F%96%E7%AB%AF%E5%8F%A3%E5%8F%B71235%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE)/"
    >Spark Streaming实战：窗口操作，每10秒，把过去30秒的数据取出来(读取端口号1235中的数据)</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E7%AA%97%E5%8F%A3%E6%93%8D%E4%BD%9C%EF%BC%8C%E6%AF%8F10%E7%A7%92%EF%BC%8C%E6%8A%8A%E8%BF%87%E5%8E%BB30%E7%A7%92%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%96%E5%87%BA%E6%9D%A5(%E8%AF%BB%E5%8F%96%E7%AB%AF%E5%8F%A3%E5%8F%B71235%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE)/" class="article-date">
  <time datetime="2020-03-15T04:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>窗口操作，每10秒，把过去30秒的数据取出来</p>
<ul>
<li>窗口长度：30秒</li>
<li>滑动距离：10秒</li>
</ul>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-MyNetWorkWordCountByWindow-scala"><a href="#2-MyNetWorkWordCountByWindow-scala" class="headerlink" title="(2)MyNetWorkWordCountByWindow.scala"></a>(2)MyNetWorkWordCountByWindow.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1211</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.StorageLevel</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 需求：每10秒，把过去30秒的数据取出来</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 窗口长度：30秒</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 滑动距离：10秒</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">object MyNetWorkWordCountByWindow &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">&quot;MyNetWorkWordCountByWindow&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf,Seconds(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    val lines = ssc.socketTextStream(<span class="string">&quot;192.168.1.121&quot;</span>, <span class="number">1235</span>, StorageLevel.MEMORY_ONLY)</span><br><span class="line"></span><br><span class="line">    val words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>)).map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * reduce By Key And Window</span></span><br><span class="line"><span class="comment">     * 三个参数</span></span><br><span class="line"><span class="comment">     * 1、要进行什么操作</span></span><br><span class="line"><span class="comment">     * 2、窗口的大小</span></span><br><span class="line"><span class="comment">     * 3、窗口滑动的距离</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    val result = words.reduceByKeyAndWindow((x:Int,y:Int)=&gt;(x+y),Seconds(<span class="number">30</span>),Seconds(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    result.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-运行：往端口中发送数据"><a href="#3-运行：往端口中发送数据" class="headerlink" title="3.运行：往端口中发送数据"></a>3.运行：往端口中发送数据</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTc2MmZiN2RhYjBkMTRlMjAucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-结果"><a href="#4-结果" class="headerlink" title="4.结果"></a>4.结果</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWZhMTEyNzljZjNjNGM0MDUucG5n?x-oss-process=image/format,png" alt="image.png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Streaming实战：设置检查点，写一个wordcount程序并计数，计算端口号1235中的信息"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E8%AE%BE%E7%BD%AE%E6%A3%80%E6%9F%A5%E7%82%B9%EF%BC%8C%E5%86%99%E4%B8%80%E4%B8%AAwordcount%E7%A8%8B%E5%BA%8F%E5%B9%B6%E8%AE%A1%E6%95%B0%EF%BC%8C%E8%AE%A1%E7%AE%97%E7%AB%AF%E5%8F%A3%E5%8F%B71235%E4%B8%AD%E7%9A%84%E4%BF%A1%E6%81%AF/"
    >Spark Streaming实战：设置检查点，写一个wordcount程序并计数，计算端口号1235中的信息</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E8%AE%BE%E7%BD%AE%E6%A3%80%E6%9F%A5%E7%82%B9%EF%BC%8C%E5%86%99%E4%B8%80%E4%B8%AAwordcount%E7%A8%8B%E5%BA%8F%E5%B9%B6%E8%AE%A1%E6%95%B0%EF%BC%8C%E8%AE%A1%E7%AE%97%E7%AB%AF%E5%8F%A3%E5%8F%B71235%E4%B8%AD%E7%9A%84%E4%BF%A1%E6%81%AF/" class="article-date">
  <time datetime="2020-03-15T04:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>用spark Streaming写一个wordcount程序，计算发往端口号1235中的信息(单词计数)</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-MyTotalNetworkWordCount-scala"><a href="#2-MyTotalNetworkWordCount-scala" class="headerlink" title="(2)MyTotalNetworkWordCount.scala"></a>(2)MyTotalNetworkWordCount.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1211</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.StorageLevel</span><br><span class="line"></span><br><span class="line">object MyTotalNetworkWordCount &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local[2]&quot;</span>).setAppName(<span class="string">&quot;MyTotalNetworkWordCount&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf,Seconds(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置检查点目录，保存之前的状态信息</span></span><br><span class="line">    ssc.checkpoint(<span class="string">&quot;hdfs://192.168.1.121:9000/TestFile/chkp0826&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val lines = ssc.socketTextStream(<span class="string">&quot;192.168.1.121&quot;</span>, <span class="number">1235</span>, StorageLevel.MEMORY_ONLY)</span><br><span class="line"></span><br><span class="line">    val words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">    val wordPair = words.map((_,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 两个参数：</span></span><br><span class="line"><span class="comment">     * 第一个参数：当前的值是多少</span></span><br><span class="line"><span class="comment">     * 第二个参数：之前的结果是多少</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    val addFunc = (curreValues:Seq[Int],previousValues:Option[Int]) =&gt; &#123;</span><br><span class="line">      <span class="comment">//进行累加运算</span></span><br><span class="line">      <span class="comment">// 1、把当前值的序列进行累加</span></span><br><span class="line">      val currentTotal = curreValues.sum</span><br><span class="line"></span><br><span class="line">      <span class="comment">//2、在之前的值上再累加</span></span><br><span class="line"></span><br><span class="line">      Some( currentTotal + previousValues.getOrElse(<span class="number">0</span>) )</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//进行累加运算</span></span><br><span class="line">    val total = wordPair.updateStateByKey(addFunc)</span><br><span class="line"></span><br><span class="line">    total.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="3-运行程序，并往端口号1235发送信息："><a href="#3-运行程序，并往端口号1235发送信息：" class="headerlink" title="3.运行程序，并往端口号1235发送信息："></a>3.运行程序，并往端口号1235发送信息：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThlNmUyYTFiNTk2YTdmNWYucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-结果："><a href="#4-结果：" class="headerlink" title="4.结果："></a>4.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTUzNTc3ZTZiYzc0OGM4NzUucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark Streaming实战：写一个wordcount程序，统计从netcat中向端口发送的数据"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%86%99%E4%B8%80%E4%B8%AAwordcount%E7%A8%8B%E5%BA%8F%EF%BC%8C%E7%BB%9F%E8%AE%A1%E4%BB%8Enetcat%E4%B8%AD%E5%90%91%E7%AB%AF%E5%8F%A3%E5%8F%91%E9%80%81%E7%9A%84%E6%95%B0%E6%8D%AE/"
    >Spark Streaming实战:写一个wordcount程序，统计从netcat中向端口发送的数据</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/15/Spark%20Streaming%E5%AE%9E%E6%88%98%EF%BC%9A%E5%86%99%E4%B8%80%E4%B8%AAwordcount%E7%A8%8B%E5%BA%8F%EF%BC%8C%E7%BB%9F%E8%AE%A1%E4%BB%8Enetcat%E4%B8%AD%E5%90%91%E7%AB%AF%E5%8F%A3%E5%8F%91%E9%80%81%E7%9A%84%E6%95%B0%E6%8D%AE/" class="article-date">
  <time datetime="2020-03-15T03:00:00.000Z" itemprop="datePublished">2020-03-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>通过spark streaming统计端口号1234中的信息</p>
<h4 id="2-编写代码："><a href="#2-编写代码：" class="headerlink" title="2.编写代码："></a>2.编写代码：</h4><h5 id="1-添加依赖："><a href="#1-添加依赖：" class="headerlink" title="(1)添加依赖："></a>(1)添加依赖：</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">      <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>记得去掉spark-streaming中的<scope>provided</scope></p>
<h5 id="2-MyNetwordWordCount-scala"><a href="#2-MyNetwordWordCount-scala" class="headerlink" title="(2)MyNetwordWordCount.scala"></a>(2)MyNetwordWordCount.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> day1211</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.StreamingContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.Seconds</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.StorageLevel</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 知识点汇总：</span></span><br><span class="line"><span class="comment"> * 1、创建StreamingContext--&gt;本质，核心：创建DStream</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 2、DStream的表现形式：就是一个RDD</span></span><br><span class="line"><span class="comment"> * 	操作DSteam和操作RDD是一样的。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 3、使用DStream把连续的数据流编程不连续的RDD</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">object MyNetwordWordCount &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>, <span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.eclipse.jetty.server&quot;</span>).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//local[2]代表开启两个线程</span></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">&quot;MyNetwordWordCount&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//接收两个参数，第一个conf，第二个是采样时间间隔</span></span><br><span class="line">    val ssc = <span class="keyword">new</span> StreamingContext(conf,Seconds(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建DStream 从netcat服务器上接收数据 因为接收字符串，所以使用textStream</span></span><br><span class="line">    val lines = ssc.socketTextStream(<span class="string">&quot;192.168.1.121&quot;</span>, <span class="number">1234</span>, StorageLevel.MEMORY_ONLY)</span><br><span class="line"></span><br><span class="line">    val words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line">    val wordCount = words.map((_,<span class="number">1</span>)).reduceByKey(_+_)</span><br><span class="line">    <span class="comment">//    val wordCount = words.transform(x =&gt; x.map((_,1))).reduceByKey(_+_)</span></span><br><span class="line"></span><br><span class="line">    wordCount.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//等待任务结束</span></span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-运行此程序，同时用netcat向1234端口号中发送信息，"><a href="#3-运行此程序，同时用netcat向1234端口号中发送信息，" class="headerlink" title="3.运行此程序，同时用netcat向1234端口号中发送信息，"></a>3.运行此程序，同时用netcat向1234端口号中发送信息，</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWIxM2Q3NTIzMjBkNzk0YWIucG5n?x-oss-process=image/format,png" alt="1"></p>
<h4 id="4-结果："><a href="#4-结果：" class="headerlink" title="4.结果："></a>4.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTE2OWFkYWI4MzM4ODc2ZDcucG5n?x-oss-process=image/format,png" alt="1"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-Streaming/" rel="tag">Spark Streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark SQL实战：UDF与UDAF的使用"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9AUDF%E4%B8%8EUDAF%E7%9A%84%E4%BD%BF%E7%94%A8/"
    >Spark SQL实战之UDF与UDAF的使用</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9AUDF%E4%B8%8EUDAF%E7%9A%84%E4%BD%BF%E7%94%A8/" class="article-date">
  <time datetime="2020-03-13T11:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-概念："><a href="#1-概念：" class="headerlink" title="1.概念："></a>1.概念：</h4><p>UDF就是用户自定义的函数<br>UDAF就是用户自定义的聚合函数</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-SparkSQLUDFUDAF-scala"><a href="#2-SparkSQLUDFUDAF-scala" class="headerlink" title="(2)SparkSQLUDFUDAF.scala"></a>(2)SparkSQLUDFUDAF.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.sqlshizhan</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkContext</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123; Row, SQLContext &#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructField</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StringType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.UserDefinedAggregateFunction</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.MutableAggregationBuffer</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.DataType</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.IntegerType</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> SparkSQLUDFUDAF</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@MethodDesc</span>: SparkSQL UDF与UDAF的使用</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Movle</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 5/18/20 10:44 下午</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Email</span> movle_xjk@foxmail.com</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line">object SparkSQLUDFUDAF &#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line"></span><br><span class="line">    val conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;SparkSQLUDFUDAF&quot;</span>)</span><br><span class="line"></span><br><span class="line">    val sc = <span class="keyword">new</span> SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val sqlContext = <span class="keyword">new</span> SQLContext(sc)</span><br><span class="line"></span><br><span class="line">    val bigData = Array(<span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;spark&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建Dataframe</span></span><br><span class="line">    val bigDataRDD = sc.parallelize(bigData)</span><br><span class="line"></span><br><span class="line">    val bigDataRDDRow = bigDataRDD.map(item =&gt; Row(item))</span><br><span class="line"></span><br><span class="line">    val structType = StructType(Array(</span><br><span class="line">      <span class="keyword">new</span> StructField(<span class="string">&quot;word&quot;</span>, StringType)))</span><br><span class="line"></span><br><span class="line">    val bigDataDF = sqlContext.createDataFrame(bigDataRDDRow, structType)</span><br><span class="line"></span><br><span class="line">    bigDataDF.createOrReplaceTempView(<span class="string">&quot;bigDataTable&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//UDF 最多22个输入参数</span></span><br><span class="line">    sqlContext.udf.register(<span class="string">&quot;computeLength&quot;</span>,(input:String,input2:String) =&gt; input.length())</span><br><span class="line"></span><br><span class="line">    sqlContext.sql(<span class="string">&quot;select word,computeLength(word,word) from bigDataTable&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    sqlContext.udf.register(<span class="string">&quot;wordcount&quot;</span>, <span class="keyword">new</span> MyUDAF)</span><br><span class="line"></span><br><span class="line">    sqlContext.sql(<span class="string">&quot;select word,wordcount(word) as count from bigDataTable group by word&quot;</span>).show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyUDAF</span> <span class="keyword">extends</span> <span class="title">UserDefinedAggregateFunction</span></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 该方法指定具体输入数据的类型</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def inputSchema: StructType = StructType(Array(StructField(<span class="string">&quot;input&quot;</span>, StringType, <span class="keyword">true</span>)))</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 在进行聚合操作的时候所要处理的数据的结果的类型</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def bufferSchema: StructType = StructType(Array(StructField(<span class="string">&quot;count&quot;</span>, IntegerType, <span class="keyword">true</span>)))</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 指定UDAF函数计算后返回的结果类型</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def dataType: DataType = IntegerType</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 确保一致性，一般都用true</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  override def deterministic: Boolean = <span class="keyword">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 在Aggregate之前每组数据的初始化结果</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">initialize</span><span class="params">(buffer: MutableAggregationBuffer)</span>: Unit </span>= &#123; buffer(<span class="number">0</span>) = <span class="number">0</span> &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 在进行聚合的时候，每当有新的值进来，对分组后的聚合如何进行计算</span></span><br><span class="line"><span class="comment">   * 本地的聚合操作，相当于Hadoop MapReduce模型中的Combiner</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> input</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">update</span><span class="params">(buffer: MutableAggregationBuffer, input: Row)</span>: Unit </span>= &#123;</span><br><span class="line">    buffer(<span class="number">0</span>) = buffer.getAs[Int](<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 最后在分布式节点进行Local Reduce完成后需要进行全局级别的Merge操作</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer1</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer2</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">merge</span><span class="params">(buffer1: MutableAggregationBuffer, buffer2: Row)</span>: Unit </span>= &#123;</span><br><span class="line">    buffer1(<span class="number">0</span>) = buffer1.getAs[Int](<span class="number">0</span>) + buffer2.getAs[Int](<span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 返回UDAF最后的计算结果</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffer</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function">override def <span class="title">evaluate</span><span class="params">(buffer: Row)</span>: Any </span>= buffer.getAs[Int](<span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Spark SQL实战：SparkSQL exmple"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9ASparkSQL%20exmple/"
    >Spark SQL实战：SparkSQL exmple</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/13/Spark%20SQL%E5%AE%9E%E6%88%98%EF%BC%9ASparkSQL%20exmple/" class="article-date">
  <time datetime="2020-03-13T10:00:00.000Z" itemprop="datePublished">2020-03-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-需求："><a href="#1-需求：" class="headerlink" title="1.需求："></a>1.需求：</h4><p>使用Spark SQL，读取文件并查询数据表</p>
<h4 id="2-代码："><a href="#2-代码：" class="headerlink" title="2.代码："></a>2.代码：</h4><h5 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="(1)pom.xml"></a>(1)pom.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="2-SparkSQLExample-scala"><a href="#2-SparkSQLExample-scala" class="headerlink" title="(2)SparkSQLExample.scala"></a>(2)SparkSQLExample.scala</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> spark.sqlshizhan</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;Level, Logger&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span> SparkSQLExample</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@MethodDesc</span>: TODO SparkSQLExample功能介绍</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> Movle</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span> 5/18/20 9:34 下午</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Email</span> movle_xjk@foxmail.com</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Student1</span><span class="params">(sno:String,sname:String,ssex:String,sbirthday:String,sclass:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Course</span><span class="params">(cno:String,cname:String,tno:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Score</span><span class="params">(sno:String,cno:String,degree:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">case</span> class <span class="title">Teacher</span><span class="params">(tno:String,tname:String,tsex:String,tbirthday:String,tprof:String,tdepart:String)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">import</span> java.text.SimpleDateFormat</span></span><br><span class="line"><span class="function">object SparkSQLExample </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">def <span class="title">main</span><span class="params">(args: Array[String])</span>: Unit </span>= &#123;</span><br><span class="line">    System.setProperty(<span class="string">&quot;hadoop.home.dir&quot;</span>,<span class="string">&quot;/Users/macbook/Documents/hadoop/hadoop-2.8.4&quot;</span>)</span><br><span class="line"></span><br><span class="line">    Logger.getLogger(<span class="string">&quot;org.apache.spark&quot;</span>).setLevel(Level.ERROR)</span><br><span class="line">    <span class="comment">//Logger.getLogger(&quot;org.eclipse.jetty.server&quot;).setLevel(Level.OFF)</span></span><br><span class="line"></span><br><span class="line">    <span class="function">def <span class="title">getDate</span><span class="params">(time: String)</span> </span>= &#123;</span><br><span class="line">      val now: Long = System.currentTimeMillis()</span><br><span class="line">      val df: SimpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(time)</span><br><span class="line">      df.format(now)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val spark = SparkSession.builder().master(<span class="string">&quot;local&quot;</span>).appName(<span class="string">&quot;SparkSQLExample&quot;</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.sqlContext.implicits._</span><br><span class="line"></span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Student.csv&quot;</span>)</span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map(x=&gt;Student1(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>),x(<span class="number">3</span>),x(<span class="number">4</span>)))</span><br><span class="line">      .toDF</span><br><span class="line">      .createOrReplaceTempView(<span class="string">&quot;Student1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Course.csv&quot;</span>)</span><br><span class="line">        .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        .map(x =&gt; Course(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>)))</span><br><span class="line">        .toDF</span><br><span class="line">        .createOrReplaceTempView(<span class="string">&quot;Course&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Score.csv&quot;</span>)</span><br><span class="line">        .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        .map(x =&gt; Score(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>)))</span><br><span class="line">        .toDF</span><br><span class="line">        .createOrReplaceTempView(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line">    spark.sparkContext.textFile(<span class="string">&quot;/users/macbook/TestInfo/Teacher.csv&quot;</span>)</span><br><span class="line">        .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">        .map(x =&gt; Teacher(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>),x(<span class="number">3</span>),x(<span class="number">4</span>),x(<span class="number">5</span>)))</span><br><span class="line">        .toDF</span><br><span class="line">        .createOrReplaceTempView(<span class="string">&quot;Teacher&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询整个teacher表</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from Teacher&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查询Student表中所有记录的sname ssex class列</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sname,ssex,sclass from student&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询教师表中不重复的depart列</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select distinct tdepart from teacher&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line">    spark.sql(<span class="string">&quot;select tdepart from teacher group by tdepart&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score表中成绩在60 80 之间的所有记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree &gt;= 60 and degree &lt;= 80&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree between 60 and 80&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score表中成绩为 85 86 或 88 的记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree = &#x27;85&#x27; or degree=&#x27;86&#x27; OR degree=&#x27;88&#x27;&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where degree =85 or degree=86 OR degree=88&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//以class降序、升序排列查询</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from student order by sclass desc&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from student order by sclass&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//以cno升序 degree降序查询score表中的数据</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score t order by t.sno asc, t.degree desc&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询Score表中的最高分的学生学号和课程</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score order by Int(degree) desc limit 1&quot;</span>).show()</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score order by Int(degree) desc&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询每门课的平均成绩</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select cno,avg(degree) from score group by cno&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score表中至少有5名学生选修的课，并且名字以 3 开头的课程 的平均分数</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select cno,avg(degree) from score where cno like &#x27;3%&#x27; group by cno having count(cno) &gt;= 5&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询所有学生中的sname cname degree</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select s.sname, t.degree,c.cname from score t &quot;</span> +</span><br><span class="line">      <span class="string">&quot;join student s on t.sno=s.sno &quot;</span> +</span><br><span class="line">      <span class="string">&quot;join course c on c.cno=t.cno&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询score中选择多门课程的同学中，分数为非最高分成绩的记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from score where &quot;</span> +</span><br><span class="line">      <span class="string">&quot;sno in (select sno from score t group by t.sno having count(1) &gt; 1) &quot;</span> +</span><br><span class="line">      <span class="string">&quot; and degree != (select max(degree) from score)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询和学号为108的同学同年出生的所有学生的sno sname sbirthday 列</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sno,sname,sbirthday from student where substring(sbirthday,0,4) = (&quot;</span> +</span><br><span class="line">      <span class="string">&quot; select substring(t.sbirthday,0,4) from student t where sno=&#x27;108&#x27;)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询选修某课程的同学人数多于5人的教师姓名</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select tname from teacher e &quot;</span> +</span><br><span class="line">      <span class="string">&quot; join course c on e.tno = c.tno &quot;</span> +</span><br><span class="line">      <span class="string">&quot; join (select cno from score group by cno having count(cno) &gt; 5) t on c.cno = t.cno&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询成绩比该课程平均成绩低的同学的成绩表</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select s.* from score s where s.degree &lt; (select avg(degree) from score c where s.cno = c.cno)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询所有没有讲课的教师的tname 和 depart</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select tname , tdepart from teacher t where t.tno not in (select tno from course c where c.cno in (select cno from score))&quot;</span>).show(<span class="keyword">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询至少有2名男生的班号</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sclass from student t where ssex=&#x27;male&#x27; group by sclass having count(ssex) &gt;= 2&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询student表中不姓 王 的同学记录</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from student t where sname not like(&#x27;Wang%&#x27;)&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询student表中每个学生的姓名和年龄</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select sname, (cast(&quot;</span> + getDate(<span class="string">&quot;yyyy&quot;</span>) + <span class="string">&quot; as int) - cast(substring(sbirthday,0,4) as int)) as age from student t&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="3-结果："><a href="#3-结果：" class="headerlink" title="3.结果："></a>3.结果：</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWZkNjQ4ZTg2ZTQ0NjQ0MjMucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark%E5%AE%9E%E6%88%98/" rel="tag">Spark实战</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/6/">上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/8/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2021
        <i class="ri-heart-fill heart_icon"></i> Movle
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="https://img-blog.csdnimg.cn/20200609161448519.jpg" alt="Movle"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>
<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> Movle</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="https://img-blog.csdnimg.cn/20200609161448519.jpg" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/Shen-Yu/hexo-theme-ayer"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="https://img-blog.csdnimg.cn/2020060916514052.png" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">Movle</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['种一棵树，最好的时机是十年前，其次是现在', '人必有痴，而后有成', '今天，我没有浑浑噩噩的度过'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Hive之压缩和存储"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E4%B9%8B%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%AD%98%E5%82%A8/"
    >Hive之压缩和存储</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E4%B9%8B%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%AD%98%E5%82%A8/" class="article-date">
  <time datetime="2019-07-15T14:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-Hadoop源码编译支持Snappy压缩"><a href="#一-Hadoop源码编译支持Snappy压缩" class="headerlink" title="一.Hadoop源码编译支持Snappy压缩"></a>一.Hadoop源码编译支持Snappy压缩</h3><h4 id="1-资源准备"><a href="#1-资源准备" class="headerlink" title="1.资源准备"></a>1.资源准备</h4><h5 id="1-CentOS联网"><a href="#1-CentOS联网" class="headerlink" title="(1).CentOS联网"></a>(1).CentOS联网</h5><p>配置CentOS能连接外网。Linux虚拟机ping <a target="_blank" rel="noopener" href="http://www.baidu.com是畅通的/">www.baidu.com是畅通的</a></p>
<p>注意：采用root角色编译，减少文件夹权限出现问题</p>
<h6 id="2-jar包准备-hadoop源码、JDK8-、maven、protobuf"><a href="#2-jar包准备-hadoop源码、JDK8-、maven、protobuf" class="headerlink" title="(2).jar包准备(hadoop源码、JDK8 、maven、protobuf)"></a>(2).jar包准备(hadoop源码、JDK8 、maven、protobuf)</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(a)hadoop-2.8.4-src.tar.gz</span><br><span class="line">(b)jdk-8u144-linux-x64.tar.gz</span><br><span class="line">(c)snappy-1.1.3.tar.gz</span><br><span class="line">(d)apache-maven-3.0.5-bin.tar.gz</span><br><span class="line">(e)protobuf-2.5.0.tar.gz</span><br></pre></td></tr></table></figure>
<h4 id="2-jar包安装"><a href="#2-jar包安装" class="headerlink" title="2.jar包安装"></a>2.jar包安装</h4><h5 id="0-注意："><a href="#0-注意：" class="headerlink" title="(0).注意："></a>(0).注意：</h5><p>所有操作必须在root用户下完成</p>
<h5 id="1-JDK解压、配置环境变量JAVA-HOME和PATH，验证java-version-如下都需要验证是否配置成功"><a href="#1-JDK解压、配置环境变量JAVA-HOME和PATH，验证java-version-如下都需要验证是否配置成功" class="headerlink" title="(1).JDK解压、配置环境变量JAVA_HOME和PATH，验证java-version(如下都需要验证是否配置成功)"></a>(1).JDK解压、配置环境变量JAVA_HOME和PATH，验证java-version(如下都需要验证是否配置成功)</h5><p>解压：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf jdk-8u144-linux-x64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>
<p>修改环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure>
<p>修改内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>
<p>使环境变量生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<p>验证命令：java -version</p>
<h5 id="2-Maven解压、配置-MAVEN-HOME和PATH。"><a href="#2-Maven解压、配置-MAVEN-HOME和PATH。" class="headerlink" title="(2).Maven解压、配置  MAVEN_HOME和PATH。"></a>(2).Maven解压、配置  MAVEN_HOME和PATH。</h5><p>解压</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-maven-3.0.5-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>
<p>修改环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure>
<p>修改内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">MAVEN_HOME</span></span><br><span class="line">export MAVEN_HOME=/opt/module/apache-maven-3.0.5</span><br><span class="line">export PATH=$PATH:$MAVEN_HOME/bin</span><br></pre></td></tr></table></figure>
<p>使环境变量生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<p>验证命令：mvn -version</p>
<h4 id="3-编译源码"><a href="#3-编译源码" class="headerlink" title="3. 编译源码"></a>3. 编译源码</h4><h5 id="1-准备编译环境"><a href="#1-准备编译环境" class="headerlink" title="(1).准备编译环境"></a>(1).准备编译环境</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 software]# yum install svn</span><br><span class="line"></span><br><span class="line">[root@bigdata111 software]# yum install autoconf automake libtool cmake</span><br><span class="line"></span><br><span class="line">[root@bigdata111 software]# yum install ncurses-devel</span><br><span class="line"></span><br><span class="line">[root@bigdata111 software]# yum install openssl-devel</span><br><span class="line"></span><br><span class="line">[root@bigdata111 software]# yum install gcc*</span><br></pre></td></tr></table></figure>
<h5 id="2-编译安装snappy"><a href="#2-编译安装snappy" class="headerlink" title="(2).编译安装snappy"></a>(2).编译安装snappy</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 software]# tar -zxvf snappy-1.1.3.tar.gz -C /opt/module/</span><br><span class="line"></span><br><span class="line">[root@bigdata111 module]# cd snappy-1.1.3/</span><br><span class="line"></span><br><span class="line">[root@bigdata111 snappy-1.1.3]# ./configure</span><br><span class="line"></span><br><span class="line">[root@bigdata111 snappy-1.1.3]# make</span><br><span class="line"></span><br><span class="line">[root@bigdata111 snappy-1.1.3]# make install</span><br></pre></td></tr></table></figure>
<p>查看snappy库文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 snappy-1.1.3]# ls -lh /usr/local/lib |grep snappy</span><br></pre></td></tr></table></figure>
<h5 id="3-编译安装protobuf"><a href="#3-编译安装protobuf" class="headerlink" title="(3).编译安装protobuf"></a>(3).编译安装protobuf</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 software]# tar -zxvf protobuf-2.5.0.tar.gz -C /opt/module/</span><br><span class="line"></span><br><span class="line">[root@bigdata111 module]# cd protobuf-2.5.0/</span><br><span class="line"></span><br><span class="line">[root@bigdata111 protobuf-2.5.0]# ./configure </span><br><span class="line"></span><br><span class="line">[root@bigdata111 protobuf-2.5.0]#  make </span><br><span class="line"></span><br><span class="line">[root@bigdata111 protobuf-2.5.0]#  make install</span><br></pre></td></tr></table></figure>
<p>查看protobuf版本以测试是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 protobuf-2.5.0]# protoc --version</span><br></pre></td></tr></table></figure>
<h5 id="4-编译hadoop-native"><a href="#4-编译hadoop-native" class="headerlink" title="(4).编译hadoop native"></a>(4).编译hadoop native</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 software]# tar -zxvf hadoop-2.8.4-src.tar.gz</span><br><span class="line"></span><br><span class="line">[root@bigdata111 software]# cd hadoop-2.8.4-src/</span><br><span class="line"></span><br><span class="line">[root@bigdata111 software]# mvn clean package -DskipTests -Pdist,native -Dtar -Dsnappy.lib=/usr/local/lib -Dbundle.snappy</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;执行成功后，/opt/software/hadoop-2.8.4-src/hadoop-dist/target/<a href="applewebdata://9D206B90-1CCC-4328-98EC-98839FAA89F0/_blank">hadoop</a>-2.8.4.tar.gz即为新生成的支持snappy压缩的二进制安装包。</p>
<h3 id="二-Hadoop压缩配置"><a href="#二-Hadoop压缩配置" class="headerlink" title="二.Hadoop压缩配置"></a>二.Hadoop压缩配置</h3><h4 id="1-MR支持的压缩编码"><a href="#1-MR支持的压缩编码" class="headerlink" title="1.MR支持的压缩编码"></a>1.MR支持的压缩编码</h4><table>
<thead>
<tr>
<th align="center">压缩格式</th>
<th align="center">工具</th>
<th align="center">算法</th>
<th align="center">文件扩展名</th>
<th align="center">是否可切分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">DEFAULT</td>
<td align="center">无</td>
<td align="center">DEFAULT</td>
<td align="center">.deflate</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">Gzip</td>
<td align="center">gzip</td>
<td align="center">DEFAULT</td>
<td align="center">.gz</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">bzip2</td>
<td align="center">bzip2</td>
<td align="center">bzip2</td>
<td align="center">.bz2</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">LZO</td>
<td align="center">lzop</td>
<td align="center">LZO</td>
<td align="center">.lzo</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">Snappy</td>
<td align="center">无</td>
<td align="center">Snappy</td>
<td align="center">.snappy</td>
<td align="center">否</td>
</tr>
</tbody></table>
<p>&nbsp;&nbsp;&nbsp;&nbsp;为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示</p>
<table>
<thead>
<tr>
<th align="center">压缩格式</th>
<th align="center">对应的编码/解码器</th>
</tr>
</thead>
<tbody><tr>
<td align="center">DEFLATE</td>
<td align="center">org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td align="center">gzip</td>
<td align="center">org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td align="center">bzip2</td>
<td align="center">org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td align="center">LZO</td>
<td align="center">com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td align="center">Snappy</td>
<td align="center">org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody></table>
<p>压缩性能的比较</p>
<table>
<thead>
<tr>
<th align="center">压缩算法</th>
<th align="center">原始文件大小</th>
<th align="center">压缩文件大小</th>
<th align="center">压缩速度</th>
<th align="center">解压速度</th>
</tr>
</thead>
<tbody><tr>
<td align="center">gzip</td>
<td align="center">8.3GB</td>
<td align="center">1.8GB</td>
<td align="center">17.5MB/s</td>
<td align="center">58MB/s</td>
</tr>
<tr>
<td align="center">bzip2</td>
<td align="center">8.3GB</td>
<td align="center">1.1GB</td>
<td align="center">2.4MB/s</td>
<td align="center">9.5MB/s</td>
</tr>
<tr>
<td align="center">LZO</td>
<td align="center">8.3GB</td>
<td align="center">2.9GB</td>
<td align="center">49.3MB/s</td>
<td align="center">74.6MB/s</td>
</tr>
</tbody></table>
<p>On a single core of a Core i7 processor in 64-bit mode, Snappy compresses at about 250 MB/sec or more and decompresses at about 500 MB/sec or more.</p>
<h4 id="2-压缩参数配置"><a href="#2-压缩参数配置" class="headerlink" title="2.压缩参数配置"></a>2.压缩参数配置</h4><p>要在Hadoop中启用压缩，可以配置如下参数（mapred-site.xml文件中）：</p>
<table>
<thead>
<tr>
<th align="center">参数</th>
<th align="center">默认值</th>
<th align="center">阶段</th>
<th align="center">建议</th>
</tr>
</thead>
<tbody><tr>
<td align="center">io.compression.codecs(在core-site.xml中配置)</td>
<td align="center">org.apache.hadoop.io.compress.DefaultCodec<br>org.apache.hadoop.io.compress.GzipCodec<br>org.apache.hadoop.io.compress.BZip2Codec<br>org.apache.hadoop.io.compress.Lz4Codec</td>
<td align="center">输入压缩</td>
<td align="center">Hadoop使用文件扩展名判断是否支持某种编解码器</td>
</tr>
<tr>
<td align="center">mapreduce.map.output.compress</td>
<td align="center">false</td>
<td align="center">mapper输出</td>
<td align="center">这个参数设为true启用压缩</td>
</tr>
<tr>
<td align="center">mapreduce.map.output.compress.codec</td>
<td align="center">org.apache.hadoop.io.compress.DefaultCodec</td>
<td align="center">mapper输出</td>
<td align="center">使用LZO、LZ4或snappy编解码器在此阶段压缩数据</td>
</tr>
<tr>
<td align="center">mapreduce.output.fileoutputformat.compress</td>
<td align="center">false</td>
<td align="center">reducer输出</td>
<td align="center">这个参数设为true启用压缩</td>
</tr>
<tr>
<td align="center">mapreduce.output.fileoutputformat.compress.codec</td>
<td align="center">org.apache.hadoop.io.compress. DefaultCodec</td>
<td align="center">reducer输出</td>
<td align="center">使用标准工具或者编解码器，如gzip和bzip2</td>
</tr>
<tr>
<td align="center">mapreduce.output.fileoutputformat.compress.type</td>
<td align="center">RECORD</td>
<td align="center">reducer输出</td>
<td align="center">SequenceFile输出使用的压缩类型：NONE和BLOCK</td>
</tr>
</tbody></table>
<h3 id="三-开启Map输出阶段压缩"><a href="#三-开启Map输出阶段压缩" class="headerlink" title="三.开启Map输出阶段压缩"></a>三.开启Map输出阶段压缩</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;开启map输出阶段压缩可以减少job中map和Reduce task间数据传输量。具体配置如下：</p>
<p><strong>案例实操：</strong></p>
<h5 id="1-开启hive中间传输数据压缩功能-默认为false"><a href="#1-开启hive中间传输数据压缩功能-默认为false" class="headerlink" title="(1)开启hive中间传输数据压缩功能,默认为false"></a>(1)开启hive中间传输数据压缩功能,默认为false</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;set hive.exec.compress.intermediate=true;</span><br></pre></td></tr></table></figure>
<h5 id="2-开启mapreduce中map输出压缩功能-默认为false"><a href="#2-开启mapreduce中map输出压缩功能-默认为false" class="headerlink" title="(2)开启mapreduce中map输出压缩功能,默认为false"></a>(2)开启mapreduce中map输出压缩功能,默认为false</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;set mapreduce.map.output.compress=true;</span><br></pre></td></tr></table></figure>
<h5 id="3-设置mapreduce中map输出数据的压缩方式"><a href="#3-设置mapreduce中map输出数据的压缩方式" class="headerlink" title="(3)设置mapreduce中map输出数据的压缩方式"></a>(3)设置mapreduce中map输出数据的压缩方式</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;set mapreduce.map.output.compress.codec= org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>
<h5 id="4-执行查询语句"><a href="#4-执行查询语句" class="headerlink" title="(4)执行查询语句"></a>(4)执行查询语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(ename) name from emp;</span><br></pre></td></tr></table></figure>
<h3 id="四-开启Reduce输出阶段压缩"><a href="#四-开启Reduce输出阶段压缩" class="headerlink" title="四.开启Reduce输出阶段压缩"></a>四.开启Reduce输出阶段压缩</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;当Hive将输出写入到表中时，输出内容同样可以进行压缩。属性hive.exec.compress.output控制着这个功能。用户可能需要保持默认设置文件中的默认值false，这样默认的输出就是非压缩的纯文本文件了。用户可以通过在查询语句或执行脚本中设置这个值为true，来开启输出结果压缩功能。</p>
<p><strong>案例实操：</strong></p>
<h5 id="1"><a href="#1" class="headerlink" title="(1)"></a>(1)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br></pre></td></tr></table></figure>
<h5 id="2-开启hive最终输出数据压缩功能-默认为false"><a href="#2-开启hive最终输出数据压缩功能-默认为false" class="headerlink" title="(2)开启hive最终输出数据压缩功能,默认为false"></a>(2)开启hive最终输出数据压缩功能,默认为false</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;set hive.exec.compress.output=true;</span><br></pre></td></tr></table></figure>
<h5 id="3-开启mapreduce最终输出数据压缩-默认为false"><a href="#3-开启mapreduce最终输出数据压缩-默认为false" class="headerlink" title="(3)开启mapreduce最终输出数据压缩,默认为false"></a>(3)开启mapreduce最终输出数据压缩,默认为false</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;set mapreduce.output.fileoutputformat.compress=true;</span><br></pre></td></tr></table></figure>
<h5 id="4-设置mapreduce最终数据输出压缩方式"><a href="#4-设置mapreduce最终数据输出压缩方式" class="headerlink" title="(4)设置mapreduce最终数据输出压缩方式"></a>(4)设置mapreduce最终数据输出压缩方式</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.output.fileoutputformat.compress.codec = org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>
<h5 id="5-设置mapreduce最终数据输出压缩为块压缩"><a href="#5-设置mapreduce最终数据输出压缩为块压缩" class="headerlink" title="(5)设置mapreduce最终数据输出压缩为块压缩"></a>(5)设置mapreduce最终数据输出压缩为块压缩</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.output.fileoutputformat.compress.type=BLOCK;</span><br></pre></td></tr></table></figure>
<h5 id="6-测试一下输出结果是否是压缩文件"><a href="#6-测试一下输出结果是否是压缩文件" class="headerlink" title="(6)测试一下输出结果是否是压缩文件"></a>(6)测试一下输出结果是否是压缩文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory &#x27;/opt/module/datas/distribute-result&#x27; select * from emp distribute by deptno sort by empno desc;</span><br></pre></td></tr></table></figure>
<p>测试:不设置reduce，结果是否是压缩格式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces=-1;</span><br><span class="line"></span><br><span class="line">insert overwrite local directory &#x27;/opt/module/datas/distribute-result&#x27; select * from test;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTkwMGI2ZjI4MTA4YTBkYjIucG5n?x-oss-process=image/format,png"></p>
<h3 id="五-文件存储格式"><a href="#五-文件存储格式" class="headerlink" title="五. 文件存储格式"></a>五. 文件存储格式</h3><p>Hive支持的存储数的格式主要有：TEXTFILE 、SEQUENCEFILE、ORC、PARQUET。</p>
<p>简写：</p>
<ul>
<li>行储存：textFile 、 sequencefile 、</li>
<li>列储存：orc 、parquet</li>
</ul>
<h4 id="1-列式存储和行式存储"><a href="#1-列式存储和行式存储" class="headerlink" title="1.列式存储和行式存储"></a>1.列式存储和行式存储</h4><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWUyYmMyYzJlMDhjZGI3YTIucG5n?x-oss-process=image/format,png"></p>
<p>上图左边为逻辑表，右边第一个为行式存储，第二个为列式存储。</p>
<h5 id="1-行存储的特点："><a href="#1-行存储的特点：" class="headerlink" title="(1).行存储的特点："></a>(1).行存储的特点：</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。</p>
<h5 id="2-列存储的特点："><a href="#2-列存储的特点：" class="headerlink" title="(2).列存储的特点："></a>(2).列存储的特点：</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>TEXTFILE和SEQUENCEFILE的存储格式都是基于行存储的；</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;<strong>ORC和PARQUET是基于列式存储的</strong></p>
<h4 id="2-TextFile格式"><a href="#2-TextFile格式" class="headerlink" title="2.TextFile格式"></a>2.TextFile格式</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;默认格式，数据不做压缩，磁盘开销大，数据解析开销大。可结合Gzip、Bzip2使用，但使用Gzip这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作。</p>
<h4 id="3-Orc格式"><a href="#3-Orc格式" class="headerlink" title="3.Orc格式"></a>3.Orc格式</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;Orc (Optimized Row Columnar)是Hive 0.11版里引入的新的存储格式。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;可以看到每个Orc文件由1个或多个stripe组成，每个stripe250MB大小，这个Stripe实际相当于RowGroup概念，不过大小由4MB-&gt;250MB，这样应该能提升顺序读的吞吐率。每个Stripe里有三部分组成，分别是Index Data，Row Data，Stripe Footer：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTUzMTU4ZTYyMGM0MGE2ZTYucG5n?x-oss-process=image/format,png"></p>
<h5 id="1-Index-Data："><a href="#1-Index-Data：" class="headerlink" title="(1)Index Data："></a>(1)Index Data：</h5><p> 一个轻量级的index，默认是每隔1W行做一个索引。这里做的索引应该只是记录某行的各字段在Row Data中的offset。</p>
<h5 id="2-Row-Data："><a href="#2-Row-Data：" class="headerlink" title="(2)Row Data："></a>(2)Row Data：</h5><p>存的是具体的数据，先取部分行，然后对这些行按列进行存储。对每个列进行了编码，分成多个Stream来存储。</p>
<h5 id="3-Stripe-Footer："><a href="#3-Stripe-Footer：" class="headerlink" title="(3)Stripe Footer："></a>(3)Stripe Footer：</h5><p>存的是各个Stream的类型，长度等信息。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;每个文件有一个File Footer，这里面存的是每个Stripe的行数，每个Column的数据类型信息等；每个文件的尾部是一个PostScript，这里面记录了整个文件的压缩类型以及FileFooter的长度信息等。在读取文件时，会seek到文件尾部读PostScript，从里面解析到File Footer长度，再读FileFooter，从里面解析到各个Stripe信息，再读各个Stripe，即从后往前读。</p>
<h4 id="4-Parquet格式"><a href="#4-Parquet格式" class="headerlink" title="4.Parquet格式"></a>4.Parquet格式</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Parquet文件是以二进制方式存储的，所以是不可以直接读取的，文件中包括该文件的数据和元数据，因此Parquet格式文件是自解析的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;通常情况下，在存储Parquet数据的时候会按照Block大小设置行组的大小，由于一般情况下每一个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个Mapper任务处理，增大任务执行并行度。Parquet文件的格式如下图所示。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTJjMzI5Mzc4Mzc3OWI1NWYucG5n?x-oss-process=image/format,png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;上图展示了一个Parquet文件的内容，一个文件中可以存储多个行组，文件的首位都是该文件的Magic Code，用于校验它是否是一个Parquet文件，Footer length记录了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息和该文件存储数据的Schema信息。除了文件中每一个行组的元数据，每一页的开始都会存储该页的元数据，在Parquet中，有三种类型的页：<strong>数据页、字典页和索引页</strong>。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引，目前Parquet中还不支持索引页。</p>
<h4 id="5-主流文件存储格式对比实验"><a href="#5-主流文件存储格式对比实验" class="headerlink" title="5.主流文件存储格式对比实验"></a>5.主流文件存储格式对比实验</h4><p>从存储文件的压缩比和查询速度两个角度对比。</p>
<p>(一)<strong>存储文件的压缩比测试：</strong></p>
<h5 id="0-测试数据-log-data-大小为18-1MB"><a href="#0-测试数据-log-data-大小为18-1MB" class="headerlink" title="(0).测试数据(log.data 大小为18.1MB)"></a>(0).测试数据(log.data 大小为18.1MB)</h5><h5 id="1-TextFile"><a href="#1-TextFile" class="headerlink" title="(1).TextFile"></a>(1).TextFile</h5><h6 id="a-创建表，存储数据格式为TEXTFILE"><a href="#a-创建表，存储数据格式为TEXTFILE" class="headerlink" title="(a)创建表，存储数据格式为TEXTFILE"></a>(a)创建表，存储数据格式为TEXTFILE</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">create table log_text (</span><br><span class="line"></span><br><span class="line">track_time string,</span><br><span class="line"></span><br><span class="line">url string,</span><br><span class="line"></span><br><span class="line">session_id string,</span><br><span class="line"></span><br><span class="line">referer string,</span><br><span class="line"></span><br><span class="line">ip string,</span><br><span class="line"></span><br><span class="line">end_user_id string,</span><br><span class="line"></span><br><span class="line">city_id string</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">stored as textfile ;</span><br></pre></td></tr></table></figure>
<h6 id="b-向表中加载数据"><a href="#b-向表中加载数据" class="headerlink" title="(b)向表中加载数据"></a>(b)向表中加载数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/log.data&#x27; into table log_text ;</span><br></pre></td></tr></table></figure>

<h6 id="c-查看表中数据大小"><a href="#c-查看表中数据大小" class="headerlink" title="(c )查看表中数据大小"></a>(c )查看表中数据大小</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -du -h /user/hive/warehouse/log_text;</span><br></pre></td></tr></table></figure>

<p>18.1 M  /user/hive/warehouse/log_text/log.data</p>
<h5 id="2-ORC"><a href="#2-ORC" class="headerlink" title="(2).ORC"></a>(2).ORC</h5><h6 id="a-创建表，存储数据格式为ORC"><a href="#a-创建表，存储数据格式为ORC" class="headerlink" title="(a)创建表，存储数据格式为ORC"></a>(a)创建表，存储数据格式为ORC</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">create table log_orc(</span><br><span class="line"></span><br><span class="line">track_time string,</span><br><span class="line"></span><br><span class="line">url string,</span><br><span class="line"></span><br><span class="line">session_id string,</span><br><span class="line"></span><br><span class="line">referer string,</span><br><span class="line"></span><br><span class="line">ip string,</span><br><span class="line"></span><br><span class="line">end_user_id string,</span><br><span class="line"></span><br><span class="line">city_id string</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">stored as orc ;</span><br></pre></td></tr></table></figure>
<h6 id="b-向表中加载数据-1"><a href="#b-向表中加载数据-1" class="headerlink" title="(b)向表中加载数据"></a>(b)向表中加载数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert into table log_orc select * from log_text ;</span><br></pre></td></tr></table></figure>
<h6 id="c-查看表中数据大小-1"><a href="#c-查看表中数据大小-1" class="headerlink" title="(c )查看表中数据大小"></a>(c )查看表中数据大小</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -du -h /user/hive/warehouse/log_orc/ ;</span><br></pre></td></tr></table></figure>
<p>2.8 M  /user/hive/warehouse/log_orc/000000_0</p>
<h5 id="3-Parquet"><a href="#3-Parquet" class="headerlink" title="(3).Parquet"></a>(3).Parquet</h5><h6 id="a-创建表，存储数据格式为parquet"><a href="#a-创建表，存储数据格式为parquet" class="headerlink" title="(a)创建表，存储数据格式为parquet"></a>(a)创建表，存储数据格式为parquet</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">create table log_parquet(</span><br><span class="line"></span><br><span class="line">track_time string,</span><br><span class="line"></span><br><span class="line">url string,</span><br><span class="line"></span><br><span class="line">session_id string,</span><br><span class="line"></span><br><span class="line">referer string,</span><br><span class="line"></span><br><span class="line">ip string,</span><br><span class="line"></span><br><span class="line">end_user_id string,</span><br><span class="line"></span><br><span class="line">city_id string</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">stored as parquet ;  </span><br></pre></td></tr></table></figure>
<h6 id="b-向表中加载数据-2"><a href="#b-向表中加载数据-2" class="headerlink" title="(b)向表中加载数据"></a>(b)向表中加载数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert into table log_parquet select * from log_text ;</span><br></pre></td></tr></table></figure>
<h6 id="c-查看表中数据大小-2"><a href="#c-查看表中数据大小-2" class="headerlink" title="(c )查看表中数据大小"></a>(c )查看表中数据大小</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -du -h /user/hive/warehouse/log_parquet/ ;</span><br></pre></td></tr></table></figure>
<p>13.1 M  /user/hive/warehouse/log_parquet/000000_0</p>
<p>存储文件的压缩比总结：</p>
<p>ORC &gt;  Parquet &gt;  textFile</p>
<p>(二)<strong>存储文件的查询速度测试：</strong></p>
<h5 id="1-TextFile-1"><a href="#1-TextFile-1" class="headerlink" title="(1).TextFile"></a>(1).TextFile</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(*) from log_text;</span><br></pre></td></tr></table></figure>
<p>_c0<br>100000<br>Time taken: 21.54 seconds, Fetched: 1 row(s)<br>Time taken: 21.08 seconds, Fetched: 1 row(s)</p>
<h5 id="2-ORC-1"><a href="#2-ORC-1" class="headerlink" title="(2).ORC"></a>(2).ORC</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(*) from log_orc;</span><br></pre></td></tr></table></figure>
<p>_c0<br>100000<br>Time taken: 20.867 seconds, Fetched: 1 row(s)<br>Time taken: 22.667 seconds, Fetched: 1 row(s)</p>
<h5 id="3-Parquet-1"><a href="#3-Parquet-1" class="headerlink" title="(3).Parquet"></a>(3).Parquet</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(*) from log_parquet;</span><br></pre></td></tr></table></figure>
<p>_c0<br>100000<br>Time taken: 22.922 seconds, Fetched: 1 row(s)<br>Time taken: 21.074 seconds, Fetched: 1 row(s)</p>
<p><strong>存储文件的查询速度总结：查询速度相近。</strong></p>
<h3 id="六-存储和压缩结合"><a href="#六-存储和压缩结合" class="headerlink" title="六.存储和压缩结合"></a>六.存储和压缩结合</h3><h4 id="1-修改Hadoop集群具有Snappy压缩方式"><a href="#1-修改Hadoop集群具有Snappy压缩方式" class="headerlink" title="1.修改Hadoop集群具有Snappy压缩方式"></a>1.修改Hadoop集群具有Snappy压缩方式</h4><h5 id="1-查看hadoop-checknative命令使用"><a href="#1-查看hadoop-checknative命令使用" class="headerlink" title="(1).查看hadoop checknative命令使用"></a>(1).查看hadoop checknative命令使用</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop checknative [-a|-h]  check native hadoop and compression libraries availability</span><br></pre></td></tr></table></figure>
<h5 id="2-查看hadoop支持的压缩方式"><a href="#2-查看hadoop支持的压缩方式" class="headerlink" title="(2).查看hadoop支持的压缩方式"></a>(2).查看hadoop支持的压缩方式</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop checknative</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTc2OWQyOGMyOTNjY2YzOTkucG5n?x-oss-process=image/format,png"></p>
<h5 id="3-将编译好的支持Snappy压缩的hadoop-2-8-4-tar-gz包导入到bigdata111的-opt-software中"><a href="#3-将编译好的支持Snappy压缩的hadoop-2-8-4-tar-gz包导入到bigdata111的-opt-software中" class="headerlink" title="(3).将编译好的支持Snappy压缩的hadoop-2.8.4.tar.gz包导入到bigdata111的/opt/software中"></a>(3).将编译好的支持Snappy压缩的hadoop-2.8.4.tar.gz包导入到bigdata111的/opt/software中</h5><h5 id="4-解压hadoop-2-8-4-tar-gz到当前路径"><a href="#4-解压hadoop-2-8-4-tar-gz到当前路径" class="headerlink" title="(4).解压hadoop-2.8.4.tar.gz到当前路径"></a>(4).解压hadoop-2.8.4.tar.gz到当前路径</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.8.4.tar.gz</span><br></pre></td></tr></table></figure>
<h5 id="5-进入到-opt-software-hadoop-2-8-4-lib-native路径可以看到支持Snappy压缩的动态链接库"><a href="#5-进入到-opt-software-hadoop-2-8-4-lib-native路径可以看到支持Snappy压缩的动态链接库" class="headerlink" title="(5).进入到/opt/software/hadoop-2.8.4/lib/native路径可以看到支持Snappy压缩的动态链接库"></a>(5).进入到/opt/software/hadoop-2.8.4/lib/native路径可以看到支持Snappy压缩的动态链接库</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pwd</span><br><span class="line"></span><br><span class="line">ll</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTZiZmQwYzUyZjVkODc4MzUucG5n?x-oss-process=image/format,png"></p>
<h5 id="6-拷贝-opt-software-hadoop-2-8-4-lib-native里面的所有内容到开发集群的-opt-module-hadoop-2-8-4-lib-native路径上"><a href="#6-拷贝-opt-software-hadoop-2-8-4-lib-native里面的所有内容到开发集群的-opt-module-hadoop-2-8-4-lib-native路径上" class="headerlink" title="(6).拷贝/opt/software/hadoop-2.8.4/lib/native里面的所有内容到开发集群的/opt/module/hadoop-2.8.4/lib/native路径上"></a>(6).拷贝/opt/software/hadoop-2.8.4/lib/native里面的所有内容到开发集群的/opt/module/hadoop-2.8.4/lib/native路径上</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp ../native/* /opt/module/hadoop-2.8.4/lib/native/</span><br></pre></td></tr></table></figure>
<h5 id="7-分发集群-scp-到其他集群目录"><a href="#7-分发集群-scp-到其他集群目录" class="headerlink" title="(7).分发集群 scp 到其他集群目录"></a>(7).分发集群 scp 到其他集群目录</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp - r ./native/ root@主机名:绝对路径</span><br></pre></td></tr></table></figure>
<h5 id="8-再次查看hadoop支持的压缩类型"><a href="#8-再次查看hadoop支持的压缩类型" class="headerlink" title="(8).再次查看hadoop支持的压缩类型"></a>(8).再次查看hadoop支持的压缩类型</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop checknative</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTU4YjM0OGYzODg3OTA1MzMucG5n?x-oss-process=image/format,png"></p>
<h5 id="9-重新启动hadoop集群和hive"><a href="#9-重新启动hadoop集群和hive" class="headerlink" title="(9).重新启动hadoop集群和hive"></a>(9).重新启动hadoop集群和hive</h5><h4 id="2-测试存储和压缩"><a href="#2-测试存储和压缩" class="headerlink" title="2.测试存储和压缩"></a>2.测试存储和压缩</h4><p>官网:<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC</a></p>
<p>ORC存储方式的压缩：</p>
<table>
<thead>
<tr>
<th align="center">Key</th>
<th align="center">Default</th>
<th align="center">Notes</th>
</tr>
</thead>
<tbody><tr>
<td align="center">orc.compress</td>
<td align="center">ZLIB</td>
<td align="center">high level compression (one of NONE, ZLIB, SNAPPY)</td>
</tr>
<tr>
<td align="center">orc.compress.size</td>
<td align="center">262,144</td>
<td align="center">number of bytes in each compression chunk</td>
</tr>
<tr>
<td align="center">orc.stripe.size</td>
<td align="center">67,108,864</td>
<td align="center">number of bytes in each stripe</td>
</tr>
<tr>
<td align="center">orc.row.index.stride</td>
<td align="center">10,000</td>
<td align="center">number of rows between index entries (must be &gt;= 1000)</td>
</tr>
<tr>
<td align="center">orc.create.index</td>
<td align="center">true</td>
<td align="center">whether to create row indexes</td>
</tr>
<tr>
<td align="center">orc.bloom.filter.columns</td>
<td align="center">“”</td>
<td align="center">comma separated list of column names for which bloom filter should be created</td>
</tr>
<tr>
<td align="center">orc.bloom.filter.fpp</td>
<td align="center">0.05</td>
<td align="center">false positive probability for bloom filter (must &gt;0.0 and &lt;1.0)</td>
</tr>
</tbody></table>
<h5 id="1-创建一个非压缩的的ORC存储方式"><a href="#1-创建一个非压缩的的ORC存储方式" class="headerlink" title="(1).创建一个非压缩的的ORC存储方式"></a>(1).创建一个非压缩的的ORC存储方式</h5><h6 id="a-建表语句"><a href="#a-建表语句" class="headerlink" title="(a)建表语句"></a>(a)建表语句</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">create table log_orc_none(</span><br><span class="line"></span><br><span class="line">track_time string,</span><br><span class="line"></span><br><span class="line">url string,</span><br><span class="line"></span><br><span class="line">session_id string,</span><br><span class="line"></span><br><span class="line">referer string,</span><br><span class="line"></span><br><span class="line">ip string,</span><br><span class="line"></span><br><span class="line">end_user_id string,</span><br><span class="line"></span><br><span class="line">city_id string</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">stored as orc tblproperties (&quot;orc.compress&quot;=&quot;NONE&quot;);</span><br></pre></td></tr></table></figure>
<h6 id="b-插入数据"><a href="#b-插入数据" class="headerlink" title="(b)插入数据"></a>(b)插入数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert into table log_orc_none select * from log_text ;</span><br></pre></td></tr></table></figure>
<h6 id="c-查看插入后数据"><a href="#c-查看插入后数据" class="headerlink" title="(c )查看插入后数据"></a>(c )查看插入后数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -du -h /user/hive/warehouse/log_orc_none/ ;</span><br></pre></td></tr></table></figure>
<p>7.7 M  /user/hive/warehouse/log_orc_none/000000_0</p>
<h5 id="2-创建一个SNAPPY压缩的ORC存储方式"><a href="#2-创建一个SNAPPY压缩的ORC存储方式" class="headerlink" title="(2).创建一个SNAPPY压缩的ORC存储方式"></a>(2).创建一个SNAPPY压缩的ORC存储方式</h5><h6 id="a-建表语句-1"><a href="#a-建表语句-1" class="headerlink" title="(a)建表语句"></a>(a)建表语句</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">create table log_orc_snappy(</span><br><span class="line"></span><br><span class="line">track_time string,</span><br><span class="line"></span><br><span class="line">url string,</span><br><span class="line"></span><br><span class="line">session_id string,</span><br><span class="line"></span><br><span class="line">referer string,</span><br><span class="line"></span><br><span class="line">ip string,</span><br><span class="line"></span><br><span class="line">end_user_id string,</span><br><span class="line"></span><br><span class="line">city_id string</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">stored as orc tblproperties (&quot;orc.compress&quot;=&quot;SNAPPY&quot;);</span><br></pre></td></tr></table></figure>
<h6 id="b-插入数据-1"><a href="#b-插入数据-1" class="headerlink" title="(b)插入数据"></a>(b)插入数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert into table log_orc_snappy select * from log_text ;</span><br></pre></td></tr></table></figure>
<h6 id="c-查看插入后数据-1"><a href="#c-查看插入后数据-1" class="headerlink" title="(c )查看插入后数据"></a>(c )查看插入后数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -du -h /user/hive/warehouse/log_orc_snappy/ ;</span><br></pre></td></tr></table></figure>

<p>3.8 M  /user/hive/warehouse/log_orc_snappy/000000_0</p>
<h5 id="3-上一节中默认创建的ORC存储方式，导入数据后的大小为"><a href="#3-上一节中默认创建的ORC存储方式，导入数据后的大小为" class="headerlink" title="(3).上一节中默认创建的ORC存储方式，导入数据后的大小为"></a>(3).上一节中默认创建的ORC存储方式，导入数据后的大小为</h5><p>2.8 M  /user/hive/warehouse/log_orc/000000_0</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;比Snappy压缩的还小。原因是orc存储文件默认采用ZLIB压缩。比snappy压缩的小。</p>
<h5 id="4-存储方式和压缩总结"><a href="#4-存储方式和压缩总结" class="headerlink" title="(4).存储方式和压缩总结:"></a>(4).存储方式和压缩总结:</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;在实际的项目开发当中，hive表的数据存储格式一般选择：orc或parquet。压缩方式一般选择snappy，lzo。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive-企业级调优"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive-%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%B0%83%E4%BC%98/"
    >Hive之企业调优</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive-%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%B0%83%E4%BC%98/" class="article-date">
  <time datetime="2019-07-15T13:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-Fetch抓取"><a href="#一-Fetch抓取" class="headerlink" title="一. Fetch抓取"></a>一. Fetch抓取</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：SELECT * FROM employees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.fetch.task.conversion<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>more<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      Expects one of [none, minimal, more].</span><br><span class="line"></span><br><span class="line">      Some select queries can be converted to single FETCH task minimizing latency.</span><br><span class="line"></span><br><span class="line">      Currently the query should be single sourced not having any subquery and should not have</span><br><span class="line"></span><br><span class="line">      any aggregations or distincts (which incurs RS), lateral views and joins.</span><br><span class="line"></span><br><span class="line">      0\. none : disable hive.fetch.task.conversion</span><br><span class="line"></span><br><span class="line">      1\. minimal : SELECT STAR, FILTER on partition columns, LIMIT only</span><br><span class="line"></span><br><span class="line">      2\. more  : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual columns)</span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>案例实操</strong>：</p>
<p>1.把hive.fetch.task.conversion设置成none，然后执行查询语句，都会执行mapreduce程序。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.fetch.task.conversion=none;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp limit 3;</span><br></pre></td></tr></table></figure>

<p>2.把hive.fetch.task.conversion设置成more，然后执行查询语句，如下查询方式都不会执行mapreduce程序。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.fetch.task.conversion=more;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp limit 3;</span><br></pre></td></tr></table></figure>
<h3 id="二-本地模式"><a href="#二-本地模式" class="headerlink" title="二. 本地模式"></a>二. 本地模式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，<strong>Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.mode.local.auto=true;  //开启本地mr</span><br><span class="line"></span><br><span class="line">//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local  mr的方式，默认为134217728，即128M</span><br><span class="line"></span><br><span class="line">set hive.exec.mode.local.auto.inputbytes.max=50000000;</span><br><span class="line"></span><br><span class="line">//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</span><br><span class="line"></span><br><span class="line">set hive.exec.mode.local.auto.input.files.max=10;</span><br></pre></td></tr></table></figure>
<p><strong>案例实操</strong>：</p>
<h3 id="1-开启本地模式，并执行查询语句-注意重启Hive"><a href="#1-开启本地模式，并执行查询语句-注意重启Hive" class="headerlink" title="1.开启本地模式，并执行查询语句(注意重启Hive)"></a>1.开启本地模式，并执行查询语句(注意重启Hive)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.exec.mode.local.auto=true; </span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp cluster by deptno;</span><br></pre></td></tr></table></figure>
<p>Time taken: 1.328 seconds, Fetched: 14 row(s)</p>
<h4 id="2-关闭本地模式，并执行查询语句"><a href="#2-关闭本地模式，并执行查询语句" class="headerlink" title="2.关闭本地模式，并执行查询语句"></a>2.关闭本地模式，并执行查询语句</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.exec.mode.local.auto=false; </span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp cluster by deptno;</span><br></pre></td></tr></table></figure>
<p>Time taken: 20.09 seconds, Fetched: 14 row(s)</p>
<h3 id="三-表的优化"><a href="#三-表的优化" class="headerlink" title="三.表的优化"></a>三.表的优化</h3><h4 id="1-小表、大表Join"><a href="#1-小表、大表Join" class="headerlink" title="1. 小表、大表Join"></a>1. 小表、大表Join</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用Group变小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce（预聚合）。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</p>
<p><strong>案例实操</strong></p>
<h5 id="0-需求：测试大表JOIN小表和小表JOIN大表的效率"><a href="#0-需求：测试大表JOIN小表和小表JOIN大表的效率" class="headerlink" title="(0)需求：测试大表JOIN小表和小表JOIN大表的效率"></a>(0)需求：测试大表JOIN小表和小表JOIN大表的效率</h5><h5 id="1-建大表、小表和JOIN后表的语句"><a href="#1-建大表、小表和JOIN后表的语句" class="headerlink" title="(1)建大表、小表和JOIN后表的语句"></a>(1)建大表、小表和JOIN后表的语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 创建大表</span><br><span class="line">create table bigtable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建小表</span><br><span class="line">create table smalltable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建join后表的语句</span><br><span class="line">create table jointable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-分别向大表和小表中导入数据"><a href="#2-分别向大表和小表中导入数据" class="headerlink" title="(2)分别向大表和小表中导入数据"></a>(2)分别向大表和小表中导入数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/bigtable&#x27; into table bigtable;</span><br><span class="line"></span><br><span class="line">hive (default)&gt;load data local inpath &#x27;/opt/module/datas/smalltable&#x27; into table smalltable;</span><br></pre></td></tr></table></figure>
<h5 id="3-关闭mapjoin功能（默认是打开的）"><a href="#3-关闭mapjoin功能（默认是打开的）" class="headerlink" title="(3)关闭mapjoin功能（默认是打开的）"></a>(3)关闭mapjoin功能（默认是打开的）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.auto.convert.join = false;</span><br></pre></td></tr></table></figure>
<h5 id="4-执行小表JOIN大表语句"><a href="#4-执行小表JOIN大表语句" class="headerlink" title="(4)执行小表JOIN大表语句"></a>(4)执行小表JOIN大表语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line"></span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line"></span><br><span class="line">from smalltable s</span><br><span class="line"></span><br><span class="line">left join bigtable  b</span><br><span class="line"></span><br><span class="line">on b.id = s.id;</span><br></pre></td></tr></table></figure>

<h5 id="5-执行大表JOIN小表语句"><a href="#5-执行大表JOIN小表语句" class="headerlink" title="(5)执行大表JOIN小表语句"></a>(5)执行大表JOIN小表语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line"></span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line"></span><br><span class="line">from bigtable  b</span><br><span class="line"></span><br><span class="line">left join smalltable  s</span><br><span class="line"></span><br><span class="line">on s.id = b.id;</span><br></pre></td></tr></table></figure>
<h4 id="2-大表Join大表"><a href="#2-大表Join大表" class="headerlink" title="2.大表Join大表"></a>2.大表Join大表</h4><h5 id="1-空KEY过滤"><a href="#1-空KEY过滤" class="headerlink" title="(1).空KEY过滤"></a>(1).空KEY过滤</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。例如key对应的字段为空，操作如下：</p>
<p><strong>案例实操</strong></p>
<h6 id="a-配置历史服务器"><a href="#a-配置历史服务器" class="headerlink" title="(a)配置历史服务器"></a>(a)配置历史服务器</h6><p>配置mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata111:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata111:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>启动历史服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<p>查看jobhistory</p>
<p><a target="_blank" rel="noopener" href="http://192.168.1.102:19888/jobhistory">http://192.168.1.102:19888/jobhistory</a></p>
<h6 id="b-创建原始数据表、空id表、合并后数据表"><a href="#b-创建原始数据表、空id表、合并后数据表" class="headerlink" title="(b)创建原始数据表、空id表、合并后数据表"></a>(b)创建原始数据表、空id表、合并后数据表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 创建原始表</span><br><span class="line">create table ori(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建空id表</span><br><span class="line">create table nullidtable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建join后表的语句</span><br><span class="line">create table jointable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="c-分别加载原始数据和空id数据到对应表中"><a href="#c-分别加载原始数据和空id数据到对应表中" class="headerlink" title="(c )分别加载原始数据和空id数据到对应表中"></a>(c )分别加载原始数据和空id数据到对应表中</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/ori&#x27; into table ori;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/nullid&#x27; into table nullidtable;</span><br></pre></td></tr></table></figure>

<h6 id="d-测试不过滤空id"><a href="#d-测试不过滤空id" class="headerlink" title="(d)测试不过滤空id"></a>(d)测试不过滤空id</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite table jointable </span><br><span class="line"></span><br><span class="line">select n.* from nullidtable n left join ori o on n.id = o.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 42.038 seconds</p>
<p>Time taken: 37.284 seconds</p>
<p>Time taken: 97.281 seconds</p>
<h5 id="e-测试过滤空id"><a href="#e-测试过滤空id" class="headerlink" title="(e)测试过滤空id"></a>(e)测试过滤空id</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite table jointable </span><br><span class="line"></span><br><span class="line">select n.* from (select * from nullidtable where id is not null ) n  left join ori o on n.id = o.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 31.725 seconds</p>
<p>Time taken: 28.876 seconds</p>
<h5 id="2-空key转换"><a href="#2-空key转换" class="headerlink" title="(2).空key转换"></a>(2).空key转换</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。例如：</p>
<p><strong>案例实操：</strong></p>
<p><strong>不随机分布空null值：</strong></p>
<h6 id="a-设置5个reduce个数"><a href="#a-设置5个reduce个数" class="headerlink" title="(a)设置5个reduce个数"></a>(a)设置5个reduce个数</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>
<h6 id="b-JOIN两张表"><a href="#b-JOIN两张表" class="headerlink" title="(b)JOIN两张表"></a>(b)JOIN两张表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line"></span><br><span class="line">select n.* from nullidtable n left join ori b on n.id = b.id;</span><br></pre></td></tr></table></figure>

<p><strong>结果：可以看出来，出现了数据倾斜，某些reducer的资源消耗远大于其他reducer</strong></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWE0MTZjMTY3ZDRiODYxNmQucG5n?x-oss-process=image/format,png"></p>
<p><strong>随机分布空null值</strong></p>
<h6 id="a-设置5个reduce个数-1"><a href="#a-设置5个reduce个数-1" class="headerlink" title="(a)设置5个reduce个数"></a>(a)设置5个reduce个数</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>
<h6 id="b-JOIN两张表-1"><a href="#b-JOIN两张表-1" class="headerlink" title="(b)JOIN两张表"></a>(b)JOIN两张表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line">select n.* from nullidtable n full join ori o on </span><br><span class="line">case when n.id is null then concat(&#x27;hive&#x27;, rand()) else n.id end = o.id;</span><br></pre></td></tr></table></figure>
<p><strong>结果：可以看出来，消除了数据倾斜，负载均衡reducer的资源消耗</strong></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWUxOTVmMzc4YzQ0NzYyMzUucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-MapJoin"><a href="#3-MapJoin" class="headerlink" title="3.MapJoin"></a>3.MapJoin</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即：在Reduce阶段完成join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在map端进行join，避免reducer处理。</p>
<h5 id="1-开启MapJoin参数设置："><a href="#1-开启MapJoin参数设置：" class="headerlink" title="(1).开启MapJoin参数设置："></a>(1).开启MapJoin参数设置：</h5><h6 id="a-设置自动选择Mapjoin"><a href="#a-设置自动选择Mapjoin" class="headerlink" title="(a)设置自动选择Mapjoin"></a>(a)设置自动选择Mapjoin</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set hive.auto.convert.join = true;</span><br><span class="line">//默认为true</span><br></pre></td></tr></table></figure>
<h6 id="b-大表小表的阈值设置-默认25M一下认为是小表-："><a href="#b-大表小表的阈值设置-默认25M一下认为是小表-：" class="headerlink" title="(b)大表小表的阈值设置(默认25M一下认为是小表)："></a>(b)大表小表的阈值设置(默认25M一下认为是小表)：</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.mapjoin.smalltable.filesize=25000000;</span><br></pre></td></tr></table></figure>
<h5 id="2-MapJoin工作机制"><a href="#2-MapJoin工作机制" class="headerlink" title="(2).MapJoin工作机制"></a>(2).MapJoin工作机制</h5><p><strong>案例实操</strong>：</p>
<h6 id="a-开启Mapjoin功能"><a href="#a-开启Mapjoin功能" class="headerlink" title="(a)开启Mapjoin功能"></a>(a)开启Mapjoin功能</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.auto.convert.join = true; 默认为true</span><br></pre></td></tr></table></figure>
<h6 id="b-执行小表JOIN大表语句"><a href="#b-执行小表JOIN大表语句" class="headerlink" title="(b)执行小表JOIN大表语句"></a>(b)执行小表JOIN大表语句</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line">from smalltable s</span><br><span class="line">join bigtable  b</span><br><span class="line">on s.id = b.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 24.594 seconds</p>
<h6 id="c-执行大表JOIN小表语句"><a href="#c-执行大表JOIN小表语句" class="headerlink" title="(c )执行大表JOIN小表语句"></a>(c )执行大表JOIN小表语句</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line">from bigtable  b</span><br><span class="line">join smalltable  s</span><br><span class="line">on s.id = b.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 24.315 seconds</p>
<h4 id="4-Group-By"><a href="#4-Group-By" class="headerlink" title="4.Group By"></a>4.Group By</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p>
<h5 id="1-开启Map端聚合参数设置"><a href="#1-开启Map端聚合参数设置" class="headerlink" title="(1).开启Map端聚合参数设置"></a>(1).开启Map端聚合参数设置</h5><h6 id="a-是否在Map端进行聚合，默认为True"><a href="#a-是否在Map端进行聚合，默认为True" class="headerlink" title="(a)是否在Map端进行聚合，默认为True"></a>(a)是否在Map端进行聚合，默认为True</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr = true</span><br></pre></td></tr></table></figure>

<h6 id="b-在Map端进行聚合操作的条目数目"><a href="#b-在Map端进行聚合操作的条目数目" class="headerlink" title="(b)在Map端进行聚合操作的条目数目"></a>(b)在Map端进行聚合操作的条目数目</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.groupby.mapaggr.checkinterval = 100000</span><br></pre></td></tr></table></figure>
<h6 id="c-有数据倾斜的时候进行负载均衡（默认是false）"><a href="#c-有数据倾斜的时候进行负载均衡（默认是false）" class="headerlink" title="(c )有数据倾斜的时候进行负载均衡（默认是false）"></a>(c )有数据倾斜的时候进行负载均衡（默认是false）</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.groupby.skewindata = true</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;当选项设定为 true，生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中(这个过程可以保证相同的Group By Key被分布到同一个Reduce中)，最后完成最终的聚合操作。</p>
<h4 id="5-Count-Distinct-去重统计"><a href="#5-Count-Distinct-去重统计" class="headerlink" title="5.Count(Distinct) 去重统计"></a>5.Count(Distinct) 去重统计</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换：</p>
<p><strong>案例实操</strong></p>
<h5 id="1-创建一张大表"><a href="#1-创建一张大表" class="headerlink" title="(1)创建一张大表"></a>(1)创建一张大表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table bigtable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-加载数据"><a href="#2-加载数据" class="headerlink" title="(2)加载数据"></a>(2)加载数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/bigtable&#x27; into table bigtable;</span><br></pre></td></tr></table></figure>
<h5 id="3-设置5个reduce个数"><a href="#3-设置5个reduce个数" class="headerlink" title="(3)设置5个reduce个数"></a>(3)设置5个reduce个数</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>

<h5 id="4-执行去重id查询"><a href="#4-执行去重id查询" class="headerlink" title="(4)执行去重id查询"></a>(4)执行去重id查询</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(distinct id) from bigtable;</span><br></pre></td></tr></table></figure>
<p>Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 7.12 sec   HDFS Read: 120741990 HDFS Write: 7 SUCCESS<br>Total MapReduce CPU Time Spent: 7 seconds 120 msec<br>OK<br>c0<br>100001<br>Time taken: 23.607 seconds, Fetched: 1 row(s)</p>
<h5 id="5-采用GROUP-by去重id-推荐"><a href="#5-采用GROUP-by去重id-推荐" class="headerlink" title="(5)采用GROUP by去重id(推荐)"></a>(5)采用GROUP by去重id(推荐)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(id) from (select id from bigtable group by id) a;</span><br></pre></td></tr></table></figure>
<p>Stage-Stage-1: Map: 1  Reduce: 5   Cumulative CPU: 17.53 sec   HDFS Read: 120752703 HDFS Write: 580 SUCCESS<br>Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.29 sec   HDFS Read: 9409 HDFS Write: 7 SUCCESS<br>Total MapReduce CPU Time Spent: 21 seconds 820 msec<br>OK<br>_c0<br>100001<br>Time taken: 50.795 seconds, Fetched: 1 row(s)</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</p>
<h4 id="6-笛卡尔积"><a href="#6-笛卡尔积" class="headerlink" title="6. 笛卡尔积"></a>6. 笛卡尔积</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p>
<h4 id="7-行列过滤"><a href="#7-行列过滤" class="headerlink" title="7.行列过滤"></a>7.行列过滤</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;列处理：在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤，总而言之，就是先where还是先join的执行顺序的问题，以下两种，经过SQL优化器，执行效果大体一样。比如：</p>
<p><strong>案例实操</strong>：</p>
<h5 id="1-测试先关联两张表，再用where条件过滤"><a href="#1-测试先关联两张表，再用where条件过滤" class="headerlink" title="(1)测试先关联两张表，再用where条件过滤"></a>(1)测试先关联两张表，再用where条件过滤</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select o.id from bigtable b</span><br><span class="line">join ori o on o.id = b.id</span><br><span class="line">where o.id &lt;= 10;</span><br></pre></td></tr></table></figure>
<p>Time taken: 34.406 seconds, Fetched: 100 row(s)</p>
<h5 id="2-通过子查询后，再关联表"><a href="#2-通过子查询后，再关联表" class="headerlink" title="(2)通过子查询后，再关联表"></a>(2)通过子查询后，再关联表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select b.id from bigtable b</span><br><span class="line">join (select id from ori where id &lt;= 10 ) o on b.id = o.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 30.058 seconds, Fetched: 100 row(s)</p>
<h4 id="8-动态分区调整"><a href="#8-动态分区调整" class="headerlink" title="8.动态分区调整"></a>8.动态分区调整</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。</p>
<h5 id="1-开启动态分区参数设置"><a href="#1-开启动态分区参数设置" class="headerlink" title="(1).开启动态分区参数设置"></a>(1).开启动态分区参数设置</h5><h6 id="a-开启动态分区功能-默认true，开启"><a href="#a-开启动态分区功能-默认true，开启" class="headerlink" title="(a)开启动态分区功能(默认true，开启)"></a>(a)开启动态分区功能(默认true，开启)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition=true</span><br></pre></td></tr></table></figure>
<h6 id="b-设置为非严格模式-动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区"><a href="#b-设置为非严格模式-动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区" class="headerlink" title="(b)设置为非严格模式(动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区)"></a>(b)设置为非严格模式(动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition.mode=nonstrict</span><br></pre></td></tr></table></figure>
<h6 id="c-在所有执行MR的节点上，最大一共可以创建多少个动态分区。-默认1000"><a href="#c-在所有执行MR的节点上，最大一共可以创建多少个动态分区。-默认1000" class="headerlink" title="(c )在所有执行MR的节点上，最大一共可以创建多少个动态分区。(默认1000)"></a>(c )在所有执行MR的节点上，最大一共可以创建多少个动态分区。(默认1000)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.max.dynamic.partitions=1000</span><br></pre></td></tr></table></figure>
<h6 id="d-在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。"><a href="#d-在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。" class="headerlink" title="(d)在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。"></a>(d)在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.max.dynamic.partitions.pernode=100</span><br></pre></td></tr></table></figure>
<h6 id="e-整个MR-Job中，最大可以创建多少个HDFS文件。-默认值100000"><a href="#e-整个MR-Job中，最大可以创建多少个HDFS文件。-默认值100000" class="headerlink" title="(e)整个MR Job中，最大可以创建多少个HDFS文件。(默认值100000)"></a>(e)整个MR Job中，最大可以创建多少个HDFS文件。(默认值100000)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.max.created.files=100000</span><br></pre></td></tr></table></figure>
<h6 id="f-当有空分区生成时，是否抛出异常。一般不需要设置。-默认false"><a href="#f-当有空分区生成时，是否抛出异常。一般不需要设置。-默认false" class="headerlink" title="(f)当有空分区生成时，是否抛出异常。一般不需要设置。(默认false)"></a>(f)当有空分区生成时，是否抛出异常。一般不需要设置。(默认false)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.error.on.empty.partition=false</span><br></pre></td></tr></table></figure>
<h5 id="2-案例实操"><a href="#2-案例实操" class="headerlink" title="(2).案例实操"></a>(2).案例实操</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;需求：将ori中的数据按照时间(如：20111230000008)，插入到目标表ori_partitioned_target的相应分区中。</p>
<h6 id="a-创建分区表"><a href="#a-创建分区表" class="headerlink" title="(a)创建分区表"></a>(a)创建分区表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create table ori_partitioned(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) </span><br><span class="line">partitioned by (p_time bigint) </span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<h6 id="b-加载数据到分区表中"><a href="#b-加载数据到分区表中" class="headerlink" title="(b)加载数据到分区表中"></a>(b)加载数据到分区表中</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/ds1&#x27; into table ori_partitioned partition(p_time=&#x27;20111230000010&#x27;) ;</span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/ds2&#x27; into table ori_partitioned partition(p_time=&#x27;20111230000011&#x27;) ;</span><br></pre></td></tr></table></figure>
<h6 id="c-创建目标分区表"><a href="#c-创建目标分区表" class="headerlink" title="(c )创建目标分区表"></a>(c )创建目标分区表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table ori_partitioned_target(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) PARTITIONED BY (p_time STRING) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="d-设置动态分区"><a href="#d-设置动态分区" class="headerlink" title="(d)设置动态分区"></a>(d)设置动态分区</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition = true;  //（默认true）</span><br><span class="line">set hive.exec.dynamic.partition.mode = nonstrict;  //(默认strict)</span><br><span class="line">set hive.exec.max.dynamic.partitions = 1000;   //(默认1000)</span><br><span class="line">set hive.exec.max.dynamic.partitions.pernode = 100;   //（默认100）</span><br><span class="line">set hive.exec.max.created.files = 100000;  //(默认值100000)</span><br><span class="line">set hive.error.on.empty.partition = false;   //(默认值false)</span><br><span class="line"></span><br><span class="line">hive (default)&gt; insert overwrite table ori_partitioned_target partition (p_time) </span><br><span class="line">select id, time, uid, keyword, url_rank, click_num, click_url, p_time from ori_partitioned;</span><br></pre></td></tr></table></figure>

<h6 id="e-查看目标分区表的分区情况"><a href="#e-查看目标分区表的分区情况" class="headerlink" title="(e)查看目标分区表的分区情况"></a>(e)查看目标分区表的分区情况</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; show partitions ori_partitioned_target;</span><br></pre></td></tr></table></figure>
<h6 id="f-如果不设置非严格模式，报错如下"><a href="#f-如果不设置非严格模式，报错如下" class="headerlink" title="(f)如果不设置非严格模式，报错如下"></a>(f)如果不设置非严格模式，报错如下</h6><p>FAILED: SemanticException [Error 10096]: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict</p>
<h4 id="9-分桶"><a href="#9-分桶" class="headerlink" title="9. 分桶"></a>9. 分桶</h4><h4 id="10-分区"><a href="#10-分区" class="headerlink" title="10.分区"></a>10.分区</h4><h3 id="四-数据倾斜"><a href="#四-数据倾斜" class="headerlink" title="四.数据倾斜"></a>四.数据倾斜</h3><h4 id="1-合理设置Map数"><a href="#1-合理设置Map数" class="headerlink" title="1.合理设置Map数"></a>1.合理设置Map数</h4><h5 id="1-通常情况下，作业会通过input的目录产生一个或者多个map任务。"><a href="#1-通常情况下，作业会通过input的目录产生一个或者多个map任务。" class="headerlink" title="(1).通常情况下，作业会通过input的目录产生一个或者多个map任务。"></a>(1).通常情况下，作业会通过input的目录产生一个或者多个map任务。</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p>
<h5 id="2-是不是map数越多越好？"><a href="#2-是不是map数越多越好？" class="headerlink" title="(2).是不是map数越多越好？"></a>(2).是不是map数越多越好？</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;答案是否定的。如果一个任务有很多小文件(远远小于块大小128m)，则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p>
<h5 id="3-是不是保证每个map处理接近128m的文件块，就高枕无忧了？"><a href="#3-是不是保证每个map处理接近128m的文件块，就高枕无忧了？" class="headerlink" title="(3).是不是保证每个map处理接近128m的文件块，就高枕无忧了？"></a>(3).是不是保证每个map处理接近128m的文件块，就高枕无忧了？</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。<br>针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</p>
<h4 id="2-小文件进行合并"><a href="#2-小文件进行合并" class="headerlink" title="2.小文件进行合并"></a>2.小文件进行合并</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>
<h4 id="3-复杂文件增加Map数"><a href="#3-复杂文件增加Map数" class="headerlink" title="3.复杂文件增加Map数"></a>3.复杂文件增加Map数</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;增加map的方法为：根据computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p>
<p><strong>案例实操</strong>：</p>
<h5 id="1-执行查询"><a href="#1-执行查询" class="headerlink" title="(1)执行查询"></a>(1)执行查询</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(*) from emp;</span><br></pre></td></tr></table></figure>
<p>Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</p>
<h5 id="2-设置最大切片值为100个字节"><a href="#2-设置最大切片值为100个字节" class="headerlink" title="(2)设置最大切片值为100个字节"></a>(2)设置最大切片值为100个字节</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.input.fileinputformat.split.maxsize=100;</span><br><span class="line">hive (default)&gt; select count(*) from emp;</span><br></pre></td></tr></table></figure>
<p>Hadoop job information for Stage-1: number of mappers: 6; number of reducers: 1</p>
<h4 id="4-合理设置Reduce数"><a href="#4-合理设置Reduce数" class="headerlink" title="4. 合理设置Reduce数"></a>4. 合理设置Reduce数</h4><h5 id="1-调整reduce个数方法一"><a href="#1-调整reduce个数方法一" class="headerlink" title="(1).调整reduce个数方法一"></a>(1).调整reduce个数方法一</h5><h6 id="a-每个Reduce处理的数据量默认是256MB"><a href="#a-每个Reduce处理的数据量默认是256MB" class="headerlink" title="(a)每个Reduce处理的数据量默认是256MB"></a>(a)每个Reduce处理的数据量默认是256MB</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.reducers.bytes.per.reducer=256000000</span><br></pre></td></tr></table></figure>
<h6 id="b-每个任务最大的reduce数，默认为1009"><a href="#b-每个任务最大的reduce数，默认为1009" class="headerlink" title="(b)每个任务最大的reduce数，默认为1009"></a>(b)每个任务最大的reduce数，默认为1009</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.reducers.max=1009</span><br></pre></td></tr></table></figure>
<h6 id="c-计算reducer数的公式"><a href="#c-计算reducer数的公式" class="headerlink" title="(c )计算reducer数的公式"></a>(c )计算reducer数的公式</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">N=min(参数2=1009，总输入数据量/参数1=？)</span><br></pre></td></tr></table></figure>
<h5 id="2-调整reduce个数方法二"><a href="#2-调整reduce个数方法二" class="headerlink" title="(2).调整reduce个数方法二"></a>(2).调整reduce个数方法二</h5><p>在hadoop的mapred-default.xml文件中修改<br>设置每个job的Reduce个数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>
<h5 id="3-reduce个数并不是越多越好"><a href="#3-reduce个数并不是越多越好" class="headerlink" title="(3).reduce个数并不是越多越好"></a>(3).reduce个数并不是越多越好</h5><h6 id="a-过多的启动和初始化reduce也会消耗时间和资源；"><a href="#a-过多的启动和初始化reduce也会消耗时间和资源；" class="headerlink" title="(a)过多的启动和初始化reduce也会消耗时间和资源；"></a>(a)过多的启动和初始化reduce也会消耗时间和资源；</h6><h6 id="b-另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；"><a href="#b-另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；" class="headerlink" title="(b)另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；"></a>(b)另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p>
<h3 id="五-并行执行"><a href="#五-并行执行" class="headerlink" title="五. 并行执行"></a>五. 并行执行</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.parallel=true;              //打开任务并行执行,默认false</span><br><span class="line">set hive.exec.parallel.thread.number=16;  //同一个sql允许最大并行度，默认为8。</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p>
<h3 id="六-严格模式"><a href="#六-严格模式" class="headerlink" title="六.严格模式"></a>六.严格模式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;Hive提供了一个严格模式，可以防止用户执行那些可能意向不到的不好的影响的查询。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;通过设置属性hive.mapred.mode值为默认是非严格模式nonstrict 。开启严格模式需要修改hive.mapred.mode值为strict，开启严格模式可以禁止3种类型的查询。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.mode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>strict<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The mode in which the Hive operations are being performed. </span><br><span class="line">      In strict mode, some risky queries are not allowed to run. They include:</span><br><span class="line">        Cartesian Product.</span><br><span class="line">        No partition being picked up for a query.</span><br><span class="line">        Comparing bigints and strings.</span><br><span class="line">        Comparing bigints and doubles.</span><br><span class="line">        Orderby without limit.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>1.对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p>
<p>2.对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p>
<p>3.限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况</p>
<h3 id="七-JVM重用"><a href="#七-JVM重用" class="headerlink" title="七. JVM重用"></a>七. JVM重用</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;JVM重用是Hadoop调优参数的内容，其对Hive的性能具有非常大的影响，特别是对于很难避免小文件的场景或task特别多的场景，这类场景大多数执行时间都很短。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含有成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次。N的值可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间，具体多少需要根据具体业务场景测试得出。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.jvm.numtasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>How many tasks to run per jvm. If set to -1, there is</span><br><span class="line">  no limit. </span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p>
<h3 id="八-推测执行"><a href="#八-推测执行" class="headerlink" title="八.推测执行"></a>八.推测执行</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;在分布式集群环境下，因为程序Bug(包括Hadoop本身的bug)，负载不均衡或者资源分布不均等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务（比如一个作业的某个任务进度只有50%，而其他所有任务已经运行完毕），则这些任务会拖慢作业的整体执行进度。为了避免这种情况发生，Hadoop采用了推测执行（Speculative Execution）机制，它根据一定的法则推测出“拖后腿”的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;设置开启推测执行参数：Hadoop的mapred-site.xml文件中进行配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some map tasks may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some reduce tasks may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>不过hive本身也提供了配置项来控制reduce-side的推测执行：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.reduce.tasks.speculative.execution<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether speculative execution for reducers should be turned on. <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;关于调优这些推测执行变量，还很难给一个具体的建议。如果用户对于运行时的偏差非常敏感的话，那么可以将这些功能关闭掉。如果用户因为输入数据量很大而需要执行长时间的map或者Reduce task的话，那么启动推测执行造成的浪费是非常巨大大。</p>
<h3 id="九-压缩"><a href="#九-压缩" class="headerlink" title="九. 压缩"></a>九. 压缩</h3><p>详见之前的文章。</p>
<h3 id="十-执行计划-Explain"><a href="#十-执行计划-Explain" class="headerlink" title="十. 执行计划(Explain)"></a>十. 执行计划(Explain)</h3><h4 id="1-基本语法"><a href="#1-基本语法" class="headerlink" title="1.基本语法"></a>1.基本语法</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query</span><br></pre></td></tr></table></figure>
<h4 id="2-案例实操-1"><a href="#2-案例实操-1" class="headerlink" title="2.案例实操"></a>2.案例实操</h4><h5 id="1-查看下面这条语句的执行计划"><a href="#1-查看下面这条语句的执行计划" class="headerlink" title="(1)查看下面这条语句的执行计划"></a>(1)查看下面这条语句的执行计划</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; explain select * from emp;</span><br><span class="line">hive (default)&gt; explain select deptno, avg(sal) avg_sal from emp group by deptno;</span><br></pre></td></tr></table></figure>
<h5 id="2-查看详细执行计划"><a href="#2-查看详细执行计划" class="headerlink" title="(2)查看详细执行计划"></a>(2)查看详细执行计划</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; explain extended select * from emp;</span><br><span class="line">hive (default)&gt; explain extended select deptno, avg(sal) avg_sal from emp group by deptno;</span><br></pre></td></tr></table></figure>
<p>以下是在MySQL中的显示</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQxNWE3ZGNkMDJkNzUwZGYucG5n?x-oss-process=image/format,png"></p>
<p><strong>EXPLAIN字段</strong>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Table：显示这一行的数据是关于哪张表的</span><br><span class="line">possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句</span><br><span class="line">key：实际使用的索引。如果为NULL，则没有使用索引。MYSQL很少会选择优化不足的索引，此时可以在SELECT语句中使用USE INDEX（index）来强制使用一个索引或者用IGNORE INDEX（index）来强制忽略索引</span><br><span class="line">key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好</span><br><span class="line">ref：显示索引的哪一列被使用了，如果可能的话，是一个常数</span><br><span class="line">rows：MySQL认为必须检索的用来返回请求数据的行数</span><br><span class="line">type：这是最重要的字段之一，显示查询使用了何种类型。从最好到最差的连接类型为system、const、eq_reg、ref、range、index和ALL</span><br><span class="line">system、const：可以将查询的变量转为常量.  如id=1; id为 主键或唯一键.</span><br><span class="line">eq_ref：访问索引,返回某单一行的数据.(通常在联接时出现，查询使用的索引为主键或惟一键)</span><br><span class="line">ref：访问索引,返回某个值的数据.(可以返回多行) 通常使用=时发生</span><br><span class="line">range：这个连接类型使用索引返回一个范围中的行，比如使用&gt;或&lt;查找东西，并且该字段上建有索引时发生的情况(注:不一定好于index)</span><br><span class="line">index：以索引的顺序进行全表扫描，优点是不用排序,缺点是还要全表扫描</span><br><span class="line">ALL：全表扫描，应该尽量避免</span><br><span class="line">Extra：关于MYSQL如何解析查询的额外信息，主要有以下几种</span><br><span class="line">using index：只用到索引,可以避免访问表. </span><br><span class="line">using where：使用到where来过虑数据. 不是所有的where clause都要显示using where. 如以=方式访问索引.</span><br><span class="line">using tmporary：用到临时表</span><br><span class="line">using filesort：用到额外的排序. (当使用order by v1,而没用到索引时,就会使用额外的排序)</span><br><span class="line">range checked for eache record(index map:N)：没有好的索引.</span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive之函数"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E4%B9%8B%E5%87%BD%E6%95%B0/"
    >Hive之函数</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E4%B9%8B%E5%87%BD%E6%95%B0/" class="article-date">
  <time datetime="2019-07-15T12:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-系统自带的函数"><a href="#一-系统自带的函数" class="headerlink" title="一.系统自带的函数"></a>一.系统自带的函数</h3><h4 id="1-查看系统自带的函数"><a href="#1-查看系统自带的函数" class="headerlink" title="1.查看系统自带的函数"></a>1.查看系统自带的函数</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show <span class="built_in">functions</span>;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThjNDgzZWU2Y2QwYmZhNGMucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-显示自带的函数的用法"><a href="#2-显示自带的函数的用法" class="headerlink" title="2.显示自带的函数的用法"></a>2.显示自带的函数的用法</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc <span class="keyword">function</span> upper;</span></span><br></pre></td></tr></table></figure>
<h4 id="3-详细显示自带的函数的用法"><a href="#3-详细显示自带的函数的用法" class="headerlink" title="3.详细显示自带的函数的用法"></a>3.详细显示自带的函数的用法</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc <span class="keyword">function</span> extended upper;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWU5NTk5OTI2ZDE1OGFkMzIucG5n?x-oss-process=image/format,png"></p>
<h3 id="二-自定义函数"><a href="#二-自定义函数" class="headerlink" title="二. 自定义函数"></a>二. 自定义函数</h3><h4 id="1-Hive-自带了一些函数，比如：max-min等，但是数量有限，自己可以通过自定义UDF来方便的扩展。"><a href="#1-Hive-自带了一些函数，比如：max-min等，但是数量有限，自己可以通过自定义UDF来方便的扩展。" class="headerlink" title="1.Hive 自带了一些函数，比如：max/min等，但是数量有限，自己可以通过自定义UDF来方便的扩展。"></a>1.Hive 自带了一些函数，比如：max/min等，但是数量有限，自己可以通过自定义UDF来方便的扩展。</h4><h4 id="2-当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined-function）。"><a href="#2-当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined-function）。" class="headerlink" title="2.当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。"></a>2.当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。</h4><h4 id="3-根据用户自定义函数类别分为以下三种："><a href="#3-根据用户自定义函数类别分为以下三种：" class="headerlink" title="3.根据用户自定义函数类别分为以下三种："></a>3.根据用户自定义函数类别分为以下三种：</h4><h5 id="1-UDF-User-Defined-Function"><a href="#1-UDF-User-Defined-Function" class="headerlink" title="(1)UDF(User-Defined-Function)"></a>(1)UDF(User-Defined-Function)</h5><pre><code>    一进一出
</code></pre>
<h5 id="2-UDAF-User-Defined-Aggregation-Function"><a href="#2-UDAF-User-Defined-Aggregation-Function" class="headerlink" title="(2)UDAF(User-Defined Aggregation Function)"></a>(2)UDAF(User-Defined Aggregation Function)</h5><pre><code>    聚集函数，多进一出
    类似于：count/max/min
</code></pre>
<h5 id="3-UDTF-User-Defined-Table-Generating-Functions"><a href="#3-UDTF-User-Defined-Table-Generating-Functions" class="headerlink" title="(3)UDTF(User-Defined Table-Generating Functions)"></a>(3)UDTF(User-Defined Table-Generating Functions)</h5><pre><code>    一进多出
    如lateral view explore()
</code></pre>
<h4 id="4-官方文档地址"><a href="#4-官方文档地址" class="headerlink" title="4.官方文档地址"></a>4.官方文档地址</h4><p><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/HivePlugins">https://cwiki.apache.org/confluence/display/Hive/HivePlugins</a></p>
<h4 id="5-编程步骤："><a href="#5-编程步骤：" class="headerlink" title="5.编程步骤："></a>5.编程步骤：</h4><h5 id="1-继承org-apache-hadoop-hive-ql-UDF"><a href="#1-继承org-apache-hadoop-hive-ql-UDF" class="headerlink" title="(1)继承org.apache.hadoop.hive.ql.UDF"></a>(1)继承org.apache.hadoop.hive.ql.UDF</h5><h5 id="2-需要实现evaluate函数；evaluate函数支持重载；"><a href="#2-需要实现evaluate函数；evaluate函数支持重载；" class="headerlink" title="(2)需要实现evaluate函数；evaluate函数支持重载；"></a>(2)需要实现evaluate函数；evaluate函数支持重载；</h5><h5 id="3-在hive的命令行窗口创建函数"><a href="#3-在hive的命令行窗口创建函数" class="headerlink" title="(3)在hive的命令行窗口创建函数"></a>(3)在hive的命令行窗口创建函数</h5><h6 id="a-添加jar"><a href="#a-添加jar" class="headerlink" title="(a)添加jar"></a>(a)添加jar</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar linux_jar_path</span><br></pre></td></tr></table></figure>
<h6 id="b-创建function，"><a href="#b-创建function，" class="headerlink" title="(b)创建function，"></a>(b)创建function，</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create [temporary] function [dbname.]function_name AS class_name;</span><br></pre></td></tr></table></figure>
<h5 id="4-在hive的命令行窗口删除函数"><a href="#4-在hive的命令行窗口删除函数" class="headerlink" title="(4)在hive的命令行窗口删除函数"></a>(4)在hive的命令行窗口删除函数</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Drop [temporary] function [if exists] [dbname.]function_name;</span><br></pre></td></tr></table></figure>
<h4 id="6-注意事项"><a href="#6-注意事项" class="headerlink" title="6.注意事项"></a>6.注意事项</h4><h5 id="1-UDF必须要有返回类型，可以返回null，但是返回类型不能为void；"><a href="#1-UDF必须要有返回类型，可以返回null，但是返回类型不能为void；" class="headerlink" title="(1)UDF必须要有返回类型，可以返回null，但是返回类型不能为void；"></a>(1)UDF必须要有返回类型，可以返回null，但是返回类型不能为void；</h5><h3 id="三-自定义UDF函数开发案例"><a href="#三-自定义UDF函数开发案例" class="headerlink" title="三. 自定义UDF函数开发案例"></a>三. 自定义UDF函数开发案例</h3><h4 id="1-创建一个maven工程"><a href="#1-创建一个maven工程" class="headerlink" title="1.创建一个maven工程:"></a>1.创建一个maven工程:</h4><h4 id="2-将hive的jar包解压后，将apache-hive-1-2-1-bin-lib文件下的jar包都拷贝到java工程中。"><a href="#2-将hive的jar包解压后，将apache-hive-1-2-1-bin-lib文件下的jar包都拷贝到java工程中。" class="headerlink" title="2.将hive的jar包解压后，将apache-hive-1.2.1-bin\lib文件下的jar包都拷贝到java工程中。"></a>2.将hive的jar包解压后，将apache-hive-1.2.1-bin\lib文件下的jar包都拷贝到java工程中。</h4><h4 id="3-添加pomy依赖："><a href="#3-添加pomy依赖：" class="headerlink" title="3.添加pomy依赖："></a>3.添加pomy依赖：</h4><p>pom.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">       <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-metastore --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-metastore<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">       <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-jdbc --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">       <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-exec --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">       <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-common --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="4-创建一个类"><a href="#4-创建一个类" class="headerlink" title="4.创建一个类"></a>4.创建一个类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> HiveUDF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Lower</span> <span class="keyword">extends</span> <span class="title">UDF</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">evaluate</span> <span class="params">(<span class="keyword">final</span> String s)</span> </span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (s == <span class="keyword">null</span>) &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> s.toString().toLowerCase();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-打成jar包上传到服务器-opt-module-jars-Hive-1-0-SNAPSHOT-jar"><a href="#5-打成jar包上传到服务器-opt-module-jars-Hive-1-0-SNAPSHOT-jar" class="headerlink" title="5.打成jar包上传到服务器/opt/module/jars/Hive-1.0-SNAPSHOT.jar"></a>5.打成jar包上传到服务器/opt/module/jars/Hive-1.0-SNAPSHOT.jar</h4><h5 id="1-打包："><a href="#1-打包：" class="headerlink" title="(1)打包："></a>(1)打包：</h5><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTZhNDEzZmY4YTBhZDRiN2UucG5n?x-oss-process=image/format,png"></p>
<h5 id="2-上传："><a href="#2-上传：" class="headerlink" title="(2)上传："></a>(2)上传：</h5><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWFlNWU1YTE2YWIyZjJkMjQucG5n?x-oss-process=image/format,png" alt="上传"></p>
<h4 id="6-将jar包添加到hive的classpath"><a href="#6-将jar包添加到hive的classpath" class="headerlink" title="6.将jar包添加到hive的classpath"></a>6.将jar包添加到hive的classpath</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; add jar /opt/module/jars/Hive-1.0-SNAPSHOT.jar ;</span><br></pre></td></tr></table></figure>
<h4 id="7-创建临时函数与开发好的java-class关联-全类名"><a href="#7-创建临时函数与开发好的java-class关联-全类名" class="headerlink" title="7.创建临时函数与开发好的java class关联(全类名)"></a>7.创建临时函数与开发好的java class关联(全类名)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create temporary function udf_lower as &quot;HiveUDF.Lower&quot;;</span><br></pre></td></tr></table></figure>
<h4 id="8-即可在hql中使用自定义的函数strip"><a href="#8-即可在hql中使用自定义的函数strip" class="headerlink" title="8.即可在hql中使用自定义的函数strip"></a>8.即可在hql中使用自定义的函数strip</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename, udf_lower(ename) lowername from emp;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTM5NjY1NmY5Yzc4MTJiODgucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive之查询"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E4%B9%8B%E6%9F%A5%E8%AF%A2/"
    >Hive 查询</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E4%B9%8B%E6%9F%A5%E8%AF%A2/" class="article-date">
  <time datetime="2019-07-15T11:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-基本查询（Select…From）"><a href="#一-基本查询（Select…From）" class="headerlink" title="一.基本查询（Select…From）"></a>一.基本查询（Select…From）</h3><h4 id="1-全表和特定列查询"><a href="#1-全表和特定列查询" class="headerlink" title="1.全表和特定列查询"></a>1.全表和特定列查询</h4><h5 id="1-全表查询"><a href="#1-全表查询" class="headerlink" title="(1).全表查询"></a>(1).全表查询</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp;</span><br></pre></td></tr></table></figure>
<h5 id="2-选择特定列查询"><a href="#2-选择特定列查询" class="headerlink" title="(2).选择特定列查询"></a>(2).选择特定列查询</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select empno, ename from emp;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQwMGMzMGVhYTRjM2YxNTYucG5n?x-oss-process=image/format,png"></p>
<p>注意：</p>
<ul>
<li>SQL 语言大小写不敏感。</li>
<li>SQL 可以写在一行或者多行</li>
<li>关键字不能被缩写也不能分行</li>
<li>各子句一般要分行写。</li>
<li>使用缩进提高语句的可读性。</li>
</ul>
<h4 id="2-列别名"><a href="#2-列别名" class="headerlink" title="2. 列别名"></a>2. 列别名</h4><h5 id="1-重命名一个列。"><a href="#1-重命名一个列。" class="headerlink" title="(1).重命名一个列。"></a>(1).重命名一个列。</h5><h5 id="2-便于计算。"><a href="#2-便于计算。" class="headerlink" title="(2).便于计算。"></a>(2).便于计算。</h5><h5 id="3-紧跟列名，也可以在列名和别名之间加入关键字‘AS’"><a href="#3-紧跟列名，也可以在列名和别名之间加入关键字‘AS’" class="headerlink" title="(3).紧跟列名，也可以在列名和别名之间加入关键字‘AS’"></a>(3).紧跟列名，也可以在列名和别名之间加入关键字‘AS’</h5><h5 id="4-案例实操"><a href="#4-案例实操" class="headerlink" title="(4).案例实操"></a>(4).案例实操</h5><h6 id="a-查询名称和部门"><a href="#a-查询名称和部门" class="headerlink" title="(a)查询名称和部门"></a>(a)查询名称和部门</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename AS name, deptno dn from emp;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTlhNmE5NjY3MThlZGQ4MjcucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-算术运算符"><a href="#3-算术运算符" class="headerlink" title="3.算术运算符"></a>3.算术运算符</h4><table>
<thead>
<tr>
<th align="center">运算符</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">A+B</td>
<td align="center">A和B 相加</td>
</tr>
<tr>
<td align="center">A-B</td>
<td align="center">A减去B</td>
</tr>
<tr>
<td align="center">A*B</td>
<td align="center">A和B相乘</td>
</tr>
<tr>
<td align="center">A/B</td>
<td align="center">A除以B</td>
</tr>
<tr>
<td align="center">A%B</td>
<td align="center">A对B取余/模</td>
</tr>
<tr>
<td align="center">A&amp;B</td>
<td align="center">A和B按位取与</td>
</tr>
<tr>
<td align="center">A|B</td>
<td align="center">A和B按位取或</td>
</tr>
<tr>
<td align="center">A^B</td>
<td align="center">A和B按位取异或</td>
</tr>
<tr>
<td align="center">~A</td>
<td align="center">A按位取反</td>
</tr>
</tbody></table>
<h5 id="1-案例实操"><a href="#1-案例实操" class="headerlink" title="(1)案例实操"></a>(1)案例实操</h5><p>查询出所有员工的薪水后加1显示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select sal +1 from emp;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWVhMTMxNDJlZDc5MzY3NzkucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-常用函数"><a href="#4-常用函数" class="headerlink" title="4.常用函数"></a>4.常用函数</h4><h5 id="1-求总行数（count）"><a href="#1-求总行数（count）" class="headerlink" title="(1).求总行数（count）"></a>(1).求总行数（count）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(1) cnt from emp;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWYzYmEzOTQ3ZDMzNzgwM2MucG5n?x-oss-process=image/format,png"></p>
<h5 id="2-求工资的最大值（max）"><a href="#2-求工资的最大值（max）" class="headerlink" title="(2).求工资的最大值（max）"></a>(2).求工资的最大值（max）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select max(sal) max_sal from emp;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTM2MDYxYTZjNDA0ODc5NmYucG5n?x-oss-process=image/format,png"></p>
<h5 id="3-求工资的最小值（min）"><a href="#3-求工资的最小值（min）" class="headerlink" title="(3).求工资的最小值（min）"></a>(3).求工资的最小值（min）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select min(sal) min_sal from emp;</span><br></pre></td></tr></table></figure>
<h5 id="4-求工资的总和（sum）"><a href="#4-求工资的总和（sum）" class="headerlink" title="(4).求工资的总和（sum）"></a>(4).求工资的总和（sum）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select sum(sal) sum_sal from emp; </span><br></pre></td></tr></table></figure>
<h5 id="5-求工资的平均值（avg）"><a href="#5-求工资的平均值（avg）" class="headerlink" title="(5).求工资的平均值（avg）"></a>(5).求工资的平均值（avg）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select avg(sal) avg_sal from emp;</span><br></pre></td></tr></table></figure>
<h4 id="5-Limit语句"><a href="#5-Limit语句" class="headerlink" title="5.Limit语句"></a>5.Limit语句</h4><p>典型的查询会返回多行数据。LIMIT子句用于限制返回的行数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp limit 5;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThjODQ0ZjFkZTk2N2I3ZjIucG5n?x-oss-process=image/format,png"></p>
<h3 id="二-Where语句"><a href="#二-Where语句" class="headerlink" title="二.Where语句"></a>二.Where语句</h3><h4 id="0-定义"><a href="#0-定义" class="headerlink" title="0.定义"></a>0.定义</h4><h5 id="1-使用WHERE子句，将不满足条件的行过滤掉。"><a href="#1-使用WHERE子句，将不满足条件的行过滤掉。" class="headerlink" title="(1).使用WHERE子句，将不满足条件的行过滤掉。"></a>(1).使用WHERE子句，将不满足条件的行过滤掉。</h5><h5 id="2-WHERE子句紧随FROM子句。"><a href="#2-WHERE子句紧随FROM子句。" class="headerlink" title="(2).WHERE子句紧随FROM子句。"></a>(2).WHERE子句紧随FROM子句。</h5><h5 id="3-案例实操"><a href="#3-案例实操" class="headerlink" title="(3).案例实操"></a>(3).案例实操</h5><p>查询出薪水大于1000的所有员工</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename , sal from emp where sal &gt; 1000;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTY3NTU1NGI0YTU1YTk1NjgucG5n?x-oss-process=image/format,png"></p>
<h4 id="1-比较运算符（Between-In-Is-Null）"><a href="#1-比较运算符（Between-In-Is-Null）" class="headerlink" title="1.比较运算符（Between/In/ Is Null）"></a>1.比较运算符（Between/In/ Is Null）</h4><h5 id="1-下面表中描述了谓词操作符，这些操作符同样可以用于JOIN…ON和HAVING语句中。"><a href="#1-下面表中描述了谓词操作符，这些操作符同样可以用于JOIN…ON和HAVING语句中。" class="headerlink" title="(1).下面表中描述了谓词操作符，这些操作符同样可以用于JOIN…ON和HAVING语句中。"></a>(1).下面表中描述了谓词操作符，这些操作符同样可以用于JOIN…ON和HAVING语句中。</h5><table>
<thead>
<tr>
<th align="center">操作符</th>
<th align="center">支持的数据类型</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">A=B</td>
<td align="center">基本数据类型</td>
<td align="center">如果A等于B则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">A&lt;=&gt;B</td>
<td align="center">基本数据类型</td>
<td align="center">如果A和B都为NULL，则返回TRUE，其他的和等号（=）操作符的结果一致，如果任一为NULL则结果为NULL</td>
</tr>
<tr>
<td align="center">A&lt;&gt;B, A!=B</td>
<td align="center">基本数据类型</td>
<td align="center">A或者B为NULL则返回NULL；如果A不等于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">A&lt;B</td>
<td align="center">基本数据类型</td>
<td align="center">A或者B为NULL，则返回NULL；如果A小于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">A&lt;=B</td>
<td align="center">基本数据类型</td>
<td align="center">A或者B为NULL，则返回NULL；如果A小于等于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">A&gt;B</td>
<td align="center">基本数据类型</td>
<td align="center">A或者B为NULL，则返回NULL；如果A大于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">A&gt;=B</td>
<td align="center">基本数据类型</td>
<td align="center">A或者B为NULL，则返回NULL；如果A大于等于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">A [NOT] BETWEEN B AND C</td>
<td align="center">基本数据类型</td>
<td align="center">如果A，B或者C任一为NULL，则结果为NULL。如果A的值大于等于B而且小于或等于C，则结果为TRUE，反之为FALSE。如果使用NOT关键字则可达到相反的效果。</td>
</tr>
<tr>
<td align="center">A IS NULL</td>
<td align="center">所有数据类型</td>
<td align="center">如果A等于NULL，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">A IS NOT NULL</td>
<td align="center">所有数据类型</td>
<td align="center">如果A不等于NULL，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td align="center">IN(数值1, 数值2)</td>
<td align="center">所有数据类型</td>
<td align="center">使用 IN运算显示列表中的值</td>
</tr>
<tr>
<td align="center">A [NOT] LIKE B</td>
<td align="center">STRING 类型</td>
<td align="center">B是一个SQL下的简单正则表达式，如果A与其匹配的话，则返回TRUE；反之返回FALSE。B的表达式说明如下：‘x%’表示A必须以字母‘x’开头，‘%x’表示A必须以字母’x’结尾，而‘%x%’表示A包含有字母’x’,可以位于开头，结尾或者字符串中间。如果使用NOT关键字则可达到相反的效果。</td>
</tr>
<tr>
<td align="center">A RLIKE B, A REGEXP B</td>
<td align="center">STRING 类型</td>
<td align="center">B是一个正则表达式，如果A与其匹配，则返回TRUE；反之返回FALSE。匹配使用的是JDK中的正则表达式接口实现的，因为正则也依据其中的规则。例如，正则表达式必须和整个字符串A相匹配，而不是只需与其字符串匹配。</td>
</tr>
</tbody></table>
<h5 id="2-案例实操"><a href="#2-案例实操" class="headerlink" title="(2).案例实操"></a>(2).案例实操</h5><h6 id="a-查询出薪水等于5000的所有员工"><a href="#a-查询出薪水等于5000的所有员工" class="headerlink" title="(a)查询出薪水等于5000的所有员工"></a>(a)查询出薪水等于5000的所有员工</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal =5000;</span><br></pre></td></tr></table></figure>
<h6 id="b-查询工资在500到1000的员工信息，注意between-…-and-是闭区间"><a href="#b-查询工资在500到1000的员工信息，注意between-…-and-是闭区间" class="headerlink" title="(b)查询工资在500到1000的员工信息，注意between … and 是闭区间"></a>(b)查询工资在500到1000的员工信息，注意between … and 是闭区间</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal between 500 and 1000;</span><br></pre></td></tr></table></figure>
<h6 id="c-查询comm-奖金-为空的所有员工信息"><a href="#c-查询comm-奖金-为空的所有员工信息" class="headerlink" title="(c )查询comm(奖金)为空的所有员工信息"></a>(c )查询comm(奖金)为空的所有员工信息</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where comm is null;</span><br></pre></td></tr></table></figure>

<h6 id="d-查询工资是1500和5000的员工信息"><a href="#d-查询工资是1500和5000的员工信息" class="headerlink" title="(d)查询工资是1500和5000的员工信息"></a>(d)查询工资是1500和5000的员工信息</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal IN (1500, 5000);</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ2NmNmYmIwMWNlNmVjYTkucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-Like和RLike"><a href="#2-Like和RLike" class="headerlink" title="2.Like和RLike"></a>2.Like和RLike</h4><h5 id="1-使用LIKE运算选择类似的值"><a href="#1-使用LIKE运算选择类似的值" class="headerlink" title="(1).使用LIKE运算选择类似的值"></a>(1).使用LIKE运算选择类似的值</h5><h5 id="2-选择条件可以包含字符或数字"><a href="#2-选择条件可以包含字符或数字" class="headerlink" title="(2).选择条件可以包含字符或数字:"></a>(2).选择条件可以包含字符或数字:</h5><ul>
<li><p>% 代表零个或多个字符(任意个字符)。</p>
</li>
<li><p>_ 代表一个字符。</p>
</li>
</ul>
<h5 id="3-RLIKE子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件。"><a href="#3-RLIKE子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件。" class="headerlink" title="(3).RLIKE子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件。"></a>(3).RLIKE子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件。</h5><h5 id="4-案例实操-1"><a href="#4-案例实操-1" class="headerlink" title="(4).案例实操"></a>(4).案例实操</h5><h6 id="a-查找以2开头薪水的员工信息"><a href="#a-查找以2开头薪水的员工信息" class="headerlink" title="(a)查找以2开头薪水的员工信息"></a>(a)查找以2开头薪水的员工信息</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal LIKE &#x27;2%&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="b-查找第二个数值为2的薪水的员工信息"><a href="#b-查找第二个数值为2的薪水的员工信息" class="headerlink" title="(b)查找第二个数值为2的薪水的员工信息"></a>(b)查找第二个数值为2的薪水的员工信息</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal LIKE &#x27;_2%&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="c-查找薪水中含有2的员工信息"><a href="#c-查找薪水中含有2的员工信息" class="headerlink" title="(c )查找薪水中含有2的员工信息"></a>(c )查找薪水中含有2的员工信息</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal RLIKE &#x27;[2]&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQ2NjQxZDNmNDFiYmYzYmYucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-逻辑运算符（And-Or-Not）"><a href="#3-逻辑运算符（And-Or-Not）" class="headerlink" title="3.逻辑运算符（And/Or/Not）"></a>3.逻辑运算符（And/Or/Not）</h4><table>
<thead>
<tr>
<th align="center">操作符</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">AND</td>
<td align="center">逻辑并</td>
</tr>
<tr>
<td align="center">OR</td>
<td align="center">逻辑或</td>
</tr>
<tr>
<td align="center">NOT</td>
<td align="center">逻辑否</td>
</tr>
</tbody></table>
<p>案例实操</p>
<h5 id="1-查询薪水大于1000，部门是30"><a href="#1-查询薪水大于1000，部门是30" class="headerlink" title="(1)查询薪水大于1000，部门是30"></a>(1)查询薪水大于1000，部门是30</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal&gt;1000 and deptno=30;</span><br></pre></td></tr></table></figure>
<h5 id="2-查询薪水大于1000，或者部门是30"><a href="#2-查询薪水大于1000，或者部门是30" class="headerlink" title="(2)查询薪水大于1000，或者部门是30"></a>(2)查询薪水大于1000，或者部门是30</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal&gt;1000 or deptno=30;</span><br></pre></td></tr></table></figure>
<h5 id="3-查询除了20部门和30部门以外的员工信息"><a href="#3-查询除了20部门和30部门以外的员工信息" class="headerlink" title="(3)查询除了20部门和30部门以外的员工信息"></a>(3)查询除了20部门和30部门以外的员工信息</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where deptno not IN(30, 20);</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWRmNGVhYmEzODU2MGU0YjYucG5n?x-oss-process=image/format,png"></p>
<h3 id="三-分组"><a href="#三-分组" class="headerlink" title="三. 分组"></a>三. 分组</h3><h4 id="1-Group-By语句"><a href="#1-Group-By语句" class="headerlink" title="1.Group By语句"></a>1.Group By语句</h4><p>GROUP BY语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
<p>案例实操：</p>
<h5 id="1-计算emp表每个部门的平均工资"><a href="#1-计算emp表每个部门的平均工资" class="headerlink" title="(1)计算emp表每个部门的平均工资"></a>(1)计算emp表每个部门的平均工资</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select t.deptno, avg(t.sal) avg_sal from emp t group by t.deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWI3NWUxNDM1NTIxMTlhNGMucG5n?x-oss-process=image/format,png"></p>
<h5 id="2-计算emp每个部门中每个岗位的最高薪水"><a href="#2-计算emp每个部门中每个岗位的最高薪水" class="headerlink" title="(2)计算emp每个部门中每个岗位的最高薪水"></a>(2)计算emp每个部门中每个岗位的最高薪水</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select t.deptno, t.job, max(t.sal) max_sal from emp t group by t.deptno, t.job;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWNjYzIzODY3Y2Y4ZmNiNjEucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-Having语句"><a href="#2-Having语句" class="headerlink" title="2. Having语句"></a>2. Having语句</h4><h5 id="1-having与where不同点"><a href="#1-having与where不同点" class="headerlink" title="(1).having与where不同点"></a>(1).having与where不同点</h5><ul>
<li><p>where针对表中的列发挥作用，查询数据；having针对查询结果中的列发挥作用，筛选数据。</p>
</li>
<li><p>where后面不能写分组函数，而having后面可以使用分组函数。</p>
</li>
<li><p>having只用于group by分组统计语句。</p>
</li>
</ul>
<h5 id="2-案例实操："><a href="#2-案例实操：" class="headerlink" title="(2).案例实操："></a>(2).案例实操：</h5><h6 id="a-求每个部门的平均薪水大于2000的部门"><a href="#a-求每个部门的平均薪水大于2000的部门" class="headerlink" title="(a)求每个部门的平均薪水大于2000的部门"></a>(a)求每个部门的平均薪水大于2000的部门</h6><p>求每个部门的平均工资</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select deptno, avg(sal) from emp group by deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWFmMWY0YmZlMWYxNDViMDgucG5n?x-oss-process=image/format,png"></p>
<h6 id="b-求每个部门的平均薪水大于2000的部门"><a href="#b-求每个部门的平均薪水大于2000的部门" class="headerlink" title="(b)求每个部门的平均薪水大于2000的部门"></a>(b)求每个部门的平均薪水大于2000的部门</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select deptno, avg(sal) avg_sal from emp group by deptno having avg_sal &gt; 2000;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWI1YWZiYWY5ZDk3MmQxY2YucG5n?x-oss-process=image/format,png"></p>
<h3 id="四-Join语句"><a href="#四-Join语句" class="headerlink" title="四.Join语句"></a>四.Join语句</h3><h4 id="1-等值Join"><a href="#1-等值Join" class="headerlink" title="1.等值Join"></a>1.等值Join</h4><p>Hive支持通常的SQL JOIN语句，但是只支持等值连接，不支持非等值连接。</p>
<p>案例实操</p>
<h5 id="1-根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门编号；"><a href="#1-根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门编号；" class="headerlink" title="(1)根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门编号；"></a>(1)根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门编号；</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno, d.dname from emp e join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWEwZjA4ZTRiMDQ3ZmRkMWUucG5n?x-oss-process=image/format,png"></p>
<p>同样与</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno,e.ename,d.deptno,d.dname from emp e,dept d where e.deptno=d.deptno;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTIxZDBiZDdmNDA5ZGNkMDMucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-表的别名"><a href="#2-表的别名" class="headerlink" title="2. 表的别名"></a>2. 表的别名</h4><h5 id="1-好处"><a href="#1-好处" class="headerlink" title="(1).好处"></a>(1).好处</h5><ul>
<li>使用别名可以简化查询。</li>
<li>使用表名前缀可以提高执行效率。</li>
</ul>
<h5 id="2-案例实操-1"><a href="#2-案例实操-1" class="headerlink" title="(2).案例实操"></a>(2).案例实操</h5><p>合并员工表和部门表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTg2YTkzNGRmNTgwYmM1NDAucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-内连接"><a href="#3-内连接" class="headerlink" title="3.内连接"></a>3.内连接</h4><p>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWEyODAwZjRhMzAyMDU3YjEucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-左外连接"><a href="#4-左外连接" class="headerlink" title="4.左外连接"></a>4.左外连接</h4><p>左外连接：JOIN操作符左边表中符合WHERE子句的所有记录将会被返回。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e left join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ1MjdhOTg3OWM0OWMzNDIucG5n?x-oss-process=image/format,png"></p>
<h4 id="5-右外连接"><a href="#5-右外连接" class="headerlink" title="5.右外连接"></a>5.右外连接</h4><p>右外连接：JOIN操作符右边表中符合WHERE子句的所有记录将会被返回。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e right join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTViZjc0NDRhYjg1OTViZGYucG5n?x-oss-process=image/format,png"></p>
<h4 id="6-满外连接"><a href="#6-满外连接" class="headerlink" title="6.满外连接"></a>6.满外连接</h4><p>满外连接：将会返回所有表中符合WHERE语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用NULL值替代。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e full join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWM0NzY4NWMyM2I5YzgyNmYucG5n?x-oss-process=image/format,png"></p>
<h4 id="7-多表连接"><a href="#7-多表连接" class="headerlink" title="7.多表连接"></a>7.多表连接</h4><p>注意：连接 n个表，至少需要n-1个连接条件。例如：连接三个表，至少需要两个连接条件。</p>
<h5 id="0-数据准备"><a href="#0-数据准备" class="headerlink" title="(0)数据准备"></a>(0)数据准备</h5><h5 id="1-创建位置表"><a href="#1-创建位置表" class="headerlink" title="(1)创建位置表"></a>(1)创建位置表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists default.location(</span><br><span class="line">loc int,</span><br><span class="line">loc_name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-导入数据"><a href="#2-导入数据" class="headerlink" title="(2)导入数据"></a>(2)导入数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/location.txt&#x27; into table default.location;</span><br></pre></td></tr></table></figure>
<h5 id="3-多表连接查询distinct"><a href="#3-多表连接查询distinct" class="headerlink" title="(3)多表连接查询distinct"></a>(3)多表连接查询distinct</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;SELECT e.ename, d.deptno, l. loc_name</span><br><span class="line">              FROM   emp e </span><br><span class="line">              JOIN   dept d</span><br><span class="line">              ON     d.deptno = e.deptno </span><br><span class="line">              JOIN   location l</span><br><span class="line">              ON     d.loc = l.loc;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ5ZDQxZmVhZDM2NDBmYzMucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWYwZTQyNDJiNWRiNjQyZDMucG5n?x-oss-process=image/format,png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;大多数情况下，Hive会对每对JOIN连接对象启动一个MapReduce任务。本例中会首先启动一个MapReduce job对表e和表d进行连接操作，然后会再启动一个MapReduce job将第一个MapReduce job的输出和表l;进行连接操作。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;注意：为什么不是表d和表l先进行连接操作呢？这是因为Hive总是按照从左到右的顺序执行的。</p>
<h4 id="8-笛卡尔积"><a href="#8-笛卡尔积" class="headerlink" title="8.笛卡尔积"></a>8.笛卡尔积</h4><h5 id="1-笛卡尔集会在下面条件下产生"><a href="#1-笛卡尔集会在下面条件下产生" class="headerlink" title="(1).笛卡尔集会在下面条件下产生:"></a>(1).笛卡尔集会在下面条件下产生:</h5><ul>
<li>省略连接条件</li>
<li>连接条件无效</li>
<li>所有表中的所有行互相连接</li>
</ul>
<h5 id="2-案例实操-2"><a href="#2-案例实操-2" class="headerlink" title="(2).案例实操"></a>(2).案例实操</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select empno, deptno from emp, dept;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ4YmIwMGM3Njk5YmZkM2UucG5n?x-oss-process=image/format,png"></p>
<p>FAILED: SemanticException Column deptno Found in more than One Tables/Subqueries</p>
<h4 id="9-连接谓词中不支持or"><a href="#9-连接谓词中不支持or" class="headerlink" title="9.连接谓词中不支持or"></a>9.连接谓词中不支持or</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno = d.deptno or e.ename=d.ename;  </span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWVmYWZiZWQyNjI1MGRjMTAucG5n?x-oss-process=image/format,png"></p>
<h3 id="五-排序"><a href="#五-排序" class="headerlink" title="五.排序"></a>五.排序</h3><h4 id="1-全局排序（Order-By）"><a href="#1-全局排序（Order-By）" class="headerlink" title="1.全局排序（Order By）"></a>1.全局排序（Order By）</h4><p>Order By：全局排序，一个MapReduce</p>
<h5 id="1-使用-ORDER-BY-子句排序"><a href="#1-使用-ORDER-BY-子句排序" class="headerlink" title="(1).使用 ORDER BY 子句排序"></a>(1).使用 ORDER BY 子句排序</h5><ul>
<li>ASC（ascend）: 升序（默认）</li>
<li>DESC（descend）: 降序</li>
</ul>
<h5 id="2-ORDER-BY-子句在SELECT语句的结尾。"><a href="#2-ORDER-BY-子句在SELECT语句的结尾。" class="headerlink" title="(2).ORDER BY 子句在SELECT语句的结尾。"></a>(2).ORDER BY 子句在SELECT语句的结尾。</h5><h5 id="3-案例实操-1"><a href="#3-案例实操-1" class="headerlink" title="(3).案例实操"></a>(3).案例实操</h5><h6 id="a-查询员工信息按工资升序排列"><a href="#a-查询员工信息按工资升序排列" class="headerlink" title="(a)查询员工信息按工资升序排列"></a>(a)查询员工信息按工资升序排列</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp order by sal;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTJlMjUyMDlmOGNkYWI4MzgucG5n?x-oss-process=image/format,png"></p>
<h6 id="b-查询员工信息按工资降序排列"><a href="#b-查询员工信息按工资降序排列" class="headerlink" title="(b)查询员工信息按工资降序排列"></a>(b)查询员工信息按工资降序排列</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp order by sal desc;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ4ODFjYTdjZGJkNGU3NzUucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-按照别名排序"><a href="#2-按照别名排序" class="headerlink" title="2.按照别名排序"></a>2.按照别名排序</h4><p>按照员工薪水的2倍排序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename, sal*2 twosal from emp order by twosal;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTgwMTJiNDdkZDVkNDkzNjUucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-多个列排序"><a href="#3-多个列排序" class="headerlink" title="3.多个列排序"></a>3.多个列排序</h4><p>按照部门和工资升序排序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename, deptno, sal from emp order by deptno, sal ;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTY5YTgwYjRlZDUyNGU1ZGEucG5n?x-oss-process=image/format,png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;注：这个是先按部门号排序，部门号相同，按薪水升序排序</p>
<h4 id="4-每个MapReduce内部排序-Sort-By"><a href="#4-每个MapReduce内部排序-Sort-By" class="headerlink" title="4.每个MapReduce内部排序(Sort By)"></a>4.每个MapReduce内部排序(Sort By)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;Sort By：每个MapReduce内部进行排序，分区规则按照key的hash来运算，(区内排序)对全局结果集来说不是排序。</p>
<h5 id="1-设置reduce个数"><a href="#1-设置reduce个数" class="headerlink" title="(1).设置reduce个数"></a>(1).设置reduce个数</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br></pre></td></tr></table></figure>
<h5 id="2-查看设置reduce个数"><a href="#2-查看设置reduce个数" class="headerlink" title="(2).查看设置reduce个数"></a>(2).查看设置reduce个数</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces;</span><br></pre></td></tr></table></figure>
<h5 id="3-根据部门编号降序查看员工信息"><a href="#3-根据部门编号降序查看员工信息" class="headerlink" title="(3).根据部门编号降序查看员工信息"></a>(3).根据部门编号降序查看员工信息</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp sort by empno desc;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWFkNGU1YzRjMzhkZTQ5MDkucG5n?x-oss-process=image/format,png"></p>
<h5 id="4-将查询结果导入到文件中（按照部门编号降序排序）"><a href="#4-将查询结果导入到文件中（按照部门编号降序排序）" class="headerlink" title="(4).将查询结果导入到文件中（按照部门编号降序排序）"></a>(4).将查询结果导入到文件中（按照部门编号降序排序）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory &#x27;/opt/module/datas/emp.txt&#x27; row format delimited fields terminated by &#x27;\t&#x27; select * from emp sort by deptno desc;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTNkYzNlODlkMDkzZjVmZDgucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWVkODYxNGI5MWZjZjZiZTMucG5n?x-oss-process=image/format,png"></p>
<h4 id="5-分区排序（Distribute-By）"><a href="#5-分区排序（Distribute-By）" class="headerlink" title="5.分区排序（Distribute By）"></a>5.分区排序（Distribute By）</h4><p>Distribute By：类似MR中partition，进行分区，结合sort by使用。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;注意，Hive要求DISTRIBUTE BY语句要写在SORT BY语句之前。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</p>
<p>案例实操：</p>
<h5 id="1-先按照部门编号分区，再按照员工编号降序排序。"><a href="#1-先按照部门编号分区，再按照员工编号降序排序。" class="headerlink" title="(1)先按照部门编号分区，再按照员工编号降序排序。"></a>(1)先按照部门编号分区，再按照员工编号降序排序。</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; insert overwrite local directory &#x27;/opt/module/datas/distribute-result&#x27; row format delimited fields terminated by &#x27;\t&#x27; select * from emp distribute by deptno sort by empno desc;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTk5YTA3OWM1N2MxMzQ0MzkucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWNiMjM0NTM3MjNhZGQ2NTkucG5n?x-oss-process=image/format,png"></p>
<h4 id="6-Cluster-By"><a href="#6-Cluster-By" class="headerlink" title="6.Cluster By"></a>6.Cluster By</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;当distribute by和sorts by字段相同时，可以使用cluster by方式。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是倒序排序，不能指定排序规则为ASC或者DESC。</p>
<h5 id="1-以下两种写法等价"><a href="#1-以下两种写法等价" class="headerlink" title="(1).以下两种写法等价"></a>(1).以下两种写法等价</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory &#x27;/opt/module/datas/cluster-result&#x27; row format delimited fields terminated by &#x27;\t&#x27; select * from emp cluster by deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWE3YjlmYWUxNDQ3ZjBlN2IucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTZlNjkwZDQwYTA3MGU3OTgucG5n?x-oss-process=image/format,png"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp distribute by deptno sort by deptno;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThkZjAyNmFkNjEyZmUwZjcucG5n?x-oss-process=image/format,png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;注意：按照部门编号分区，不一定就是固定死的数值，可以是20号和30号部门分到一个分区里面去。</p>
<h3 id="六-分桶及抽样查询"><a href="#六-分桶及抽样查询" class="headerlink" title="六.分桶及抽样查询"></a>六.分桶及抽样查询</h3><h4 id="1-分桶表数据存储"><a href="#1-分桶表数据存储" class="headerlink" title="1.分桶表数据存储"></a>1.分桶表数据存储</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;分区针对的是数据的存储路径；分桶针对的是数据文件。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区，特别是之前所提到过的要确定合适的划分大小这个疑虑。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;分桶是将数据集分解成更容易管理的若干部分的另一个技术。</p>
<h5 id="1-先创建分桶表，通过直接导入数据文件的方式"><a href="#1-先创建分桶表，通过直接导入数据文件的方式" class="headerlink" title="(1).先创建分桶表，通过直接导入数据文件的方式"></a>(1).先创建分桶表，通过直接导入数据文件的方式</h5><h6 id="a-数据准备"><a href="#a-数据准备" class="headerlink" title="(a)数据准备"></a>(a)数据准备</h6><h6 id="b-创建分桶表"><a href="#b-创建分桶表" class="headerlink" title="(b)创建分桶表"></a>(b)创建分桶表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table stu_buck(id int, name string)</span><br><span class="line">clustered by(id) </span><br><span class="line">into 4 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="c-查看表结构"><a href="#c-查看表结构" class="headerlink" title="(c )查看表结构"></a>(c )查看表结构</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted stu_buck;</span><br></pre></td></tr></table></figure>
<p>Num Buckets:            4<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTBhNzExNTA1NDE5YjhhOTMucG5n?x-oss-process=image/format,png"></p>
<h6 id="d-导入数据到分桶表中"><a href="#d-导入数据到分桶表中" class="headerlink" title="(d)导入数据到分桶表中"></a>(d)导入数据到分桶表中</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/s/student.txt&#x27; into table stu_buck;</span><br></pre></td></tr></table></figure>
<h6 id="e-查看创建的分桶表中是否分成4个桶"><a href="#e-查看创建的分桶表中是否分成4个桶" class="headerlink" title="(e)查看创建的分桶表中是否分成4个桶"></a>(e)查看创建的分桶表中是否分成4个桶</h6><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWE0ZWRhNTQ1YTNlYmU4MWQucG5n?x-oss-process=image/format,png"></p>
<p>发现并没有分成4个桶。是什么原因呢？</p>
<h5 id="2-创建分桶表时，数据通过子查询的方式导入"><a href="#2-创建分桶表时，数据通过子查询的方式导入" class="headerlink" title="(2).创建分桶表时，数据通过子查询的方式导入"></a>(2).创建分桶表时，数据通过子查询的方式导入</h5><h6 id="a-先建一个普通的stu表"><a href="#a-先建一个普通的stu表" class="headerlink" title="(a)先建一个普通的stu表"></a>(a)先建一个普通的stu表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table stu(id int, name string)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<h6 id="b-向普通的stu表中导入数据"><a href="#b-向普通的stu表中导入数据" class="headerlink" title="(b)向普通的stu表中导入数据"></a>(b)向普通的stu表中导入数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/datas/s/student.txt&#x27; into table stu;</span><br></pre></td></tr></table></figure>
<h6 id="c-清空stu-buck表中数据"><a href="#c-清空stu-buck表中数据" class="headerlink" title="(c )清空stu_buck表中数据"></a>(c )清空stu_buck表中数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">truncate table stu_buck;</span><br><span class="line"></span><br><span class="line">select * from stu_buck;</span><br></pre></td></tr></table></figure>
<h6 id="d-导入数据到分桶表，通过子查询的方式"><a href="#d-导入数据到分桶表，通过子查询的方式" class="headerlink" title="(d)导入数据到分桶表，通过子查询的方式"></a>(d)导入数据到分桶表，通过子查询的方式</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert into table stu_buck</span><br><span class="line">select id, name from stu;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTJkYjA5YzU5ZTE3YzQ1NTQucG5n?x-oss-process=image/format,png"></p>
<h6 id="e-发现还是只有一个分桶"><a href="#e-发现还是只有一个分桶" class="headerlink" title="(e)发现还是只有一个分桶"></a>(e)发现还是只有一个分桶</h6><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThiNjMxMjliOGRhMjA2YmYucG5n?x-oss-process=image/format,png"></p>
<h6 id="g-需要设置一个属性"><a href="#g-需要设置一个属性" class="headerlink" title="(g)需要设置一个属性"></a>(g)需要设置一个属性</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.enforce.bucketing=true;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; set mapreduce.job.reduces=-1;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; truncate table stu_buck;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; insert into table stu_buck</span><br><span class="line">select id, name from stu;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTAwMTNkNDQ1ODlhY2QxNzcucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQzMmY4NTUwMWYwZDg4NjQucG5n?x-oss-process=image/format,png"></p>
<h6 id="h-查询分桶的数据"><a href="#h-查询分桶的数据" class="headerlink" title="(h)查询分桶的数据"></a>(h)查询分桶的数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from stu_buck;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWFjNzYwZmE5ZmExNTIyYWIucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-分桶抽样查询"><a href="#2-分桶抽样查询" class="headerlink" title="2.分桶抽样查询"></a>2.分桶抽样查询</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。</p>
<p>查询表stu_buck中的数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from stu_buck tablesample(bucket 1 out of 4 on id);</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTJkM2M0ZGY4ZGJlMGVkYTYucG5n?x-oss-process=image/format,png"></p>
<p>注：tablesample是抽样语句，语法：TABLESAMPLE(BUCKET x OUT OF y) 。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from stu_buck tablesample(bucket 1 out of 3 on id);</span><br></pre></td></tr></table></figure>
<p>不是桶数的倍数或者因子也可以，但是不推荐。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;y必须是table总bucket数的倍数或者因子。hive根据y的大小，决定抽样的比例。例如，table总共分了4份，当y=2时，抽取(4/2=)2个bucket的数据，当y=8时，抽取(4/8=)1/2个bucket的数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from stu_buck tablesample(bucket 1 out of 2 on id);</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWU3NmFmZGM3NDhmMTlmZGYucG5n?x-oss-process=image/format,png" alt="image.png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;x表示从哪个bucket开始抽取。例如，table总bucket数为4，tablesample(bucket 4 out of 4)，表示总共抽取（4/4=）1个bucket的数据，抽取第4个bucket的数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from stu_buck tablesample(bucket 1 out of 8 on id);</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTgyNjE4MTI0N2ViZTgyMjUucG5n?x-oss-process=image/format,png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;注意：x的值必须小于等于y的值，否则</p>
<p>FAILED: SemanticException [Error 10061]: Numerator should not be bigger than denominator in sample clause for table stu_buck</p>
<h4 id="3-数据块抽样"><a href="#3-数据块抽样" class="headerlink" title="3.数据块抽样"></a>3.数据块抽样</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;Hive提供了另外一种按照百分比进行抽样的方式，这种是基于行数的，按照输入路径下的数据块百分比进行的抽样。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from stu tablesample(0.1 percent) ;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTBmNzQxZDY1ZTNiMmRiNzYucG5n?x-oss-process=image/format,png"></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;提示：这种抽样方式不一定适用于所有的文件格式。另外，这种抽样的最小抽样单元是一个HDFS数据块。因此，如果表的数据大小小于普通的块大小128M的话，那么将会返回所有行。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive之DML数据操作"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E4%B9%8BDML%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"
    >Hive DML数据操作</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E4%B9%8BDML%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/" class="article-date">
  <time datetime="2019-07-15T10:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-数据导入"><a href="#一-数据导入" class="headerlink" title="一. 数据导入"></a>一. 数据导入</h3><h4 id="1-向表中装载数据（Load）"><a href="#1-向表中装载数据（Load）" class="headerlink" title="1.向表中装载数据（Load）"></a>1.向表中装载数据（Load）</h4><h5 id="1-语法"><a href="#1-语法" class="headerlink" title="(1).语法"></a>(1).语法</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash">load data [<span class="built_in">local</span>] inpath <span class="string">&#x27;/opt/module/datas/student.txt&#x27;</span> [overwrite] into table student [partition (partcol1=val1,…)];</span></span><br></pre></td></tr></table></figure>

<p>(a)load data:表示加载数据<br>(b)local:表示从本地加载数据到hive表；否则从HDFS加载数据到hive表<br>(c )inpath:表示加载数据的路径<br>(d)overwrite:表示覆盖表中已有数据，否则表示追加<br>(e)into table:表示加载到哪张表<br>(f)student:表示具体的表名<br>(g)partition:表示上传到指定分区</p>
<h5 id="2-实操案例"><a href="#2-实操案例" class="headerlink" title="(2).实操案例"></a>(2).实操案例</h5><h6 id="a-创建一张表"><a href="#a-创建一张表" class="headerlink" title="(a)创建一张表"></a>(a)创建一张表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table student (id string, name string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="b-加载本地文件到hive"><a href="#b-加载本地文件到hive" class="headerlink" title="(b)加载本地文件到hive"></a>(b)加载本地文件到hive</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/student.txt&#x27; into table default.student;</span><br></pre></td></tr></table></figure>
<h6 id="c-加载HDFS文件到hive中"><a href="#c-加载HDFS文件到hive中" class="headerlink" title="(c)加载HDFS文件到hive中"></a>(c)加载HDFS文件到hive中</h6><p>上传文件到HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt /user/movle/hive;</span><br></pre></td></tr></table></figure>

<p>加载HDFS上数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;load data inpath &#x27;/user/movle/hive/student.txt&#x27; into table default.student;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWM1ZTVjODkyOTIyNGVhMmMucG5n?x-oss-process=image/format,png"></p>
<h6 id="d-加载数据覆盖表中已有的数据"><a href="#d-加载数据覆盖表中已有的数据" class="headerlink" title="(d)加载数据覆盖表中已有的数据"></a>(d)加载数据覆盖表中已有的数据</h6><p>上传文件到HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt /user/movle/hive/;</span><br></pre></td></tr></table></figure>
<p>加载数据覆盖表中已有的数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;load data inpath &#x27;/user/movle/hive/student.txt&#x27; overwrite into table default.student;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ4ZjkxM2U4ZDJkMWIzODIucG5n?x-oss-process=image/format,png"></p>
<p>注：load hdfs的数据相当于mv文件到另一个目录中，原目录文件消失</p>
<h4 id="2-通过查询语句向表中插入数据-Insert"><a href="#2-通过查询语句向表中插入数据-Insert" class="headerlink" title="2. 通过查询语句向表中插入数据(Insert)"></a>2. 通过查询语句向表中插入数据(Insert)</h4><h5 id="1-创建一张分区表"><a href="#1-创建一张分区表" class="headerlink" title="(1)创建一张分区表"></a>(1)创建一张分区表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table student6(id int, name string) partitioned by (month string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-基本插入数据"><a href="#2-基本插入数据" class="headerlink" title="(2)基本插入数据"></a>(2)基本插入数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert into table  student6 partition(month=&#x27;201909&#x27;) values(1,&#x27;wangwu&#x27;);</span><br></pre></td></tr></table></figure>
<h5 id="3-基本模式插入-根据单张表查询结果"><a href="#3-基本模式插入-根据单张表查询结果" class="headerlink" title="(3)基本模式插入(根据单张表查询结果)"></a>(3)基本模式插入(根据单张表查询结果)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite table student6 partition(month=&#x27;201908&#x27;)</span><br><span class="line">             select id, name from student6 where month=&#x27;201909&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTRiMTY0MGZjMjU0Mzk1NDYucG5n?x-oss-process=image/format,png"></p>
<h5 id="4-多插入模式-根据多张表查询结果"><a href="#4-多插入模式-根据多张表查询结果" class="headerlink" title="(4)多插入模式(根据多张表查询结果)"></a>(4)多插入模式(根据多张表查询结果)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; from student6</span><br><span class="line">              insert overwrite table student6 partition(month=&#x27;201907&#x27;)</span><br><span class="line">              select id, name where month=&#x27;201909&#x27;</span><br><span class="line">              insert overwrite table student6 partition(month=&#x27;201906&#x27;)</span><br><span class="line">              select id, name where month=&#x27;201909&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTY3YTY5ODA2NjU2ZDBjMTYucG5n?x-oss-process=image/format,png"></p>
<h5 id="3-查询语句中创建表并加载数据-As-Select"><a href="#3-查询语句中创建表并加载数据-As-Select" class="headerlink" title="3.查询语句中创建表并加载数据(As Select)"></a>3.查询语句中创建表并加载数据(As Select)</h5><p>详见5章创建表。<br>根据查询结果创建表（查询的结果会添加到新创建的表中）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student7</span><br><span class="line">as select id, name from student;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTRjZDNhMDAwZDYxYzFlZDQucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-创建表时通过Location指定加载数据路径"><a href="#4-创建表时通过Location指定加载数据路径" class="headerlink" title="4.创建表时通过Location指定加载数据路径"></a>4.创建表时通过Location指定加载数据路径</h4><h5 id="1-创建表，并指定在hdfs上的位置"><a href="#1-创建表，并指定在hdfs上的位置" class="headerlink" title="(1).创建表，并指定在hdfs上的位置"></a>(1).创建表，并指定在hdfs上的位置</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table if not exists student5(</span><br><span class="line">              id int, name string</span><br><span class="line">              )</span><br><span class="line">              row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line">              location &#x27;/user/hive/warehouse/student5&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-上传数据到hdfs上"><a href="#2-上传数据到hdfs上" class="headerlink" title="(2)上传数据到hdfs上"></a>(2)上传数据到hdfs上</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt  /user/hive/warehouse/student5;</span><br></pre></td></tr></table></figure>
<h5 id="3-查询数据"><a href="#3-查询数据" class="headerlink" title="(3)查询数据"></a>(3)查询数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from student5;</span><br></pre></td></tr></table></figure>
<h4 id="5-Import数据到指定Hive表中"><a href="#5-Import数据到指定Hive表中" class="headerlink" title="5.Import数据到指定Hive表中"></a>5.Import数据到指定Hive表中</h4><p>注意：先用export导出后，再将数据导入。同在HDFS上是Copy级操作<br>先导出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; export table default.student6 to &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>

<p>再导入：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; import table student2 partition(month=&#x27;201909&#x27;) from &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWY5NmQxZDliZWVkYWQ5NzAucG5n?x-oss-process=image/format,png"></p>
<h3 id="二-数据导出"><a href="#二-数据导出" class="headerlink" title="二. 数据导出"></a>二. 数据导出</h3><h4 id="1-Insert导出"><a href="#1-Insert导出" class="headerlink" title="1. Insert导出"></a>1. Insert导出</h4><h5 id="1-将查询的结果导出到本地-数据之间无间隔"><a href="#1-将查询的结果导出到本地-数据之间无间隔" class="headerlink" title="(1).将查询的结果导出到本地,数据之间无间隔"></a>(1).将查询的结果导出到本地,数据之间无间隔</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory &#x27;/opt/module/datas/export/student&#x27;</span><br><span class="line">            select * from student;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTkzYmQ5ZTMwNTNiZGQyMWUucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTU1ZTk5M2M2ZWRjYTRlMzEucG5n?x-oss-process=image/format,png"></p>
<h5 id="2-将查询的结果格式化导出到本地-数据之间”-t”间隔"><a href="#2-将查询的结果格式化导出到本地-数据之间”-t”间隔" class="headerlink" title="(2)将查询的结果格式化导出到本地,数据之间”\t”间隔"></a>(2)将查询的结果格式化导出到本地,数据之间”\t”间隔</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory &#x27;/opt/module/datas/export/student1&#x27;</span><br><span class="line">             ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;             </span><br><span class="line">             select * from student;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWY3ZTY3NzA0YTlmNjM3NDQucG5n?x-oss-process=image/format,png"></p>
<h5 id="3-将查询的结果导出到HDFS上-没有local"><a href="#3-将查询的结果导出到HDFS上-没有local" class="headerlink" title="(3)将查询的结果导出到HDFS上(没有local)"></a>(3)将查询的结果导出到HDFS上(没有local)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite directory &#x27;/user/movle/student2&#x27;</span><br><span class="line">             ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27; </span><br><span class="line">             select * from student;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWZlY2VhZmNmNWU2YjllOGYucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTdjMTMwMTBiNjg5MzEzMjgucG5n?x-oss-process=image/format,png"></p>
<p>注：虽然同是HDFS，但不是copy操作</p>
<h4 id="2-Hadoop命令导出到本地"><a href="#2-Hadoop命令导出到本地" class="headerlink" title="2.Hadoop命令导出到本地"></a>2.Hadoop命令导出到本地</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -get /user/hive/warehouse/student6/month=201909/000000_0  /opt/module/datas/export/student3.txt;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTJjMWQyNWYxNTYxNGYzODYucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-Hive-Shell-命令导出"><a href="#3-Hive-Shell-命令导出" class="headerlink" title="3.Hive Shell 命令导出"></a>3.Hive Shell 命令导出</h4><p>基本语法：(hive -f/-e 执行语句或者脚本 &gt; file)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive -e &#x27;select * from default.student;&#x27; &gt; /opt/module/datas/export/student4.txt;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTMwYTI0Nzk0Yzc1YjdjOTAucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-Export导出到HDFS上"><a href="#4-Export导出到HDFS上" class="headerlink" title="4. Export导出到HDFS上"></a>4. Export导出到HDFS上</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; export table default.student to &#x27;/user/hive/warehouse/export/student2&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTc2MTAwOWU4YmVmYzg5NDkucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTdmODY5NzFkZDgxNzI2MjAucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTU4NzAyOWFkYzUxZmM4M2YucG5n?x-oss-process=image/format,png"></p>
<h4 id="5-Sqoop导出"><a href="#5-Sqoop导出" class="headerlink" title="5.Sqoop导出"></a>5.Sqoop导出</h4><h3 id="三-清除表中数据-Truncate"><a href="#三-清除表中数据-Truncate" class="headerlink" title="三.清除表中数据(Truncate)"></a>三.清除表中数据(Truncate)</h3><p>注意：Truncate只能删除管理表，不能删除外部表中数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; truncate table student;</span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive DDL数据定义"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%20DDL%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89/"
    >Hive DDL数据定义</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%20DDL%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89/" class="article-date">
  <time datetime="2019-07-15T09:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-创建数据库"><a href="#一-创建数据库" class="headerlink" title="一.创建数据库"></a>一.创建数据库</h3><h4 id="1-创建一个数据库，数据库在HDFS上的默认存储路径是-user-hive-warehouse-db。"><a href="#1-创建一个数据库，数据库在HDFS上的默认存储路径是-user-hive-warehouse-db。" class="headerlink" title="1.创建一个数据库，数据库在HDFS上的默认存储路径是/user/hive/warehouse/*.db。"></a>1.创建一个数据库，数据库在HDFS上的默认存储路径是/user/hive/warehouse/*.db。</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create database db_hive;</span><br></pre></td></tr></table></figure>
<p><strong>可能出现的报错：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:For direct MetaStore DB connections, we don&#x27;t support retries at the client level.)</span><br></pre></td></tr></table></figure>
<p><strong>解决办法</strong>：<a target="_blank" rel="noopener" href="https://blog.csdn.net/mo_ing/article/details/81219533">https://blog.csdn.net/mo_ing/article/details/81219533</a></p>
<p>个人解决版本：使用mysql-connector-java-5.1.27.jar，而不是mysql-connector-java-5.1.18.jar</p>
<h4 id="2-避免要创建的数据库已经存在错误，增加if-not-exists判断。（标准写法）"><a href="#2-避免要创建的数据库已经存在错误，增加if-not-exists判断。（标准写法）" class="headerlink" title="2.避免要创建的数据库已经存在错误，增加if not exists判断。（标准写法）"></a>2.避免要创建的数据库已经存在错误，增加if not exists判断。（标准写法）</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> create database db_hive;</span></span><br></pre></td></tr></table></figure>
<p>FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database db_hive already exists</p>
<p>标准写法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create database if not exists db_hive;</span><br></pre></td></tr></table></figure>

<h4 id="3-创建一个数据库，指定数据库在HDFS上存放的位置"><a href="#3-创建一个数据库，指定数据库在HDFS上存放的位置" class="headerlink" title="3.创建一个数据库，指定数据库在HDFS上存放的位置"></a>3.创建一个数据库，指定数据库在HDFS上存放的位置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create database db_hive2 location &#x27;/db_hive2.db&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTBiNGUzNTY2NjU2MTA3MWMucG5n?x-oss-process=image/format,png"></p>
<h3 id="二-修改数据库"><a href="#二-修改数据库" class="headerlink" title="二.修改数据库"></a>二.修改数据库</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;用户可以使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。数据库的其他元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter database db_hive set dbproperties(&#x27;createtime&#x27;=&#x27;20190506&#x27;);</span><br></pre></td></tr></table></figure>
<p>在mysql中查看修改结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc database extended db_hive;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTgxY2E4NDU2MjczM2YyYjcucG5n?x-oss-process=image/format,png"></p>
<h3 id="三-查询数据库"><a href="#三-查询数据库" class="headerlink" title="三.查询数据库"></a>三.查询数据库</h3><h4 id="1-显示数据库"><a href="#1-显示数据库" class="headerlink" title="1.显示数据库"></a>1.显示数据库</h4><h5 id="1-显示数据库-1"><a href="#1-显示数据库-1" class="headerlink" title="(1)显示数据库"></a>(1)显示数据库</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show databases;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-过滤显示查询的数据库"><a href="#2-过滤显示查询的数据库" class="headerlink" title="(2)过滤显示查询的数据库"></a>(2)过滤显示查询的数据库</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show databases like <span class="string">&#x27;db_hive*&#x27;</span>;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ4YTEzMzkxZDQ5OThhZTEucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-查看数据库详情"><a href="#2-查看数据库详情" class="headerlink" title="2. 查看数据库详情"></a>2. 查看数据库详情</h4><h5 id="1-显示数据库信息"><a href="#1-显示数据库信息" class="headerlink" title="(1)显示数据库信息"></a>(1)显示数据库信息</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc database db_hive;</span></span><br></pre></td></tr></table></figure>

<h5 id="2-显示数据库详细信息，extended"><a href="#2-显示数据库详细信息，extended" class="headerlink" title="(2)显示数据库详细信息，extended"></a>(2)显示数据库详细信息，extended</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc database extended db_hive;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTM1NDI4N2ExN2E3MjE3MGUucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-切换当前数据库"><a href="#3-切换当前数据库" class="headerlink" title="3.切换当前数据库"></a>3.切换当前数据库</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; use db_hive;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTMxOWI2ZDkzMTQ1NTdiMGYucG5n?x-oss-process=image/format,png" alt="image.png"></p>
<h3 id="四-删除数据库"><a href="#四-删除数据库" class="headerlink" title="四.删除数据库"></a>四.删除数据库</h3><h4 id="1-删除空数据库"><a href="#1-删除空数据库" class="headerlink" title="1.删除空数据库"></a>1.删除空数据库</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash">drop database db_hive2;</span></span><br></pre></td></tr></table></figure>
<h4 id="2-如果删除的数据库不存在，最好采用-if-exists判断数据库是否存在"><a href="#2-如果删除的数据库不存在，最好采用-if-exists判断数据库是否存在" class="headerlink" title="2.如果删除的数据库不存在，最好采用 if exists判断数据库是否存在"></a>2.如果删除的数据库不存在，最好采用 if exists判断数据库是否存在</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> drop database db_hive2;</span></span><br></pre></td></tr></table></figure>
<p>正确做法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> drop database <span class="keyword">if</span> exists db_hive2;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTBlMmVmMTgyMGQ4NTFjOTkucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-如果数据库不为空，可以采用cascade命令，强制删除"><a href="#3-如果数据库不为空，可以采用cascade命令，强制删除" class="headerlink" title="3.如果数据库不为空，可以采用cascade命令，强制删除"></a>3.如果数据库不为空，可以采用cascade命令，强制删除</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> drop database db_hive;</span></span><br></pre></td></tr></table></figure>
<p>正确做法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> drop database db_hive cascade;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThlYTEwOTk5OTJmMjNiMzkucG5n?x-oss-process=image/format,png"></p>
<h3 id="五-创建表"><a href="#五-创建表" class="headerlink" title="五.创建表"></a>五.创建表</h3><h4 id="1-建表语法"><a href="#1-建表语法" class="headerlink" title="1.建表语法"></a>1.建表语法</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name </span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[(col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line"></span><br><span class="line">[COMMENT table_comment] </span><br><span class="line"></span><br><span class="line">[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line"></span><br><span class="line">[CLUSTERED BY (col_name, col_name, ...) </span><br><span class="line"></span><br><span class="line">[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] </span><br><span class="line"></span><br><span class="line">[ROW FORMAT row_format] </span><br><span class="line"></span><br><span class="line">[STORED AS file_format] </span><br><span class="line"></span><br><span class="line">[LOCATION hdfs_path]</span><br></pre></td></tr></table></figure>

<h4 id="2-字段解释说明："><a href="#2-字段解释说明：" class="headerlink" title="2..字段解释说明："></a>2..字段解释说明：</h4><h5 id="1-CREATE-TABLE-创建一个指定名字的表。"><a href="#1-CREATE-TABLE-创建一个指定名字的表。" class="headerlink" title="(1)CREATE TABLE 创建一个指定名字的表。"></a>(1)CREATE TABLE 创建一个指定名字的表。</h5><p>如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</p>
<h5 id="2-EXTERNAL关键字可以让用户创建一个外部表"><a href="#2-EXTERNAL关键字可以让用户创建一个外部表" class="headerlink" title="(2)EXTERNAL关键字可以让用户创建一个外部表"></a>(2)EXTERNAL关键字可以让用户创建一个外部表</h5><p>在建表的同时指定一个指向实际数据的路径(LOCATION)，Hive创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</p>
<h5 id="3-COMMENT：为表和列添加注释。"><a href="#3-COMMENT：为表和列添加注释。" class="headerlink" title="(3)COMMENT：为表和列添加注释。"></a>(3)COMMENT：为表和列添加注释。</h5><h5 id="4-PARTITIONED-BY-创建分区表"><a href="#4-PARTITIONED-BY-创建分区表" class="headerlink" title="(4)PARTITIONED BY   创建分区表"></a>(4)PARTITIONED BY   创建分区表</h5><h5 id="5-CLUSTERED-BY-创建分桶表"><a href="#5-CLUSTERED-BY-创建分桶表" class="headerlink" title="(5)CLUSTERED BY  创建分桶表"></a>(5)CLUSTERED BY  创建分桶表</h5><h5 id="6-SORTED-BY-不常用"><a href="#6-SORTED-BY-不常用" class="headerlink" title="(6)SORTED BY    不常用"></a>(6)SORTED BY    不常用</h5><h5 id="7-ROW-FORMAT"><a href="#7-ROW-FORMAT" class="headerlink" title="(7)ROW FORMAT"></a>(7)ROW FORMAT</h5><p>DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, …)]</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;用户在建表的时候可以自定义SerDe或者使用自带的SerDe。如果没有指定ROW FORMAT 或者ROW FORMAT DELIMITED，将会使用自带的SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的SerDe，Hive通过SerDe确定表的具体的列的数据。</p>
<h5 id="8-STORED-AS指定存储文件类型"><a href="#8-STORED-AS指定存储文件类型" class="headerlink" title="(8)STORED AS指定存储文件类型"></a>(8)STORED AS指定存储文件类型</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;常用的存储文件类型：SEQUENCEFILE(二进制序列文件)、TEXTFILE(文本)、RCFILE(列式存储格式文件)<br>&nbsp;&nbsp;&nbsp;&nbsp;如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</p>
<h5 id="9-LOCATION-：指定表在HDFS上的存储位置。"><a href="#9-LOCATION-：指定表在HDFS上的存储位置。" class="headerlink" title="(9)LOCATION ：指定表在HDFS上的存储位置。"></a>(9)LOCATION ：指定表在HDFS上的存储位置。</h5><h5 id="10-LIKE允许用户复制现有的表结构，但是不复制数据。"><a href="#10-LIKE允许用户复制现有的表结构，但是不复制数据。" class="headerlink" title="(10)LIKE允许用户复制现有的表结构，但是不复制数据。"></a>(10)LIKE允许用户复制现有的表结构，但是不复制数据。</h5><h3 id="六-管理表"><a href="#六-管理表" class="headerlink" title="六.管理表"></a>六.管理表</h3><h4 id="1-理论"><a href="#1-理论" class="headerlink" title="1.理论"></a>1.理论</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive会（或多或少地）控制着数据的生命周期。Hive默认情况下会将这些表的数据存储在由配置项hive.metastore.warehouse.dir(例如，/user/hive/warehouse)所定义的目录的子目录下。   当我们删除一个管理表时，Hive也会删除这个表中数据。管理表不适合和其他工具共享数据。</p>
<h4 id="2-案例实操"><a href="#2-案例实操" class="headerlink" title="2.案例实操"></a>2.案例实操</h4><h5 id="1-普通创建表"><a href="#1-普通创建表" class="headerlink" title="(1)普通创建表"></a>(1)普通创建表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student2(</span><br><span class="line"></span><br><span class="line">id int, name string</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">stored as textfile</span><br><span class="line"></span><br><span class="line">location &#x27;/user/hive/warehouse/student2&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-根据查询结果创建表（查询的结果会添加到新创建的表中）"><a href="#2-根据查询结果创建表（查询的结果会添加到新创建的表中）" class="headerlink" title="(2)根据查询结果创建表（查询的结果会添加到新创建的表中）"></a>(2)根据查询结果创建表（查询的结果会添加到新创建的表中）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student3</span><br><span class="line">as select id from student;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTI0NTA4Mzc0MWMwMzU3OTQucG5n?x-oss-process=image/format,png"></p>
<h5 id="3-根据已经存在的表结构创建表"><a href="#3-根据已经存在的表结构创建表" class="headerlink" title="(3)根据已经存在的表结构创建表"></a>(3)根据已经存在的表结构创建表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student4 like student;</span><br></pre></td></tr></table></figure>

<h5 id="4-查询表的类型"><a href="#4-查询表的类型" class="headerlink" title="(4)查询表的类型"></a>(4)查询表的类型</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student4;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQ5ZDQ2NjQ3MGIxZWZlNTkucG5n?x-oss-process=image/format,png"></p>
<h3 id="七-外部表"><a href="#七-外部表" class="headerlink" title="七. 外部表"></a>七. 外部表</h3><h4 id="1-理论-1"><a href="#1-理论-1" class="headerlink" title="1.理论"></a>1.理论</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;因为表是外部表，所以Hive并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉。</p>
<h4 id="2-管理表和外部表的使用场景："><a href="#2-管理表和外部表的使用场景：" class="headerlink" title="2.管理表和外部表的使用场景："></a>2.管理表和外部表的使用场景：</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;每天将收集到的网站日志定期流入HDFS文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过SELECT+INSERT进入内部表。</p>
<h4 id="3-案例实操"><a href="#3-案例实操" class="headerlink" title="3.案例实操"></a>3.案例实操</h4><p>分别创建部门和员工外部表，并向表中导入数据。</p>
<h5 id="1-原始数据"><a href="#1-原始数据" class="headerlink" title="(1)原始数据"></a>(1)原始数据</h5><h5 id="2-建表语句"><a href="#2-建表语句" class="headerlink" title="(2)建表语句"></a>(2)建表语句</h5><p>创建部门表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists default.dept(</span><br><span class="line">deptno int,</span><br><span class="line">dname string,</span><br><span class="line">loc int</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTU5YWY5OTI0MjIwZGViZmYucG5n?x-oss-process=image/format,png"><br>创建员工表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists default.emp(</span><br><span class="line">empno int,</span><br><span class="line">ename string,</span><br><span class="line">job string,</span><br><span class="line">mgr int,</span><br><span class="line">hiredate string, </span><br><span class="line">sal double, </span><br><span class="line">comm double,</span><br><span class="line">deptno int)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="3-查看创建的表"><a href="#3-查看创建的表" class="headerlink" title="(3)查看创建的表"></a>(3)查看创建的表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; show tables;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTNiMTI0NzZjZWEzYWZmNWMucG5n?x-oss-process=image/format,png" alt="查看创建的表"></p>
<h5 id="4-向外部表中导入数据"><a href="#4-向外部表中导入数据" class="headerlink" title="(4)向外部表中导入数据"></a>(4)向外部表中导入数据</h5><p>导入数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table default.dept;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/emp.txt&#x27; into table default.emp;</span><br></pre></td></tr></table></figure>
<p>查询结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from dept;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWRkZjliMWFhOTQ1YjQ1NDMucG5n?x-oss-process=image/format,png"></p>
<h5 id="5-查看表格式化数据"><a href="#5-查看表格式化数据" class="headerlink" title="(5)查看表格式化数据"></a>(5)查看表格式化数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted dept;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTgzNGYzNDM4NzYxZmFiN2EucG5n?x-oss-process=image/format,png"></p>
<h3 id="八-分区表"><a href="#八-分区表" class="headerlink" title="八.分区表"></a>八.分区表</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。Hive中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过WHERE子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</p>
<h4 id="1-分区表基本操作"><a href="#1-分区表基本操作" class="headerlink" title="1.分区表基本操作"></a>1.分区表基本操作</h4><h5 id="1-引入分区表（需要根据日期对日志进行管理）"><a href="#1-引入分区表（需要根据日期对日志进行管理）" class="headerlink" title="(1)引入分区表（需要根据日期对日志进行管理）"></a>(1)引入分区表（需要根据日期对日志进行管理）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/user/hive/warehouse/log_partition/20190702/20190702.log</span><br><span class="line"></span><br><span class="line">/user/hive/warehouse/log_partition/20190703/20190703.log</span><br><span class="line"></span><br><span class="line">/user/hive/warehouse/log_partition/20190704/20190704.log</span><br></pre></td></tr></table></figure>
<h5 id="2-创建分区表语法"><a href="#2-创建分区表语法" class="headerlink" title="(2)创建分区表语法"></a>(2)创建分区表语法</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table dept_partition(</span><br><span class="line">               deptno int, dname string, loc string</span><br><span class="line">               )</span><br><span class="line">               partitioned by (month string)</span><br><span class="line">               row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="3-加载数据到分区表中"><a href="#3-加载数据到分区表中" class="headerlink" title="(3)加载数据到分区表中"></a>(3)加载数据到分区表中</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table default.dept_partition partition(month=&#x27;201909&#x27;);</span><br><span class="line"></span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table default.dept_partition partition(month=&#x27;201908&#x27;);</span><br><span class="line"></span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table default.dept_partition partition(month=&#x27;201907&#x27;);</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTIwNWRjM2RkZDg0ODk3NWIucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWJjNGFmM2RiZThhYTgxMzcucG5n?x-oss-process=image/format,png"></p>
<h5 id="4-查询分区表中数据"><a href="#4-查询分区表中数据" class="headerlink" title="(4)查询分区表中数据"></a>(4)查询分区表中数据</h5><p>单分区查询</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition where month=&#x27;201909&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTBiZTg5MGUyM2U2NWQxMzUucG5n?x-oss-process=image/format,png"></p>
<p>多分区联合查询</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition where month=&#x27;201909&#x27;</span><br><span class="line">              union</span><br><span class="line">              select * from dept_partition where month=&#x27;201908&#x27;</span><br><span class="line">              union</span><br><span class="line">              select * from dept_partition where month=&#x27;201907&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTBjODAxYmRkYTMyZDlkYjgucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWI5MWRmZGY0ZjJhNWYyM2MucG5n?x-oss-process=image/format,png"></p>
<h5 id="5-增加分区"><a href="#5-增加分区" class="headerlink" title="(5)增加分区"></a>(5)增加分区</h5><p>创建单个分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition add partition(month=&#x27;201906&#x27;) ;</span><br></pre></td></tr></table></figure>
<p>同时创建多个分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;  alter table dept_partition add partition(month=&#x27;201905&#x27;) partition(month=&#x27;201904&#x27;);</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQzNDQ2M2NiNGRlM2EyZWYucG5n?x-oss-process=image/format,png"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWU1MTZkNDRjMzI0YTVhZjMucG5n?x-oss-process=image/format,png"></p>
<p>注：增加多个分区之间用空格” “隔开，删除多个分区用”,”隔开</p>
<h5 id="6-删除分区"><a href="#6-删除分区" class="headerlink" title="(6)删除分区"></a>(6)删除分区</h5><p>删除单个分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition drop partition (month=&#x27;201904&#x27;);</span><br></pre></td></tr></table></figure>
<p>同时删除多个分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition drop partition (month=&#x27;201905&#x27;), partition (month=&#x27;201906&#x27;);</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTIyNjI0ZTc2MDg3MTBlMDMucG5n?x-oss-process=image/format,png"></p>
<h5 id="7-查看分区表有多少分区"><a href="#7-查看分区表有多少分区" class="headerlink" title="(7)查看分区表有多少分区"></a>(7)查看分区表有多少分区</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> show partitions dept_partition;</span></span><br></pre></td></tr></table></figure>
<h5 id="8-查看分区表结构"><a href="#8-查看分区表结构" class="headerlink" title="(8)查看分区表结构"></a>(8)查看分区表结构</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc formatted dept_partition;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWQxZmZmZWRhNjFkMWRjN2EucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-分区表注意事项"><a href="#2-分区表注意事项" class="headerlink" title="2.分区表注意事项"></a>2.分区表注意事项</h4><h5 id="1-创建二级分区表"><a href="#1-创建二级分区表" class="headerlink" title="(1).创建二级分区表"></a>(1).创建二级分区表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table dept_partition2(</span><br><span class="line">               deptno int, dname string, loc string</span><br><span class="line">               )</span><br><span class="line">               partitioned by (month string, day string)</span><br><span class="line">               row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-正常的加载数据"><a href="#2-正常的加载数据" class="headerlink" title="(2).正常的加载数据"></a>(2).正常的加载数据</h5><h6 id="a-加载数据到二级分区表中"><a href="#a-加载数据到二级分区表中" class="headerlink" title="(a)加载数据到二级分区表中"></a>(a)加载数据到二级分区表中</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table default.dept_partition2 partition(month=&#x27;201909&#x27;, day=&#x27;13&#x27;);</span><br></pre></td></tr></table></figure>
<h6 id="b-查询分区数据"><a href="#b-查询分区数据" class="headerlink" title="(b)查询分区数据"></a>(b)查询分区数据</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition2 where month=&#x27;201909&#x27; and day=&#x27;13&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWFiYzAwMmY0MmE1ZmJlZGEucG5n?x-oss-process=image/format,png"></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTI5MTdlZjI3NTY3NzM5OGMucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-把数据直接上传到分区目录上，让分区表和数据产生关联的两种方式"><a href="#3-把数据直接上传到分区目录上，让分区表和数据产生关联的两种方式" class="headerlink" title="3.把数据直接上传到分区目录上，让分区表和数据产生关联的两种方式"></a>3.把数据直接上传到分区目录上，让分区表和数据产生关联的两种方式</h4><h5 id="1-方式一：上传数据后修复"><a href="#1-方式一：上传数据后修复" class="headerlink" title="(1)方式一：上传数据后修复"></a>(1)方式一：上传数据后修复</h5><p>上传数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201909/day=12;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/dept.txt /user/hive/warehouse/dept_partition2/month=201909/day=12;</span><br></pre></td></tr></table></figure>

<p>查询数据（查询不到刚上传的数据）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition2 where month=&#x27;201909&#x27; and day=&#x27;12&#x27;;</span><br></pre></td></tr></table></figure>
<p>执行修复命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash">msck repair table dept_partition2;</span></span><br></pre></td></tr></table></figure>
<p>再次查询数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition2 where month=&#x27;201909&#x27; and day=&#x27;12&#x27;;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTMwNzIzNGJhZmYzMGMxZDIucG5n?x-oss-process=image/format,png"></p>
<h5 id="2-方式二：上传数据后添加分区"><a href="#2-方式二：上传数据后添加分区" class="headerlink" title="(2)方式二：上传数据后添加分区"></a>(2)方式二：上传数据后添加分区</h5><p>上传数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201909/day=11;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/dept.txt /user/hive/warehouse/dept_partition2/month=201909/day=11;</span><br></pre></td></tr></table></figure>
<p>执行添加分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition2 add partition(month=&#x27;201909&#x27;, day=&#x27;11&#x27;);</span><br></pre></td></tr></table></figure>
<p>查询数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition2 where month=&#x27;201909&#x27; and day=&#x27;11&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWUyNDhjNWVhOTY1ZGRlNmEucG5n?x-oss-process=image/format,png"></p>
<h5 id="3-方式三：上传数据后load数据到分区"><a href="#3-方式三：上传数据后load数据到分区" class="headerlink" title="(3)方式三：上传数据后load数据到分区"></a>(3)方式三：上传数据后load数据到分区</h5><p>创建目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -mkdir -p /user/hive/warehouse/dept_partition2/month=201909/day=10;</span><br></pre></td></tr></table></figure>
<p>上传数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table dept_partition2 partition(month=&#x27;201909&#x27;,day=&#x27;10&#x27;);</span><br></pre></td></tr></table></figure>
<p>查询数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from dept_partition2 where month=&#x27;201909&#x27; and day=&#x27;10&#x27;;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTc3MjE3MjlmMzY3NzQyNGQucG5n?x-oss-process=image/format,png"></p>
<h3 id="九-修改表"><a href="#九-修改表" class="headerlink" title="九.修改表"></a>九.修改表</h3><h4 id="1-重命名表"><a href="#1-重命名表" class="headerlink" title="1.重命名表"></a>1.重命名表</h4><h5 id="1-语法"><a href="#1-语法" class="headerlink" title="(1).语法"></a>(1).语法</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name RENAME TO new_table_name</span><br></pre></td></tr></table></figure>
<h5 id="2-实操案例"><a href="#2-实操案例" class="headerlink" title="(2).实操案例"></a>(2).实操案例</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition2 rename to dept_partition4;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTU4MmQ2MGJjZmFjZGE3N2YucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-增加和删除表分区"><a href="#2-增加和删除表分区" class="headerlink" title="2. 增加和删除表分区"></a>2. 增加和删除表分区</h4><p>详见1.6.1分区表基本操作。同上</p>
<h4 id="3-增加-修改-替换列信息"><a href="#3-增加-修改-替换列信息" class="headerlink" title="3. 增加/修改/替换列信息"></a>3. 增加/修改/替换列信息</h4><h5 id="1-语法-1"><a href="#1-语法-1" class="headerlink" title="(1).语法"></a>(1).语法</h5><p>更新列</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</span><br></pre></td></tr></table></figure>

<p>增加和替换列</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...) </span><br></pre></td></tr></table></figure>
<p>注：ADD是代表新增一字段，字段位置在所有列后面(partition列前)，REPLACE则是表示替换表中所有字段。</p>
<h5 id="2-实操案例-1"><a href="#2-实操案例-1" class="headerlink" title="(2).实操案例"></a>(2).实操案例</h5><h6 id="a-查询表结构"><a href="#a-查询表结构" class="headerlink" title="(a)查询表结构"></a>(a)查询表结构</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash"> desc dept_partition;</span></span><br></pre></td></tr></table></figure>
<h6 id="b-添加列"><a href="#b-添加列" class="headerlink" title="(b)添加列"></a>(b)添加列</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition add columns(deptdesc string);</span><br></pre></td></tr></table></figure>
<h6 id="c-查询表结构"><a href="#c-查询表结构" class="headerlink" title="(c )查询表结构"></a>(c )查询表结构</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash">desc dept_partition;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWZjMzZhZWI2NmE4YTUyNjMucG5n?x-oss-process=image/format,png"></p>
<h6 id="d-更新列"><a href="#d-更新列" class="headerlink" title="(d)更新列"></a>(d)更新列</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition change column deptdesc desc int;</span><br></pre></td></tr></table></figure>
<h6 id="e-查询表结构"><a href="#e-查询表结构" class="headerlink" title="(e)查询表结构"></a>(e)查询表结构</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash">desc dept_partition;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThiODRiNjc1ODEwN2U5OTQucG5n?x-oss-process=image/format,png"></p>
<h6 id="f-替换列"><a href="#f-替换列" class="headerlink" title="(f)替换列"></a>(f)替换列</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition replace columns(deptno string, dname string, loc string);</span><br></pre></td></tr></table></figure>
<h6 id="g-查询表结构"><a href="#g-查询表结构" class="headerlink" title="(g)查询表结构"></a>(g)查询表结构</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">hive&gt;</span><span class="bash">desc dept_partition;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTBhMDEzYzJmMWQzNDgwYTUucG5n?x-oss-process=image/format,png"></p>
<h3 id="十-删除表"><a href="#十-删除表" class="headerlink" title="十.删除表"></a>十.删除表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; drop table dept_partition;</span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive将本地文件导入Hive案例"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5Hive%E6%A1%88%E4%BE%8B/"
    >Hive将本地文件导入Hive案例</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5Hive%E6%A1%88%E4%BE%8B/" class="article-date">
  <time datetime="2019-07-15T08:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="0-需求："><a href="#0-需求：" class="headerlink" title="0.需求："></a>0.需求：</h4><p>将本地/opt/module/datas/student.txt这个目录下的数据导入到hive的student(id int, name string)表中。</p>
<h4 id="1-数据准备：在-opt-module-datas-student-txt这个目录下准备数据"><a href="#1-数据准备：在-opt-module-datas-student-txt这个目录下准备数据" class="headerlink" title="1.数据准备：在/opt/module/datas/student.txt这个目录下准备数据"></a>1.数据准备：在/opt/module/datas/student.txt这个目录下准备数据</h4><h5 id="1-在-opt-module-目录下创建datas"><a href="#1-在-opt-module-目录下创建datas" class="headerlink" title="(1)在/opt/module/目录下创建datas"></a>(1)在/opt/module/目录下创建datas</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir datas</span><br></pre></td></tr></table></figure>
<h5 id="2-在-opt-module-datas-目录下创建student-txt文件并添加数据"><a href="#2-在-opt-module-datas-目录下创建student-txt文件并添加数据" class="headerlink" title="(2)在/opt/module/datas/目录下创建student.txt文件并添加数据"></a>(2)在/opt/module/datas/目录下创建student.txt文件并添加数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">touch student.txt</span><br><span class="line">vi student.txt</span><br></pre></td></tr></table></figure>
<p>添加内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1001	zhangshan</span><br><span class="line">1002	lishi</span><br><span class="line">1003	zhaoliu</span><br></pre></td></tr></table></figure>
<p>注意以tab键间隔。</p>
<h4 id="2-Hive实际操作"><a href="#2-Hive实际操作" class="headerlink" title="2.Hive实际操作"></a>2.Hive实际操作</h4><h5 id="1-启动hive"><a href="#1-启动hive" class="headerlink" title="(1)启动hive"></a>(1)启动hive</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive</span><br></pre></td></tr></table></figure>
<h5 id="2-显示数据库"><a href="#2-显示数据库" class="headerlink" title="(2)显示数据库"></a>(2)显示数据库</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show databases;</span><br></pre></td></tr></table></figure>
<h5 id="3-使用default数据库"><a href="#3-使用default数据库" class="headerlink" title="(3)使用default数据库"></a>(3)使用default数据库</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use default;</span><br></pre></td></tr></table></figure>
<h5 id="4-显示default数据库中的表"><a href="#4-显示default数据库中的表" class="headerlink" title="(4)显示default数据库中的表"></a>(4)显示default数据库中的表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show tables;</span><br></pre></td></tr></table></figure>
<h5 id="5-删除已创建的student表"><a href="#5-删除已创建的student表" class="headerlink" title="(5)删除已创建的student表"></a>(5)删除已创建的student表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop table student;</span><br></pre></td></tr></table></figure>
<h5 id="6-创建student表-并声明文件分隔符’-t’"><a href="#6-创建student表-并声明文件分隔符’-t’" class="headerlink" title="(6)创建student表, 并声明文件分隔符’\t’"></a>(6)创建student表, 并声明文件分隔符’\t’</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table student(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="7-加载-opt-module-datas-student-txt-文件到student数据库表中。"><a href="#7-加载-opt-module-datas-student-txt-文件到student数据库表中。" class="headerlink" title="(7)加载/opt/module/datas/student.txt 文件到student数据库表中。"></a>(7)加载/opt/module/datas/student.txt 文件到student数据库表中。</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/datas/student.txt&#x27; into table student;</span><br></pre></td></tr></table></figure>
<h5 id="8-Hive查询结果"><a href="#8-Hive查询结果" class="headerlink" title="(8)Hive查询结果"></a>(8)Hive查询结果</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from student;</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWIxOWRjMWI0YTNiM2Q5ZjcucG5n?x-oss-process=image/format,png" alt="image.png"></p>
<p><strong>可能是编码的问题吧，留个坑</strong><br>在hdfs中就是正常的，所以应该是格式问题</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQyYjVjMmZmYzQ3YzQ0ZjYucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive参数配置方式"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F/"
    >Hive参数配置方式</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F/" class="article-date">
  <time datetime="2019-07-15T07:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-查看当前所有的配置信息"><a href="#1-查看当前所有的配置信息" class="headerlink" title="1.查看当前所有的配置信息"></a>1.查看当前所有的配置信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTcxYjk1MzhhMzViZjU4NWQucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-参数的配置三种方式"><a href="#2-参数的配置三种方式" class="headerlink" title="2.参数的配置三种方式"></a>2.参数的配置三种方式</h4><h5 id="1-配置文件方式"><a href="#1-配置文件方式" class="headerlink" title="(1)配置文件方式"></a>(1)配置文件方式</h5><ul>
<li>默认配置文件：hive-default.xml </li>
<li>用户自定义配置文件：hive-site.xml</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;注意：用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。</p>
<h5 id="2-命令行参数方式"><a href="#2-命令行参数方式" class="headerlink" title="(2)命令行参数方式"></a>(2)命令行参数方式</h5><p>启动Hive时，可以在命令行添加-hiveconf param=value来设定参数。<br>例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive -hiveconf mapred.reduce.tasks=10;</span><br></pre></td></tr></table></figure>
<p>注意：仅对本次hive启动有效<br>查看参数设置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br></pre></td></tr></table></figure>
<p>显示为：mapred.reduce.tasks=10<br>默认mapred.reduce.tasks=-1</p>
<h5 id="3-参数声明方式"><a href="#3-参数声明方式" class="headerlink" title="(3)参数声明方式"></a>(3)参数声明方式</h5><p>可以在HQL中使用SET关键字设定参数<br>例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks=10;</span><br></pre></td></tr></table></figure>
<p>注意：仅对本次hive启动有效。<br>查看参数设置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br></pre></td></tr></table></figure>
<p>上述三种设定方式的优先级依次递增。即配置文件&lt;命令行参数&lt;参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive常见属性配置"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E5%B8%B8%E8%A7%81%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE/"
    >Hive常见属性配置</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E5%B8%B8%E8%A7%81%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE/" class="article-date">
  <time datetime="2019-07-15T06:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h4 id="1-Hive数据仓库位置配置"><a href="#1-Hive数据仓库位置配置" class="headerlink" title="1.Hive数据仓库位置配置"></a>1.Hive数据仓库位置配置</h4><h5 id="1-Default数据仓库的最原始位置是在hdfs上的：-user-hive-warehouse路径下"><a href="#1-Default数据仓库的最原始位置是在hdfs上的：-user-hive-warehouse路径下" class="headerlink" title="(1)Default数据仓库的最原始位置是在hdfs上的：/user/hive/warehouse路径下"></a>(1)Default数据仓库的最原始位置是在hdfs上的：/user/hive/warehouse路径下</h5><h5 id="2-在仓库目录下，没有对默认的数据库default创建文件夹。如果某张表属于default数据库，直接在数据仓库目录下创建一个文件夹。"><a href="#2-在仓库目录下，没有对默认的数据库default创建文件夹。如果某张表属于default数据库，直接在数据仓库目录下创建一个文件夹。" class="headerlink" title="(2)在仓库目录下，没有对默认的数据库default创建文件夹。如果某张表属于default数据库，直接在数据仓库目录下创建一个文件夹。"></a>(2)在仓库目录下，没有对默认的数据库default创建文件夹。如果某张表属于default数据库，直接在数据仓库目录下创建一个文件夹。</h5><h5 id="3-修改default数据仓库原始位置-将hive-default-xml-template如下配置信息拷贝到hive-site-xml文件中"><a href="#3-修改default数据仓库原始位置-将hive-default-xml-template如下配置信息拷贝到hive-site-xml文件中" class="headerlink" title="(3)修改default数据仓库原始位置(将hive-default.xml.template如下配置信息拷贝到hive-site.xml文件中)"></a>(3)修改default数据仓库原始位置(将hive-default.xml.template如下配置信息拷贝到hive-site.xml文件中)</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>配置同组用户有执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure>
<h4 id="2-查询后信息显示配置"><a href="#2-查询后信息显示配置" class="headerlink" title="2.查询后信息显示配置"></a>2.查询后信息显示配置</h4><h5 id="1-在hive-site-xml文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。"><a href="#1-在hive-site-xml文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。" class="headerlink" title="(1)在hive-site.xml文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。"></a>(1)在hive-site.xml文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="2-重新启动hive，对比配置前后差异"><a href="#2-重新启动hive，对比配置前后差异" class="headerlink" title="(2)重新启动hive，对比配置前后差异"></a>(2)重新启动hive，对比配置前后差异</h5><p>(a)配置前<br>(b)配置后</p>
<h4 id="3-Hive运行日志信息配置"><a href="#3-Hive运行日志信息配置" class="headerlink" title="3 Hive运行日志信息配置"></a>3 Hive运行日志信息配置</h4><h5 id="1-Hive的log默认存放在-tmp-itstar-hive-log目录下-当前用户名下"><a href="#1-Hive的log默认存放在-tmp-itstar-hive-log目录下-当前用户名下" class="headerlink" title="(1)Hive的log默认存放在/tmp/itstar/hive.log目录下(当前用户名下)"></a>(1)Hive的log默认存放在/tmp/itstar/hive.log目录下(当前用户名下)</h5><h5 id="2-修改hive的log存放日志到-opt-module-hive-logs"><a href="#2-修改hive的log存放日志到-opt-module-hive-logs" class="headerlink" title="(2)修改hive的log存放日志到/opt/module/hive/logs"></a>(2)修改hive的log存放日志到/opt/module/hive/logs</h5><h6 id="a-修改-opt-module-hive-conf-hive-log4j-properties-template文件名称为hive-log4j-properties"><a href="#a-修改-opt-module-hive-conf-hive-log4j-properties-template文件名称为hive-log4j-properties" class="headerlink" title="(a)修改/opt/module/hive/conf/hive-log4j.properties.template文件名称为hive-log4j.properties"></a>(a)修改/opt/module/hive/conf/hive-log4j.properties.template文件名称为hive-log4j.properties</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pwd</span><br><span class="line"></span><br><span class="line">mv hive-log4j.properties.template hive-log4j.properties</span><br></pre></td></tr></table></figure>
<h6 id="b-在hive-log4j-properties文件中修改log存放位置"><a href="#b-在hive-log4j-properties文件中修改log存放位置" class="headerlink" title="(b)在hive-log4j.properties文件中修改log存放位置"></a>(b)在hive-log4j.properties文件中修改log存放位置</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.log.dir=/opt/module/hive/logs</span><br></pre></td></tr></table></figure>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hive基本操作"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/07/15/Hive%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"
    >Hive基本操作</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/" class="article-date">
  <time datetime="2019-07-15T05:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-Hive基本操作"><a href="#一-Hive基本操作" class="headerlink" title="一.Hive基本操作"></a>一.Hive基本操作</h3><h4 id="1-启动hive"><a href="#1-启动hive" class="headerlink" title="1.启动hive"></a>1.启动hive</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive</span><br></pre></td></tr></table></figure>
<h4 id="2-查看数据库"><a href="#2-查看数据库" class="headerlink" title="2.查看数据库"></a>2.查看数据库</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show databases;</span><br></pre></td></tr></table></figure>
<h4 id="3-打开默认数据库"><a href="#3-打开默认数据库" class="headerlink" title="3.打开默认数据库"></a>3.打开默认数据库</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use default;</span><br></pre></td></tr></table></figure>
<h4 id="4-显示default数据库中的表"><a href="#4-显示default数据库中的表" class="headerlink" title="4.显示default数据库中的表"></a>4.显示default数据库中的表</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show tables;</span><br></pre></td></tr></table></figure>
<h4 id="5-创建一张表"><a href="#5-创建一张表" class="headerlink" title="5.创建一张表"></a>5.创建一张表</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table student(id int, name string) ;</span><br></pre></td></tr></table></figure>
<h4 id="6-显示数据库中有几张表"><a href="#6-显示数据库中有几张表" class="headerlink" title="6.显示数据库中有几张表"></a>6.显示数据库中有几张表</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show tables;</span><br></pre></td></tr></table></figure>
<h4 id="7-查看表的结构"><a href="#7-查看表的结构" class="headerlink" title="7.查看表的结构"></a>7.查看表的结构</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc student;</span><br></pre></td></tr></table></figure>
<h4 id="8-向表中插入数据"><a href="#8-向表中插入数据" class="headerlink" title="8.向表中插入数据"></a>8.向表中插入数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into student values(1001,&quot;ss1&quot;);</span><br></pre></td></tr></table></figure>
<h4 id="9-查询表中数据"><a href="#9-查询表中数据" class="headerlink" title="9.查询表中数据"></a>9.查询表中数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from student;</span><br></pre></td></tr></table></figure>
<h4 id="10-退出hive"><a href="#10-退出hive" class="headerlink" title="10.退出hive"></a>10.退出hive</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quit;</span><br></pre></td></tr></table></figure>
<h3 id="二-hive常用交互命令"><a href="#二-hive常用交互命令" class="headerlink" title="二.hive常用交互命令"></a>二.hive常用交互命令</h3><h4 id="1-“-e”不进入hive的交互窗口执行sql语句"><a href="#1-“-e”不进入hive的交互窗口执行sql语句" class="headerlink" title="1.“-e”不进入hive的交互窗口执行sql语句"></a>1.“-e”不进入hive的交互窗口执行sql语句</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive -e &quot;select id from student;&quot;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTYwZTJiNzBhOGYxZDQ1OTMucG5n?x-oss-process=image/format,png" alt="image.png"></p>
<h4 id="2-“-f”执行脚本中sql语句"><a href="#2-“-f”执行脚本中sql语句" class="headerlink" title="2.“-f”执行脚本中sql语句"></a>2.“-f”执行脚本中sql语句</h4><h5 id="1-在-opt-module-datas目录下创建hivef-sql文件"><a href="#1-在-opt-module-datas目录下创建hivef-sql文件" class="headerlink" title="(1)在/opt/module/datas目录下创建hivef.sql文件"></a>(1)在/opt/module/datas目录下创建hivef.sql文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch hive.sql</span><br></pre></td></tr></table></figure>
<p>文件中写入正确的sql语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from student;</span><br></pre></td></tr></table></figure>

<h5 id="2-执行文件中的sql语句"><a href="#2-执行文件中的sql语句" class="headerlink" title="(2)执行文件中的sql语句"></a>(2)执行文件中的sql语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive -f /opt/module/datas/hive.sql</span><br></pre></td></tr></table></figure>

<h5 id="3-执行文件中的sql语句并将结果写入文件中-注：可能含有其他的表信息，如表头"><a href="#3-执行文件中的sql语句并将结果写入文件中-注：可能含有其他的表信息，如表头" class="headerlink" title="(3)执行文件中的sql语句并将结果写入文件中(注：可能含有其他的表信息，如表头)"></a>(3)执行文件中的sql语句并将结果写入文件中(注：可能含有其他的表信息，如表头)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive -f /opt/module/datas/hive.sql  &gt; /opt/module/datas/hive_result.txt</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQ3ZDc5NDlhOTc3NjczMzgucG5n?x-oss-process=image/format,png"></p>
<h3 id="三-Hive其他命令操作"><a href="#三-Hive其他命令操作" class="headerlink" title="三.Hive其他命令操作"></a>三.Hive其他命令操作</h3><h4 id="1-退出hive窗口："><a href="#1-退出hive窗口：" class="headerlink" title="1.退出hive窗口："></a>1.退出hive窗口：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">exit;</span><br><span class="line">quit;</span><br></pre></td></tr></table></figure>
<p>在新版的oracle中没区别了，在以前的版本是有的：<br>exit:先隐性提交数据，再退出；<br>quit:不提交数据，退出；</p>
<h4 id="2-在hive-cli命令窗口中如何查看hdfs文件系统"><a href="#2-在hive-cli命令窗口中如何查看hdfs文件系统" class="headerlink" title="2.在hive cli命令窗口中如何查看hdfs文件系统"></a>2.在hive cli命令窗口中如何查看hdfs文件系统</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfs -ls /;</span><br></pre></td></tr></table></figure>
<h4 id="3-在hive-cli命令窗口中如何查看linux本地系统"><a href="#3-在hive-cli命令窗口中如何查看linux本地系统" class="headerlink" title="3.在hive cli命令窗口中如何查看linux本地系统"></a>3.在hive cli命令窗口中如何查看linux本地系统</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! ls /opt/module/datas;</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTVjNDU2MjE5ZTRhODE0MjIucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-查看在hive中输入的所有历史命令"><a href="#4-查看在hive中输入的所有历史命令" class="headerlink" title="4.查看在hive中输入的所有历史命令"></a>4.查看在hive中输入的所有历史命令</h4><h5 id="1-进入到当前用户的根目录-root或-home-itstar"><a href="#1-进入到当前用户的根目录-root或-home-itstar" class="headerlink" title="(1)进入到当前用户的根目录/root或/home/itstar"></a>(1)进入到当前用户的根目录/root或/home/itstar</h5><h5 id="2-查看-hivehistory文件"><a href="#2-查看-hivehistory文件" class="headerlink" title="(2)查看. hivehistory文件"></a>(2)查看. hivehistory文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat .hivehistory</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTExYjlkMjUyMWVmYjMyMDkucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/13/">上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><a class="page-number" href="/page/16/">16</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/15/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2021
        <i class="ri-heart-fill heart_icon"></i> Movle
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="https://img-blog.csdnimg.cn/20200609161448519.jpg" alt="Movle"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>
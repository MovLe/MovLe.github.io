<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>Spark SQL:使用数据源 |  Movle</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="https://img-blog.csdnimg.cn/20200609161448519.jpg" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Spark SQL：使用数据源"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Spark SQL:使用数据源
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2020/03/11/Spark%20SQL%EF%BC%9A%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E6%BA%90/" class="article-date">
  <time datetime="2020-03-11T03:00:00.000Z" itemprop="datePublished">2020-03-11</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">2.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">10 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>&nbsp;&nbsp;&nbsp;&nbsp;在Spark SQL中，可以使用各种各样的数据源进行操作。Spark SQL 用于处理结构化的数据</p>
<h3 id="一-通用的Load-Save函数-load函数式加载数据，save函数式存储数据"><a href="#一-通用的Load-Save函数-load函数式加载数据，save函数式存储数据" class="headerlink" title="一.通用的Load/Save函数(load函数式加载数据，save函数式存储数据)"></a>一.通用的Load/Save函数(load函数式加载数据，save函数式存储数据)</h3><p>&nbsp;&nbsp;&nbsp;注意：使用load或者save函数时，默认的数据源都是 Parquet文件。列式存储文件</p>
<h4 id="1-通用的Load-Save函数"><a href="#1-通用的Load-Save函数" class="headerlink" title="1.通用的Load/Save函数"></a>1.通用的Load/Save函数</h4><h5 id="1-读取Parquet文件"><a href="#1-读取Parquet文件" class="headerlink" title="(1)读取Parquet文件"></a>(1)读取Parquet文件</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val usersDF = spark.read.load(<span class="string">&quot;/root/resources/users.parquet&quot;</span>)</span><br></pre></td></tr></table></figure>
<h5 id="2-查询Schema和数据"><a href="#2-查询Schema和数据" class="headerlink" title="(2)查询Schema和数据"></a>(2)查询Schema和数据</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; usersDF.printSchema</span><br><span class="line"></span><br><span class="line">scala&gt; usersDF.show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTM5NThiMGYzMmQ1MTI3NjMucG5n?x-oss-process=image/format,png"></p>
<h5 id="3-查询用户的name和喜爱颜色，并保存"><a href="#3-查询用户的name和喜爱颜色，并保存" class="headerlink" title="(3)查询用户的name和喜爱颜色，并保存"></a>(3)查询用户的name和喜爱颜色，并保存</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usersDF.select($<span class="string">&quot;name&quot;</span>,$<span class="string">&quot;favorite_color&quot;</span>).write.save(<span class="string">&quot;/root/result/parquet&quot;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="4-验证结果"><a href="#4-验证结果" class="headerlink" title="(4)验证结果"></a>(4)验证结果</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala &gt;val testResult = spark.read.load(<span class="string">&quot;/root/result/parquet/part-00000-8ffaac2e-aa81-4e63-89aa-15a8e4948a37.snappy.parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala &gt;testResult.printSchema</span><br><span class="line"></span><br><span class="line">scala &gt;testResult.show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTNmYmU3ODU0OTg4NGU4ZTQucG5n?x-oss-process=image/format,png"></p>
<h4 id="2-显式指定文件格式：加载json格式"><a href="#2-显式指定文件格式：加载json格式" class="headerlink" title="2.显式指定文件格式：加载json格式"></a>2.显式指定文件格式：加载json格式</h4><h5 id="1-直接加载："><a href="#1-直接加载：" class="headerlink" title="(1)直接加载："></a>(1)直接加载：</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val usersDF = spark.read.load(<span class="string">&quot;/root/resources/people.json&quot;</span>)  <span class="comment">//会出错</span></span><br></pre></td></tr></table></figure>
<p>上面这个会出错</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val usersDF = spark.read.format(<span class="string">&quot;json&quot;</span>).load(<span class="string">&quot;/root/resources/people.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-存储模式（Save-Modes）"><a href="#3-存储模式（Save-Modes）" class="headerlink" title="3.存储模式（Save Modes）"></a>3.存储模式（Save Modes）</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;可以采用SaveMode执行存储操作，SaveMode定义了对数据的处理模式。需要注意的是，这些保存模式不使用任何锁定，不是原子操作。此外，当使用Overwrite方式执行时，在输出新数据之前原数据就已经被删除。SaveMode详细介绍如下表：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQ2YTAyOGMwMjVkN2U0N2YucG5n?x-oss-process=image/format,png"><br>Demo：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usersDF.select($<span class="string">&quot;name&quot;</span>).write.save(<span class="string">&quot;/root/result/parquet1&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>上面出错：因为/root/result/parquet1已经存在</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usersDF.select($<span class="string">&quot;name&quot;</span>).write.mode(<span class="string">&quot;overwrite&quot;</span>).save(<span class="string">&quot;/root/result/parquet1&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="4-将结果保存为表"><a href="#4-将结果保存为表" class="headerlink" title="4.将结果保存为表"></a>4.将结果保存为表</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usersDF.select($<span class="string">&quot;name&quot;</span>).write.saveAsTable(<span class="string">&quot;table1&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>也可以进行分区、分桶等操作：partitionBy、bucketBy</p>
<h3 id="二-Parquet文件-列式存储文件，是Spark-SQL默认的数据源"><a href="#二-Parquet文件-列式存储文件，是Spark-SQL默认的数据源" class="headerlink" title="二.Parquet文件(列式存储文件，是Spark SQL默认的数据源)"></a>二.Parquet文件(列式存储文件，是Spark SQL默认的数据源)</h3><h4 id="1-什么是parquet文件？"><a href="#1-什么是parquet文件？" class="headerlink" title="1.什么是parquet文件？"></a>1.什么是parquet文件？</h4><h5 id="1-Parquet是列式存储格式的一种文件类型，列式存储有以下的核心："><a href="#1-Parquet是列式存储格式的一种文件类型，列式存储有以下的核心：" class="headerlink" title="(1)Parquet是列式存储格式的一种文件类型，列式存储有以下的核心："></a>(1)Parquet是列式存储格式的一种文件类型，列式存储有以下的核心：</h5><ul>
<li>可以跳过不符合条件的数据，只读取需要的数据，降低IO数据量。</li>
<li>压缩编码可以降低磁盘存储空间。由于同一列的数据类型是一样的，可以使用更高效的压缩编码（例如Run Length Encoding和Delta Encoding）进一步节约存储空间。</li>
<li>只读取需要的列，支持向量运算，能够获取更好的扫描性能。</li>
<li>Parquet格式是Spark SQL的默认数据源，可通过spark.sql.sources.default配置</li>
</ul>
<h5 id="2-Parquet是一个列格式而且用于多个数据处理系统中。"><a href="#2-Parquet是一个列格式而且用于多个数据处理系统中。" class="headerlink" title="(2)Parquet是一个列格式而且用于多个数据处理系统中。"></a>(2)Parquet是一个列格式而且用于多个数据处理系统中。</h5><p>Spark SQL提供支持对于Parquet文件的读写，也就是自动保存原始数据的schema。当写Parquet文件时，所有的列被自动转化为nullable，因为兼容性的缘故。</p>
<h4 id="2-把其他文件，转换成Parquet文件"><a href="#2-把其他文件，转换成Parquet文件" class="headerlink" title="2.把其他文件，转换成Parquet文件()"></a>2.把其他文件，转换成Parquet文件()</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;读入json格式的数据，将其转换成parquet格式，并创建相应的表来使用SQL进行查询。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala &gt;val empDF = spark.read.json(<span class="string">&quot;/opt/module/datas/TestFile/emp.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala &gt;empDF.show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LThjNDdhNmU2ZTU5MTk3ZGIucG5n?x-oss-process=image/format,png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala &gt;empDF.write.mode(<span class="string">&quot;overwrite&quot;</span>).save(<span class="string">&quot;/opt/module/datas/TestFile/myresult/parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//save和parquet都可以写入，是一样的</span></span><br><span class="line">scala &gt;empDF.write.mode(<span class="string">&quot;overwrite&quot;</span>).parquet(<span class="string">&quot;/opt/module/datas/TestFile/myresult/parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala &gt;val emp1=spark.read.parquet(<span class="string">&quot;/opt/module/datas/TestFile/myresult/parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala &gt;emp1.show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWZiZDgxNGFmNmQwMTk2NjIucG5n?x-oss-process=image/format,png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala &gt;emp1.createOrReplaceTempView(<span class="string">&quot;emptable&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala &gt;spark.sql(<span class="string">&quot;select * from emptable where deptno =10 and sal &gt;1500&quot;</span>).show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTg4ZTAwMzcxMDAxYjdkOWUucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-支持Schema的合并："><a href="#3-支持Schema的合并：" class="headerlink" title="3.支持Schema的合并："></a>3.支持Schema的合并：</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;Parquet支持Schema evolution(Schema演变，即：合并)。用户可以先定义一个简单的Schema，然后逐渐的向Schema中增加列描述。通过这种方式，用户可以获取多个有不同Schema但相互兼容的Parquet文件。<br>Demo:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">val df1= sc.makeRDD(<span class="number">1</span> to <span class="number">5</span>).map(i =&gt; (i,i*<span class="number">2</span>)).toDF(<span class="string">&quot;single&quot;</span>,<span class="string">&quot;double&quot;</span>)</span><br><span class="line"></span><br><span class="line">df1.show</span><br><span class="line"></span><br><span class="line">sc.makeRDD(<span class="number">1</span> to <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">sc.makeRDD(<span class="number">1</span> to <span class="number">5</span>).collect</span><br><span class="line"></span><br><span class="line">df1.write.parquet(<span class="string">&quot;/opt/module/datas/TestFile/test_table/key=1&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWViODVkOTA5M2M1MTg0MzgucG5n?x-oss-process=image/format,png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val df2 = sc.makeRDD(<span class="number">6</span> to <span class="number">10</span>).map(i=&gt;(i,i*<span class="number">3</span>)).toDF(<span class="string">&quot;single&quot;</span>,<span class="string">&quot;triple&quot;</span>)</span><br><span class="line"></span><br><span class="line">df2.show</span><br><span class="line"></span><br><span class="line">df2.write.parquet(<span class="string">&quot;/opt/module/datas/TestFile/test_table/key=2&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWM2NTFhMDE3M2I1YzJlNTIucG5n?x-oss-process=image/format,png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val df3 = spark.read.parquet(<span class="string">&quot;/opt/module/datas/TestFile/test_table&quot;</span>)</span><br><span class="line"></span><br><span class="line">df3.show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTFjMGQ5ODIyM2MwMDNjZDIucG5n?x-oss-process=image/format,png"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val df3 = spark.read.option(<span class="string">&quot;mergeSchema&quot;</span>,<span class="keyword">true</span>).parquet(<span class="string">&quot;/opt/module/datas/TestFile/test_table&quot;</span>)</span><br><span class="line"></span><br><span class="line">df3.show</span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTE0OGRiOTMzMTVhN2ZhZjcucG5n?x-oss-process=image/format,png"></p>
<h4 id="4-JSON-文件"><a href="#4-JSON-文件" class="headerlink" title="4.JSON 文件"></a>4.JSON 文件</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;Spark SQL能自动解析JSON数据集的Schema，读取JSON数据集为DataFrame格式。读取JSON数据集方法为SQLContext.read().json()。该方法将String格式的RDD或JSON文件转换为DataFrame。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;需要注意的是，这里的JSON文件不是常规的JSON格式。JSON文件每一行必须包含一个独立的、自满足有效的JSON对象。如果用多行描述一个JSON对象，会导致读取出错。读取JSON数据集示例如下：</p>
<h5 id="1-Demo1：使用Spark自带的示例文件-–-gt-people-json-文件"><a href="#1-Demo1：使用Spark自带的示例文件-–-gt-people-json-文件" class="headerlink" title="(1)Demo1：使用Spark自带的示例文件 –&gt; people.json 文件"></a>(1)Demo1：使用Spark自带的示例文件 –&gt; people.json 文件</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义路径：</span></span><br><span class="line">val path =<span class="string">&quot;/opt/module/datas/TestFile/people.json&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//读取Json文件，生成DataFrame：</span></span><br><span class="line">val peopleDF = spark.read.json(path)</span><br><span class="line"></span><br><span class="line"><span class="comment">//打印Schema结构信息：</span></span><br><span class="line">peopleDF.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建临时视图：</span></span><br><span class="line">peopleDF.createOrReplaceTempView(<span class="string">&quot;people&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//执行查询</span></span><br><span class="line">spark.sql(<span class="string">&quot;SELECT name FROM people WHERE age=18&quot;</span>).show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQ4ZGFmOTZlMmFiNDM4NmYucG5n?x-oss-process=image/format,png"></p>
<h4 id="5-使用JDBC-通过JDBC操作关系型数据库，mysql中的数据，通过JDBC加载到Spark中进行分析和处理"><a href="#5-使用JDBC-通过JDBC操作关系型数据库，mysql中的数据，通过JDBC加载到Spark中进行分析和处理" class="headerlink" title="5.使用JDBC(通过JDBC操作关系型数据库，mysql中的数据，通过JDBC加载到Spark中进行分析和处理)"></a>5.使用JDBC(通过JDBC操作关系型数据库，mysql中的数据，通过JDBC加载到Spark中进行分析和处理)</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;Spark SQL同样支持通过JDBC读取其他数据库的数据作为数据源。</p>
<h4 id="一-Demo演示：使用Spark-SQL读取Oracle数据库中的表。"><a href="#一-Demo演示：使用Spark-SQL读取Oracle数据库中的表。" class="headerlink" title="(一)Demo演示：使用Spark SQL读取Oracle数据库中的表。"></a>(一)Demo演示：使用Spark SQL读取Oracle数据库中的表。</h4><h5 id="1-启动Spark-Shell的时候，指定Oracle数据库的驱动"><a href="#1-启动Spark-Shell的时候，指定Oracle数据库的驱动" class="headerlink" title="(1)启动Spark Shell的时候，指定Oracle数据库的驱动"></a>(1)启动Spark Shell的时候，指定Oracle数据库的驱动</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master spark://hadoop:7077 --jars /opt/soft/mysql-connector-java-5.1.27.jar --driver-class-path /opt/soft/mysql-connector-java-5.1.27.jar </span><br></pre></td></tr></table></figure>

<h5 id="2-读取mysql数据库中的数据"><a href="#2-读取mysql数据库中的数据" class="headerlink" title="(2)读取mysql数据库中的数据"></a>(2)读取mysql数据库中的数据</h5><h6 id="a-方式一："><a href="#a-方式一：" class="headerlink" title="(a)方式一："></a>(a)方式一：</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">val mysqlDF = spark.read.format(<span class="string">&quot;jdbc&quot;</span>).</span><br><span class="line">         option(<span class="string">&quot;url&quot;</span>,<span class="string">&quot;jdbc:mysql://192.168.1.120:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8&quot;</span>).</span><br><span class="line">         option(<span class="string">&quot;dbtable&quot;</span>,<span class="string">&quot;emp&quot;</span>).</span><br><span class="line">         option(<span class="string">&quot;user&quot;</span>,<span class="string">&quot;root&quot;</span>).</span><br><span class="line">         option(<span class="string">&quot;password&quot;</span>,<span class="string">&quot;000000&quot;</span>).load</span><br><span class="line"></span><br><span class="line">mysqlDF.show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTUyMDhhNjViNGMxMGUxMTMucG5n?x-oss-process=image/format,png"></p>
<h6 id="b-方式二：定义-Properities类"><a href="#b-方式二：定义-Properities类" class="headerlink" title="(b)方式二：定义 Properities类"></a>(b)方式二：定义 Properities类</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//导入需要的类：</span></span><br><span class="line"><span class="keyword">import</span> java.util.Properties   </span><br><span class="line"></span><br><span class="line"><span class="comment">//定义属性：               </span></span><br><span class="line">val mysqlProps = <span class="keyword">new</span> Properties()</span><br><span class="line">mysqlProps.setProperty(<span class="string">&quot;user&quot;</span>,<span class="string">&quot;root&quot;</span>)</span><br><span class="line">mysqlProps.setProperty(<span class="string">&quot;password&quot;</span>,<span class="string">&quot;000000&quot;</span>)</span><br><span class="line"><span class="comment">//读取数据：</span></span><br><span class="line"></span><br><span class="line">val mysqlDF1 = spark.read.jdbc(<span class="string">&quot;jdbc:mysql://192.168.1.120:3306/company?serverTimezone=UTC&amp;characterEncoding=utf-8&quot;</span>,<span class="string">&quot;emp&quot;</span>,mysqlProps)</span><br><span class="line"></span><br><span class="line">mysqlDF1.show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQ4NTE3N2Y3MTkyM2M4OGEucG5n?x-oss-process=image/format,png"></p>
<h4 id="6-使用Hive-Table-把Hive中的数据，读取到Spark-SQL-中"><a href="#6-使用Hive-Table-把Hive中的数据，读取到Spark-SQL-中" class="headerlink" title="6.使用Hive Table(把Hive中的数据，读取到Spark SQL 中)"></a>6.使用Hive Table(把Hive中的数据，读取到Spark SQL 中)</h4><h5 id="1-首先，搭建好Hive的环境-需要Hadoop"><a href="#1-首先，搭建好Hive的环境-需要Hadoop" class="headerlink" title="(1)首先，搭建好Hive的环境(需要Hadoop)"></a>(1)首先，搭建好Hive的环境(需要Hadoop)</h5><h6 id="a-搭建台Hive，一台Hive-Server-hadoop2-，一台Hive-Client-hadoop1"><a href="#a-搭建台Hive，一台Hive-Server-hadoop2-，一台Hive-Client-hadoop1" class="headerlink" title="(a)搭建台Hive，一台Hive Server(hadoop2)，一台Hive Client(hadoop1)"></a>(a)搭建台Hive，一台Hive Server(hadoop2)，一台Hive Client(hadoop1)</h6><p>这两台hive中其他配置文件一样，知识hive-site.xml有区别<br>其中Hive Server的hive-site.xml配置如下:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop1:3306/hive?serverTimezone=UTC<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hive/iotmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.logging.operation.log.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hive/operation_logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.readOnlyDatastore<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.fixedDatastore<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoCreateSchema<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoCreateTables<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoCreateColumns<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.schema.autoCreateAll<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Hive Client 中hive-site.xml配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://192.168.1.122:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span>    </span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTlmNDI3ZTM5NWJiMzJiOTAucG5n?x-oss-process=image/format,png" alt="Hive Client"></p>
<h5 id="2-配置Spark-SQL支持Hive"><a href="#2-配置Spark-SQL支持Hive" class="headerlink" title="(2)配置Spark SQL支持Hive"></a>(2)配置Spark SQL支持Hive</h5><h6 id="a-只需要将以下文件拷贝到-SPARK-HOME-conf的目录下，即可"><a href="#a-只需要将以下文件拷贝到-SPARK-HOME-conf的目录下，即可" class="headerlink" title="(a)只需要将以下文件拷贝到$SPARK_HOME/conf的目录下，即可"></a>(a)只需要将以下文件拷贝到$SPARK_HOME/conf的目录下，即可</h6><ul>
<li>$HIVE_HOME/conf/hive-site.xml(拷贝Hive Client中的hive-site.xml)</li>
<li>$HADOOP_CONF_DIR/core-site.xml</li>
<li>$HADOOP_CONF_DIR/hdfs-site.xml</li>
</ul>
<h5 id="3-启动hive："><a href="#3-启动hive：" class="headerlink" title="(3)启动hive："></a>(3)启动hive：</h5><p>启动Hive Server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hive-1.2.1</span><br><span class="line"></span><br><span class="line">bin/hive --service metastore</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTc4YTBjMGYzNmExOTk4Y2IucG5n?x-oss-process=image/format,png" alt="Hive Server"></p>
<p>启动Hive Client</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hive-1.2.1</span><br><span class="line"></span><br><span class="line">bin/hive</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTM1NTYzNDlhNzE3NTA5MzYucG5n?x-oss-process=image/format,png" alt="Hive Client"></p>
<h5 id="4-使用Spark-Shell操作Hive"><a href="#4-使用Spark-Shell操作Hive" class="headerlink" title="(4)使用Spark Shell操作Hive"></a>(4)使用Spark Shell操作Hive</h5><h6 id="a-启动Spark-Shell的时候，需要使用–jars指定mysql的驱动程序"><a href="#a-启动Spark-Shell的时候，需要使用–jars指定mysql的驱动程序" class="headerlink" title="(a)启动Spark Shell的时候，需要使用–jars指定mysql的驱动程序"></a>(a)启动Spark Shell的时候，需要使用–jars指定mysql的驱动程序</h6><p>启动Spark</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/spark-2.1.0-bin-hadoop2.7</span><br><span class="line"></span><br><span class="line">bin/spark-shell --master://hadoop1:7077</span><br><span class="line"></span><br><span class="line">spark.sql(&quot;select * from default.emp&quot;).show</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTc0ZGVkZGYyYWQ1ZTAxNDQucG5n?x-oss-process=image/format,png" alt="查询Hive中的表"></p>
<h6 id="b-创建表"><a href="#b-创建表" class="headerlink" title="(b)创建表"></a>(b)创建表</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(&quot;create table movle.src (key INT, value STRING) row format 	delimited fields terminated by &#x27;,&#x27;&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWFjODhmZWM1MjY2MzMyMzQucG5n?x-oss-process=image/format,png" alt="创建表1"></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTU4OGIxNzNmZDdkNGQyZmUucG5n?x-oss-process=image/format,png" alt="创建表2"></p>
<h6 id="c-导入数据"><a href="#c-导入数据" class="headerlink" title="(c )导入数据"></a>(c )导入数据</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(&quot;load data local path &#x27;/root/temp/data.txt&#x27; into table src&quot;)</span><br></pre></td></tr></table></figure>
<h6 id="d-查询数据"><a href="#d-查询数据" class="headerlink" title="(d)查询数据"></a>(d)查询数据</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(&quot;select * from src&quot;).<span class="keyword">show</span></span><br></pre></td></tr></table></figure>
<h5 id="4-使用spark-sql操作Hive"><a href="#4-使用spark-sql操作Hive" class="headerlink" title="(4)使用spark-sql操作Hive"></a>(4)使用spark-sql操作Hive</h5><h6 id="a-启动spark-sql的时候，需要使用–jars指定mysql的驱动程序"><a href="#a-启动spark-sql的时候，需要使用–jars指定mysql的驱动程序" class="headerlink" title="(a)启动spark-sql的时候，需要使用–jars指定mysql的驱动程序"></a>(a)启动spark-sql的时候，需要使用–jars指定mysql的驱动程序</h6><h6 id="b-操作Hive"><a href="#b-操作Hive" class="headerlink" title="(b)操作Hive"></a>(b)操作Hive</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.sql(&quot;show tables&quot;).<span class="keyword">show</span></span><br></pre></td></tr></table></figure>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTE1ZjQxMThmNDY1NDVjYTEucG5n?x-oss-process=image/format,png"></p>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          打赏
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2020/03/11/Spark%20SQL%EF%BC%9A%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E6%BA%90/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2020/03/11/Spark%20SQL%EF%BC%9A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Spark SQL:性能优化
          
        </div>
      </a>
    
    
      <a href="/2020/03/11/Spark%20SQL%EF%BC%9A%E5%9F%BA%E7%A1%80/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Spark SQL:基础</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2021
        <i class="ri-heart-fill heart_icon"></i> Movle
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="https://img-blog.csdnimg.cn/20200609161448519.jpg" alt="Movle"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>
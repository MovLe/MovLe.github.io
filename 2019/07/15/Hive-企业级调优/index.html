<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>Hive之企业调优 |  Movle</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="https://img-blog.csdnimg.cn/20200609161448519.jpg" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Hive-企业级调优"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Hive之企业调优
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/07/15/Hive-%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%B0%83%E4%BC%98/" class="article-date">
  <time datetime="2019-07-15T13:00:00.000Z" itemprop="datePublished">2019-07-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">6.8k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">29 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="一-Fetch抓取"><a href="#一-Fetch抓取" class="headerlink" title="一. Fetch抓取"></a>一. Fetch抓取</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：SELECT * FROM employees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.fetch.task.conversion<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>more<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      Expects one of [none, minimal, more].</span><br><span class="line"></span><br><span class="line">      Some select queries can be converted to single FETCH task minimizing latency.</span><br><span class="line"></span><br><span class="line">      Currently the query should be single sourced not having any subquery and should not have</span><br><span class="line"></span><br><span class="line">      any aggregations or distincts (which incurs RS), lateral views and joins.</span><br><span class="line"></span><br><span class="line">      0\. none : disable hive.fetch.task.conversion</span><br><span class="line"></span><br><span class="line">      1\. minimal : SELECT STAR, FILTER on partition columns, LIMIT only</span><br><span class="line"></span><br><span class="line">      2\. more  : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual columns)</span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>案例实操</strong>：</p>
<p>1.把hive.fetch.task.conversion设置成none，然后执行查询语句，都会执行mapreduce程序。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.fetch.task.conversion=none;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp limit 3;</span><br></pre></td></tr></table></figure>

<p>2.把hive.fetch.task.conversion设置成more，然后执行查询语句，如下查询方式都不会执行mapreduce程序。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.fetch.task.conversion=more;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select ename from emp limit 3;</span><br></pre></td></tr></table></figure>
<h3 id="二-本地模式"><a href="#二-本地模式" class="headerlink" title="二. 本地模式"></a>二. 本地模式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，<strong>Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短</strong>。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.mode.local.auto=true;  //开启本地mr</span><br><span class="line"></span><br><span class="line">//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local  mr的方式，默认为134217728，即128M</span><br><span class="line"></span><br><span class="line">set hive.exec.mode.local.auto.inputbytes.max=50000000;</span><br><span class="line"></span><br><span class="line">//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</span><br><span class="line"></span><br><span class="line">set hive.exec.mode.local.auto.input.files.max=10;</span><br></pre></td></tr></table></figure>
<p><strong>案例实操</strong>：</p>
<h3 id="1-开启本地模式，并执行查询语句-注意重启Hive"><a href="#1-开启本地模式，并执行查询语句-注意重启Hive" class="headerlink" title="1.开启本地模式，并执行查询语句(注意重启Hive)"></a>1.开启本地模式，并执行查询语句(注意重启Hive)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.exec.mode.local.auto=true; </span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp cluster by deptno;</span><br></pre></td></tr></table></figure>
<p>Time taken: 1.328 seconds, Fetched: 14 row(s)</p>
<h4 id="2-关闭本地模式，并执行查询语句"><a href="#2-关闭本地模式，并执行查询语句" class="headerlink" title="2.关闭本地模式，并执行查询语句"></a>2.关闭本地模式，并执行查询语句</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.exec.mode.local.auto=false; </span><br><span class="line"></span><br><span class="line">hive (default)&gt; select * from emp cluster by deptno;</span><br></pre></td></tr></table></figure>
<p>Time taken: 20.09 seconds, Fetched: 14 row(s)</p>
<h3 id="三-表的优化"><a href="#三-表的优化" class="headerlink" title="三.表的优化"></a>三.表的优化</h3><h4 id="1-小表、大表Join"><a href="#1-小表、大表Join" class="headerlink" title="1. 小表、大表Join"></a>1. 小表、大表Join</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用Group变小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce（预聚合）。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</p>
<p><strong>案例实操</strong></p>
<h5 id="0-需求：测试大表JOIN小表和小表JOIN大表的效率"><a href="#0-需求：测试大表JOIN小表和小表JOIN大表的效率" class="headerlink" title="(0)需求：测试大表JOIN小表和小表JOIN大表的效率"></a>(0)需求：测试大表JOIN小表和小表JOIN大表的效率</h5><h5 id="1-建大表、小表和JOIN后表的语句"><a href="#1-建大表、小表和JOIN后表的语句" class="headerlink" title="(1)建大表、小表和JOIN后表的语句"></a>(1)建大表、小表和JOIN后表的语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 创建大表</span><br><span class="line">create table bigtable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建小表</span><br><span class="line">create table smalltable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建join后表的语句</span><br><span class="line">create table jointable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-分别向大表和小表中导入数据"><a href="#2-分别向大表和小表中导入数据" class="headerlink" title="(2)分别向大表和小表中导入数据"></a>(2)分别向大表和小表中导入数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/bigtable&#x27; into table bigtable;</span><br><span class="line"></span><br><span class="line">hive (default)&gt;load data local inpath &#x27;/opt/module/datas/smalltable&#x27; into table smalltable;</span><br></pre></td></tr></table></figure>
<h5 id="3-关闭mapjoin功能（默认是打开的）"><a href="#3-关闭mapjoin功能（默认是打开的）" class="headerlink" title="(3)关闭mapjoin功能（默认是打开的）"></a>(3)关闭mapjoin功能（默认是打开的）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.auto.convert.join = false;</span><br></pre></td></tr></table></figure>
<h5 id="4-执行小表JOIN大表语句"><a href="#4-执行小表JOIN大表语句" class="headerlink" title="(4)执行小表JOIN大表语句"></a>(4)执行小表JOIN大表语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line"></span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line"></span><br><span class="line">from smalltable s</span><br><span class="line"></span><br><span class="line">left join bigtable  b</span><br><span class="line"></span><br><span class="line">on b.id = s.id;</span><br></pre></td></tr></table></figure>

<h5 id="5-执行大表JOIN小表语句"><a href="#5-执行大表JOIN小表语句" class="headerlink" title="(5)执行大表JOIN小表语句"></a>(5)执行大表JOIN小表语句</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line"></span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line"></span><br><span class="line">from bigtable  b</span><br><span class="line"></span><br><span class="line">left join smalltable  s</span><br><span class="line"></span><br><span class="line">on s.id = b.id;</span><br></pre></td></tr></table></figure>
<h4 id="2-大表Join大表"><a href="#2-大表Join大表" class="headerlink" title="2.大表Join大表"></a>2.大表Join大表</h4><h5 id="1-空KEY过滤"><a href="#1-空KEY过滤" class="headerlink" title="(1).空KEY过滤"></a>(1).空KEY过滤</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。例如key对应的字段为空，操作如下：</p>
<p><strong>案例实操</strong></p>
<h6 id="a-配置历史服务器"><a href="#a-配置历史服务器" class="headerlink" title="(a)配置历史服务器"></a>(a)配置历史服务器</h6><p>配置mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata111:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata111:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>启动历史服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<p>查看jobhistory</p>
<p><a target="_blank" rel="noopener" href="http://192.168.1.102:19888/jobhistory">http://192.168.1.102:19888/jobhistory</a></p>
<h6 id="b-创建原始数据表、空id表、合并后数据表"><a href="#b-创建原始数据表、空id表、合并后数据表" class="headerlink" title="(b)创建原始数据表、空id表、合并后数据表"></a>(b)创建原始数据表、空id表、合并后数据表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 创建原始表</span><br><span class="line">create table ori(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建空id表</span><br><span class="line">create table nullidtable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">// 创建join后表的语句</span><br><span class="line">create table jointable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="c-分别加载原始数据和空id数据到对应表中"><a href="#c-分别加载原始数据和空id数据到对应表中" class="headerlink" title="(c )分别加载原始数据和空id数据到对应表中"></a>(c )分别加载原始数据和空id数据到对应表中</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/ori&#x27; into table ori;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/nullid&#x27; into table nullidtable;</span><br></pre></td></tr></table></figure>

<h6 id="d-测试不过滤空id"><a href="#d-测试不过滤空id" class="headerlink" title="(d)测试不过滤空id"></a>(d)测试不过滤空id</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite table jointable </span><br><span class="line"></span><br><span class="line">select n.* from nullidtable n left join ori o on n.id = o.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 42.038 seconds</p>
<p>Time taken: 37.284 seconds</p>
<p>Time taken: 97.281 seconds</p>
<h5 id="e-测试过滤空id"><a href="#e-测试过滤空id" class="headerlink" title="(e)测试过滤空id"></a>(e)测试过滤空id</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite table jointable </span><br><span class="line"></span><br><span class="line">select n.* from (select * from nullidtable where id is not null ) n  left join ori o on n.id = o.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 31.725 seconds</p>
<p>Time taken: 28.876 seconds</p>
<h5 id="2-空key转换"><a href="#2-空key转换" class="headerlink" title="(2).空key转换"></a>(2).空key转换</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。例如：</p>
<p><strong>案例实操：</strong></p>
<p><strong>不随机分布空null值：</strong></p>
<h6 id="a-设置5个reduce个数"><a href="#a-设置5个reduce个数" class="headerlink" title="(a)设置5个reduce个数"></a>(a)设置5个reduce个数</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>
<h6 id="b-JOIN两张表"><a href="#b-JOIN两张表" class="headerlink" title="(b)JOIN两张表"></a>(b)JOIN两张表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line"></span><br><span class="line">select n.* from nullidtable n left join ori b on n.id = b.id;</span><br></pre></td></tr></table></figure>

<p><strong>结果：可以看出来，出现了数据倾斜，某些reducer的资源消耗远大于其他reducer</strong></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWE0MTZjMTY3ZDRiODYxNmQucG5n?x-oss-process=image/format,png"></p>
<p><strong>随机分布空null值</strong></p>
<h6 id="a-设置5个reduce个数-1"><a href="#a-设置5个reduce个数-1" class="headerlink" title="(a)设置5个reduce个数"></a>(a)设置5个reduce个数</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>
<h6 id="b-JOIN两张表-1"><a href="#b-JOIN两张表-1" class="headerlink" title="(b)JOIN两张表"></a>(b)JOIN两张表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line">select n.* from nullidtable n full join ori o on </span><br><span class="line">case when n.id is null then concat(&#x27;hive&#x27;, rand()) else n.id end = o.id;</span><br></pre></td></tr></table></figure>
<p><strong>结果：可以看出来，消除了数据倾斜，负载均衡reducer的资源消耗</strong></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LWUxOTVmMzc4YzQ0NzYyMzUucG5n?x-oss-process=image/format,png"></p>
<h4 id="3-MapJoin"><a href="#3-MapJoin" class="headerlink" title="3.MapJoin"></a>3.MapJoin</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即：在Reduce阶段完成join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在map端进行join，避免reducer处理。</p>
<h5 id="1-开启MapJoin参数设置："><a href="#1-开启MapJoin参数设置：" class="headerlink" title="(1).开启MapJoin参数设置："></a>(1).开启MapJoin参数设置：</h5><h6 id="a-设置自动选择Mapjoin"><a href="#a-设置自动选择Mapjoin" class="headerlink" title="(a)设置自动选择Mapjoin"></a>(a)设置自动选择Mapjoin</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set hive.auto.convert.join = true;</span><br><span class="line">//默认为true</span><br></pre></td></tr></table></figure>
<h6 id="b-大表小表的阈值设置-默认25M一下认为是小表-："><a href="#b-大表小表的阈值设置-默认25M一下认为是小表-：" class="headerlink" title="(b)大表小表的阈值设置(默认25M一下认为是小表)："></a>(b)大表小表的阈值设置(默认25M一下认为是小表)：</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.mapjoin.smalltable.filesize=25000000;</span><br></pre></td></tr></table></figure>
<h5 id="2-MapJoin工作机制"><a href="#2-MapJoin工作机制" class="headerlink" title="(2).MapJoin工作机制"></a>(2).MapJoin工作机制</h5><p><strong>案例实操</strong>：</p>
<h6 id="a-开启Mapjoin功能"><a href="#a-开启Mapjoin功能" class="headerlink" title="(a)开启Mapjoin功能"></a>(a)开启Mapjoin功能</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.auto.convert.join = true; 默认为true</span><br></pre></td></tr></table></figure>
<h6 id="b-执行小表JOIN大表语句"><a href="#b-执行小表JOIN大表语句" class="headerlink" title="(b)执行小表JOIN大表语句"></a>(b)执行小表JOIN大表语句</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line">from smalltable s</span><br><span class="line">join bigtable  b</span><br><span class="line">on s.id = b.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 24.594 seconds</p>
<h6 id="c-执行大表JOIN小表语句"><a href="#c-执行大表JOIN小表语句" class="headerlink" title="(c )执行大表JOIN小表语句"></a>(c )执行大表JOIN小表语句</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table jointable</span><br><span class="line">select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url</span><br><span class="line">from bigtable  b</span><br><span class="line">join smalltable  s</span><br><span class="line">on s.id = b.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 24.315 seconds</p>
<h4 id="4-Group-By"><a href="#4-Group-By" class="headerlink" title="4.Group By"></a>4.Group By</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p>
<h5 id="1-开启Map端聚合参数设置"><a href="#1-开启Map端聚合参数设置" class="headerlink" title="(1).开启Map端聚合参数设置"></a>(1).开启Map端聚合参数设置</h5><h6 id="a-是否在Map端进行聚合，默认为True"><a href="#a-是否在Map端进行聚合，默认为True" class="headerlink" title="(a)是否在Map端进行聚合，默认为True"></a>(a)是否在Map端进行聚合，默认为True</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr = true</span><br></pre></td></tr></table></figure>

<h6 id="b-在Map端进行聚合操作的条目数目"><a href="#b-在Map端进行聚合操作的条目数目" class="headerlink" title="(b)在Map端进行聚合操作的条目数目"></a>(b)在Map端进行聚合操作的条目数目</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.groupby.mapaggr.checkinterval = 100000</span><br></pre></td></tr></table></figure>
<h6 id="c-有数据倾斜的时候进行负载均衡（默认是false）"><a href="#c-有数据倾斜的时候进行负载均衡（默认是false）" class="headerlink" title="(c )有数据倾斜的时候进行负载均衡（默认是false）"></a>(c )有数据倾斜的时候进行负载均衡（默认是false）</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.groupby.skewindata = true</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;当选项设定为 true，生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中(这个过程可以保证相同的Group By Key被分布到同一个Reduce中)，最后完成最终的聚合操作。</p>
<h4 id="5-Count-Distinct-去重统计"><a href="#5-Count-Distinct-去重统计" class="headerlink" title="5.Count(Distinct) 去重统计"></a>5.Count(Distinct) 去重统计</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换：</p>
<p><strong>案例实操</strong></p>
<h5 id="1-创建一张大表"><a href="#1-创建一张大表" class="headerlink" title="(1)创建一张大表"></a>(1)创建一张大表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table bigtable(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h5 id="2-加载数据"><a href="#2-加载数据" class="headerlink" title="(2)加载数据"></a>(2)加载数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/bigtable&#x27; into table bigtable;</span><br></pre></td></tr></table></figure>
<h5 id="3-设置5个reduce个数"><a href="#3-设置5个reduce个数" class="headerlink" title="(3)设置5个reduce个数"></a>(3)设置5个reduce个数</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>

<h5 id="4-执行去重id查询"><a href="#4-执行去重id查询" class="headerlink" title="(4)执行去重id查询"></a>(4)执行去重id查询</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(distinct id) from bigtable;</span><br></pre></td></tr></table></figure>
<p>Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 7.12 sec   HDFS Read: 120741990 HDFS Write: 7 SUCCESS<br>Total MapReduce CPU Time Spent: 7 seconds 120 msec<br>OK<br>c0<br>100001<br>Time taken: 23.607 seconds, Fetched: 1 row(s)</p>
<h5 id="5-采用GROUP-by去重id-推荐"><a href="#5-采用GROUP-by去重id-推荐" class="headerlink" title="(5)采用GROUP by去重id(推荐)"></a>(5)采用GROUP by去重id(推荐)</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(id) from (select id from bigtable group by id) a;</span><br></pre></td></tr></table></figure>
<p>Stage-Stage-1: Map: 1  Reduce: 5   Cumulative CPU: 17.53 sec   HDFS Read: 120752703 HDFS Write: 580 SUCCESS<br>Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.29 sec   HDFS Read: 9409 HDFS Write: 7 SUCCESS<br>Total MapReduce CPU Time Spent: 21 seconds 820 msec<br>OK<br>_c0<br>100001<br>Time taken: 50.795 seconds, Fetched: 1 row(s)</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</p>
<h4 id="6-笛卡尔积"><a href="#6-笛卡尔积" class="headerlink" title="6. 笛卡尔积"></a>6. 笛卡尔积</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p>
<h4 id="7-行列过滤"><a href="#7-行列过滤" class="headerlink" title="7.行列过滤"></a>7.行列过滤</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;列处理：在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤，总而言之，就是先where还是先join的执行顺序的问题，以下两种，经过SQL优化器，执行效果大体一样。比如：</p>
<p><strong>案例实操</strong>：</p>
<h5 id="1-测试先关联两张表，再用where条件过滤"><a href="#1-测试先关联两张表，再用where条件过滤" class="headerlink" title="(1)测试先关联两张表，再用where条件过滤"></a>(1)测试先关联两张表，再用where条件过滤</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select o.id from bigtable b</span><br><span class="line">join ori o on o.id = b.id</span><br><span class="line">where o.id &lt;= 10;</span><br></pre></td></tr></table></figure>
<p>Time taken: 34.406 seconds, Fetched: 100 row(s)</p>
<h5 id="2-通过子查询后，再关联表"><a href="#2-通过子查询后，再关联表" class="headerlink" title="(2)通过子查询后，再关联表"></a>(2)通过子查询后，再关联表</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select b.id from bigtable b</span><br><span class="line">join (select id from ori where id &lt;= 10 ) o on b.id = o.id;</span><br></pre></td></tr></table></figure>
<p>Time taken: 30.058 seconds, Fetched: 100 row(s)</p>
<h4 id="8-动态分区调整"><a href="#8-动态分区调整" class="headerlink" title="8.动态分区调整"></a>8.动态分区调整</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。</p>
<h5 id="1-开启动态分区参数设置"><a href="#1-开启动态分区参数设置" class="headerlink" title="(1).开启动态分区参数设置"></a>(1).开启动态分区参数设置</h5><h6 id="a-开启动态分区功能-默认true，开启"><a href="#a-开启动态分区功能-默认true，开启" class="headerlink" title="(a)开启动态分区功能(默认true，开启)"></a>(a)开启动态分区功能(默认true，开启)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition=true</span><br></pre></td></tr></table></figure>
<h6 id="b-设置为非严格模式-动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区"><a href="#b-设置为非严格模式-动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区" class="headerlink" title="(b)设置为非严格模式(动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区)"></a>(b)设置为非严格模式(动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition.mode=nonstrict</span><br></pre></td></tr></table></figure>
<h6 id="c-在所有执行MR的节点上，最大一共可以创建多少个动态分区。-默认1000"><a href="#c-在所有执行MR的节点上，最大一共可以创建多少个动态分区。-默认1000" class="headerlink" title="(c )在所有执行MR的节点上，最大一共可以创建多少个动态分区。(默认1000)"></a>(c )在所有执行MR的节点上，最大一共可以创建多少个动态分区。(默认1000)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.max.dynamic.partitions=1000</span><br></pre></td></tr></table></figure>
<h6 id="d-在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。"><a href="#d-在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。" class="headerlink" title="(d)在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。"></a>(d)在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.max.dynamic.partitions.pernode=100</span><br></pre></td></tr></table></figure>
<h6 id="e-整个MR-Job中，最大可以创建多少个HDFS文件。-默认值100000"><a href="#e-整个MR-Job中，最大可以创建多少个HDFS文件。-默认值100000" class="headerlink" title="(e)整个MR Job中，最大可以创建多少个HDFS文件。(默认值100000)"></a>(e)整个MR Job中，最大可以创建多少个HDFS文件。(默认值100000)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.max.created.files=100000</span><br></pre></td></tr></table></figure>
<h6 id="f-当有空分区生成时，是否抛出异常。一般不需要设置。-默认false"><a href="#f-当有空分区生成时，是否抛出异常。一般不需要设置。-默认false" class="headerlink" title="(f)当有空分区生成时，是否抛出异常。一般不需要设置。(默认false)"></a>(f)当有空分区生成时，是否抛出异常。一般不需要设置。(默认false)</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.error.on.empty.partition=false</span><br></pre></td></tr></table></figure>
<h5 id="2-案例实操"><a href="#2-案例实操" class="headerlink" title="(2).案例实操"></a>(2).案例实操</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;需求：将ori中的数据按照时间(如：20111230000008)，插入到目标表ori_partitioned_target的相应分区中。</p>
<h6 id="a-创建分区表"><a href="#a-创建分区表" class="headerlink" title="(a)创建分区表"></a>(a)创建分区表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create table ori_partitioned(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) </span><br><span class="line">partitioned by (p_time bigint) </span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<h6 id="b-加载数据到分区表中"><a href="#b-加载数据到分区表中" class="headerlink" title="(b)加载数据到分区表中"></a>(b)加载数据到分区表中</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/ds1&#x27; into table ori_partitioned partition(p_time=&#x27;20111230000010&#x27;) ;</span><br><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/ds2&#x27; into table ori_partitioned partition(p_time=&#x27;20111230000011&#x27;) ;</span><br></pre></td></tr></table></figure>
<h6 id="c-创建目标分区表"><a href="#c-创建目标分区表" class="headerlink" title="(c )创建目标分区表"></a>(c )创建目标分区表</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table ori_partitioned_target(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) PARTITIONED BY (p_time STRING) row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>
<h6 id="d-设置动态分区"><a href="#d-设置动态分区" class="headerlink" title="(d)设置动态分区"></a>(d)设置动态分区</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition = true;  //（默认true）</span><br><span class="line">set hive.exec.dynamic.partition.mode = nonstrict;  //(默认strict)</span><br><span class="line">set hive.exec.max.dynamic.partitions = 1000;   //(默认1000)</span><br><span class="line">set hive.exec.max.dynamic.partitions.pernode = 100;   //（默认100）</span><br><span class="line">set hive.exec.max.created.files = 100000;  //(默认值100000)</span><br><span class="line">set hive.error.on.empty.partition = false;   //(默认值false)</span><br><span class="line"></span><br><span class="line">hive (default)&gt; insert overwrite table ori_partitioned_target partition (p_time) </span><br><span class="line">select id, time, uid, keyword, url_rank, click_num, click_url, p_time from ori_partitioned;</span><br></pre></td></tr></table></figure>

<h6 id="e-查看目标分区表的分区情况"><a href="#e-查看目标分区表的分区情况" class="headerlink" title="(e)查看目标分区表的分区情况"></a>(e)查看目标分区表的分区情况</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; show partitions ori_partitioned_target;</span><br></pre></td></tr></table></figure>
<h6 id="f-如果不设置非严格模式，报错如下"><a href="#f-如果不设置非严格模式，报错如下" class="headerlink" title="(f)如果不设置非严格模式，报错如下"></a>(f)如果不设置非严格模式，报错如下</h6><p>FAILED: SemanticException [Error 10096]: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict</p>
<h4 id="9-分桶"><a href="#9-分桶" class="headerlink" title="9. 分桶"></a>9. 分桶</h4><h4 id="10-分区"><a href="#10-分区" class="headerlink" title="10.分区"></a>10.分区</h4><h3 id="四-数据倾斜"><a href="#四-数据倾斜" class="headerlink" title="四.数据倾斜"></a>四.数据倾斜</h3><h4 id="1-合理设置Map数"><a href="#1-合理设置Map数" class="headerlink" title="1.合理设置Map数"></a>1.合理设置Map数</h4><h5 id="1-通常情况下，作业会通过input的目录产生一个或者多个map任务。"><a href="#1-通常情况下，作业会通过input的目录产生一个或者多个map任务。" class="headerlink" title="(1).通常情况下，作业会通过input的目录产生一个或者多个map任务。"></a>(1).通常情况下，作业会通过input的目录产生一个或者多个map任务。</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p>
<h5 id="2-是不是map数越多越好？"><a href="#2-是不是map数越多越好？" class="headerlink" title="(2).是不是map数越多越好？"></a>(2).是不是map数越多越好？</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;答案是否定的。如果一个任务有很多小文件(远远小于块大小128m)，则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p>
<h5 id="3-是不是保证每个map处理接近128m的文件块，就高枕无忧了？"><a href="#3-是不是保证每个map处理接近128m的文件块，就高枕无忧了？" class="headerlink" title="(3).是不是保证每个map处理接近128m的文件块，就高枕无忧了？"></a>(3).是不是保证每个map处理接近128m的文件块，就高枕无忧了？</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。<br>针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</p>
<h4 id="2-小文件进行合并"><a href="#2-小文件进行合并" class="headerlink" title="2.小文件进行合并"></a>2.小文件进行合并</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>
<h4 id="3-复杂文件增加Map数"><a href="#3-复杂文件增加Map数" class="headerlink" title="3.复杂文件增加Map数"></a>3.复杂文件增加Map数</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;增加map的方法为：根据computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p>
<p><strong>案例实操</strong>：</p>
<h5 id="1-执行查询"><a href="#1-执行查询" class="headerlink" title="(1)执行查询"></a>(1)执行查询</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(*) from emp;</span><br></pre></td></tr></table></figure>
<p>Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1</p>
<h5 id="2-设置最大切片值为100个字节"><a href="#2-设置最大切片值为100个字节" class="headerlink" title="(2)设置最大切片值为100个字节"></a>(2)设置最大切片值为100个字节</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.input.fileinputformat.split.maxsize=100;</span><br><span class="line">hive (default)&gt; select count(*) from emp;</span><br></pre></td></tr></table></figure>
<p>Hadoop job information for Stage-1: number of mappers: 6; number of reducers: 1</p>
<h4 id="4-合理设置Reduce数"><a href="#4-合理设置Reduce数" class="headerlink" title="4. 合理设置Reduce数"></a>4. 合理设置Reduce数</h4><h5 id="1-调整reduce个数方法一"><a href="#1-调整reduce个数方法一" class="headerlink" title="(1).调整reduce个数方法一"></a>(1).调整reduce个数方法一</h5><h6 id="a-每个Reduce处理的数据量默认是256MB"><a href="#a-每个Reduce处理的数据量默认是256MB" class="headerlink" title="(a)每个Reduce处理的数据量默认是256MB"></a>(a)每个Reduce处理的数据量默认是256MB</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.reducers.bytes.per.reducer=256000000</span><br></pre></td></tr></table></figure>
<h6 id="b-每个任务最大的reduce数，默认为1009"><a href="#b-每个任务最大的reduce数，默认为1009" class="headerlink" title="(b)每个任务最大的reduce数，默认为1009"></a>(b)每个任务最大的reduce数，默认为1009</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.reducers.max=1009</span><br></pre></td></tr></table></figure>
<h6 id="c-计算reducer数的公式"><a href="#c-计算reducer数的公式" class="headerlink" title="(c )计算reducer数的公式"></a>(c )计算reducer数的公式</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">N=min(参数2=1009，总输入数据量/参数1=？)</span><br></pre></td></tr></table></figure>
<h5 id="2-调整reduce个数方法二"><a href="#2-调整reduce个数方法二" class="headerlink" title="(2).调整reduce个数方法二"></a>(2).调整reduce个数方法二</h5><p>在hadoop的mapred-default.xml文件中修改<br>设置每个job的Reduce个数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.job.reduces = 5;</span><br></pre></td></tr></table></figure>
<h5 id="3-reduce个数并不是越多越好"><a href="#3-reduce个数并不是越多越好" class="headerlink" title="(3).reduce个数并不是越多越好"></a>(3).reduce个数并不是越多越好</h5><h6 id="a-过多的启动和初始化reduce也会消耗时间和资源；"><a href="#a-过多的启动和初始化reduce也会消耗时间和资源；" class="headerlink" title="(a)过多的启动和初始化reduce也会消耗时间和资源；"></a>(a)过多的启动和初始化reduce也会消耗时间和资源；</h6><h6 id="b-另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；"><a href="#b-另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；" class="headerlink" title="(b)另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；"></a>(b)另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p>
<h3 id="五-并行执行"><a href="#五-并行执行" class="headerlink" title="五. 并行执行"></a>五. 并行执行</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.parallel=true;              //打开任务并行执行,默认false</span><br><span class="line">set hive.exec.parallel.thread.number=16;  //同一个sql允许最大并行度，默认为8。</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p>
<h3 id="六-严格模式"><a href="#六-严格模式" class="headerlink" title="六.严格模式"></a>六.严格模式</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;Hive提供了一个严格模式，可以防止用户执行那些可能意向不到的不好的影响的查询。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;通过设置属性hive.mapred.mode值为默认是非严格模式nonstrict 。开启严格模式需要修改hive.mapred.mode值为strict，开启严格模式可以禁止3种类型的查询。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.mode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>strict<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The mode in which the Hive operations are being performed. </span><br><span class="line">      In strict mode, some risky queries are not allowed to run. They include:</span><br><span class="line">        Cartesian Product.</span><br><span class="line">        No partition being picked up for a query.</span><br><span class="line">        Comparing bigints and strings.</span><br><span class="line">        Comparing bigints and doubles.</span><br><span class="line">        Orderby without limit.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>1.对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p>
<p>2.对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p>
<p>3.限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况</p>
<h3 id="七-JVM重用"><a href="#七-JVM重用" class="headerlink" title="七. JVM重用"></a>七. JVM重用</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;JVM重用是Hadoop调优参数的内容，其对Hive的性能具有非常大的影响，特别是对于很难避免小文件的场景或task特别多的场景，这类场景大多数执行时间都很短。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含有成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次。N的值可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间，具体多少需要根据具体业务场景测试得出。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.jvm.numtasks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>How many tasks to run per jvm. If set to -1, there is</span><br><span class="line">  no limit. </span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;这个功能的缺点是，开启JVM重用将一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个“不平衡的”job中有某几个reduce task执行的时间要比其他Reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p>
<h3 id="八-推测执行"><a href="#八-推测执行" class="headerlink" title="八.推测执行"></a>八.推测执行</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;在分布式集群环境下，因为程序Bug(包括Hadoop本身的bug)，负载不均衡或者资源分布不均等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务（比如一个作业的某个任务进度只有50%，而其他所有任务已经运行完毕），则这些任务会拖慢作业的整体执行进度。为了避免这种情况发生，Hadoop采用了推测执行（Speculative Execution）机制，它根据一定的法则推测出“拖后腿”的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;设置开启推测执行参数：Hadoop的mapred-site.xml文件中进行配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some map tasks may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some reduce tasks may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>不过hive本身也提供了配置项来控制reduce-side的推测执行：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.mapred.reduce.tasks.speculative.execution<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether speculative execution for reducers should be turned on. <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;关于调优这些推测执行变量，还很难给一个具体的建议。如果用户对于运行时的偏差非常敏感的话，那么可以将这些功能关闭掉。如果用户因为输入数据量很大而需要执行长时间的map或者Reduce task的话，那么启动推测执行造成的浪费是非常巨大大。</p>
<h3 id="九-压缩"><a href="#九-压缩" class="headerlink" title="九. 压缩"></a>九. 压缩</h3><p>详见之前的文章。</p>
<h3 id="十-执行计划-Explain"><a href="#十-执行计划-Explain" class="headerlink" title="十. 执行计划(Explain)"></a>十. 执行计划(Explain)</h3><h4 id="1-基本语法"><a href="#1-基本语法" class="headerlink" title="1.基本语法"></a>1.基本语法</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query</span><br></pre></td></tr></table></figure>
<h4 id="2-案例实操-1"><a href="#2-案例实操-1" class="headerlink" title="2.案例实操"></a>2.案例实操</h4><h5 id="1-查看下面这条语句的执行计划"><a href="#1-查看下面这条语句的执行计划" class="headerlink" title="(1)查看下面这条语句的执行计划"></a>(1)查看下面这条语句的执行计划</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; explain select * from emp;</span><br><span class="line">hive (default)&gt; explain select deptno, avg(sal) avg_sal from emp group by deptno;</span><br></pre></td></tr></table></figure>
<h5 id="2-查看详细执行计划"><a href="#2-查看详细执行计划" class="headerlink" title="(2)查看详细执行计划"></a>(2)查看详细执行计划</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; explain extended select * from emp;</span><br><span class="line">hive (default)&gt; explain extended select deptno, avg(sal) avg_sal from emp group by deptno;</span><br></pre></td></tr></table></figure>
<p>以下是在MySQL中的显示</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MzkxNDA3LTQxNWE3ZGNkMDJkNzUwZGYucG5n?x-oss-process=image/format,png"></p>
<p><strong>EXPLAIN字段</strong>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Table：显示这一行的数据是关于哪张表的</span><br><span class="line">possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句</span><br><span class="line">key：实际使用的索引。如果为NULL，则没有使用索引。MYSQL很少会选择优化不足的索引，此时可以在SELECT语句中使用USE INDEX（index）来强制使用一个索引或者用IGNORE INDEX（index）来强制忽略索引</span><br><span class="line">key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好</span><br><span class="line">ref：显示索引的哪一列被使用了，如果可能的话，是一个常数</span><br><span class="line">rows：MySQL认为必须检索的用来返回请求数据的行数</span><br><span class="line">type：这是最重要的字段之一，显示查询使用了何种类型。从最好到最差的连接类型为system、const、eq_reg、ref、range、index和ALL</span><br><span class="line">system、const：可以将查询的变量转为常量.  如id=1; id为 主键或唯一键.</span><br><span class="line">eq_ref：访问索引,返回某单一行的数据.(通常在联接时出现，查询使用的索引为主键或惟一键)</span><br><span class="line">ref：访问索引,返回某个值的数据.(可以返回多行) 通常使用=时发生</span><br><span class="line">range：这个连接类型使用索引返回一个范围中的行，比如使用&gt;或&lt;查找东西，并且该字段上建有索引时发生的情况(注:不一定好于index)</span><br><span class="line">index：以索引的顺序进行全表扫描，优点是不用排序,缺点是还要全表扫描</span><br><span class="line">ALL：全表扫描，应该尽量避免</span><br><span class="line">Extra：关于MYSQL如何解析查询的额外信息，主要有以下几种</span><br><span class="line">using index：只用到索引,可以避免访问表. </span><br><span class="line">using where：使用到where来过虑数据. 不是所有的where clause都要显示using where. 如以=方式访问索引.</span><br><span class="line">using tmporary：用到临时表</span><br><span class="line">using filesort：用到额外的排序. (当使用order by v1,而没用到索引时,就会使用额外的排序)</span><br><span class="line">range checked for eache record(index map:N)：没有好的索引.</span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          打赏
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2019/07/15/Hive-%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%B0%83%E4%BC%98/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2019/07/15/Hive%E4%B9%8B%E5%8E%8B%E7%BC%A9%E5%92%8C%E5%AD%98%E5%82%A8/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Hive之压缩和存储
          
        </div>
      </a>
    
    
      <a href="/2019/07/15/Hive%E4%B9%8B%E5%87%BD%E6%95%B0/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Hive之函数</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "",
    app_key: "",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2021
        <i class="ri-heart-fill heart_icon"></i> Movle
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="https://img-blog.csdnimg.cn/20200609161448519.jpg" alt="Movle"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>